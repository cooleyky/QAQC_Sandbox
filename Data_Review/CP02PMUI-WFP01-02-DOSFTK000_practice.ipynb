{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to work through an example QA/QC Data Problem\n",
    "**Author:** Andrew Reed\n",
    "\n",
    "This notebook is going to serve as a dev notebook for RedMine Ticket #9445. I will be testing the DOSTA on the Coastal Pioneer (CP) Site #2 (02) Pioneer Upstream Inshore Wire Fllowing Profiler Mooring (PMUI) - Wire Following Profiler (WFP) #1 (01) - Port Number 2 (02) - Dissolved Oxygen Fast Response Series K number 1 (DOSFTK0001):\n",
    "\n",
    "CP02PMUI-WFP01-02-DOSFTK0001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, requests\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import cmocean\n",
    "import netCDF4 as nc\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request OOI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API information\n",
    "username = 'OOIAPI-C9OSZAQABG1H3U'\n",
    "token = 'JA48WUQVG7F'\n",
    "data_url = 'https://ooinet.oceanobservatories.org/api/m2m/12576/sensor/inv'\n",
    "vocab_url = 'https://ooinet.oceanobservatories.org/api/m2m/12586/vocab/inv'\n",
    "asset_url = 'https://ooinet.oceanobservatories.org/api/m2m/12587'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make an API request and print the results\n",
    "def get_and_print_api(url):\n",
    "    r = requests.get(url, auth=(username, token))\n",
    "    data = r.json()\n",
    "    if r.status_code == 200:\n",
    "        for d in data:\n",
    "            print(d)\n",
    "    else:\n",
    "        print('message: ' + r.reason + '\\n' + 'status_code: ' + str(r.status_code) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site, node, method, and streamed data\n",
    "site = 'CP02PMUI'\n",
    "node = 'WFP01'\n",
    "sensor = '02-DOFSTK000'\n",
    "method = 'recovered'\n",
    "stream = 'dofst_k_wfp_instrument_recovered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'@class': '.VocabRecord', 'model': 'SBE 43F', 'manufacturer': 'Sea-Bird', 'tocL2': 'Upstream Inshore Profiler Mooring', 'tocL3': 'Wire-Following Profiler', 'mindepth': 15.0, 'maxdepth': 70.0, 'vocabId': 525, 'refdes': 'CP02PMUI-WFP01-02-DOFSTK000', 'instrument': 'Dissolved Oxygen', 'tocL1': 'Coastal Pioneer'}\n"
     ]
    }
   ],
   "source": [
    "get_and_print_api('/'.join( (vocab_url, site, node, sensor) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@class': '.VocabRecord',\n",
       " 'model': 'SBE 43F',\n",
       " 'manufacturer': 'Sea-Bird',\n",
       " 'tocL2': 'Upstream Inshore Profiler Mooring',\n",
       " 'tocL3': 'Wire-Following Profiler',\n",
       " 'mindepth': 15.0,\n",
       " 'maxdepth': 70.0,\n",
       " 'vocabId': 525,\n",
       " 'refdes': 'CP02PMUI-WFP01-02-DOFSTK000',\n",
       " 'instrument': 'Dissolved Oxygen',\n",
       " 'tocL1': 'Coastal Pioneer'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocab metadata\n",
    "vocab_request_url = '/'.join((vocab_url, site, node, sensor))\n",
    "params = {\n",
    "    'beginDT':'2014-03-14T00:00:02',\n",
    "    'endDT':'2014-03-19T22:37:54'\n",
    "}\n",
    "\n",
    "# Go get the data from the server\n",
    "r = requests.get(vocab_request_url, params=params, auth=(username, token))\n",
    "vocab_data = r.json()[0]\n",
    "vocab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_data['refdes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now grab deployment info for matching cruise ctds\n",
    "refdes = vocab_data['refdes']\n",
    "deployment_request_url = asset_url + '/events/deployment/query'\n",
    "params = {\n",
    "    'beginDT':'2014-03-14T00:00:02.000Z',\n",
    "    'endDT':'2014-03-19T22:37:54.000Z',\n",
    "    'refdes':refdes\n",
    "}\n",
    "\n",
    "# Get the deployment information \n",
    "r = requests.get(deployment_request_url, params=params, auth=(username, token))\n",
    "deployment_data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(ms):\n",
    "    if ms != None:\n",
    "        return datetime.datetime.utcfromtimestamp(ms/1000)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_cal_data(data):\n",
    "    df = pd.DataFrame()\n",
    "    for d in data[0]['sensor']['calibration']:\n",
    "        for dd in d['calData']:\n",
    "            df = df.append({\n",
    "                'value': dd['value'],\n",
    "                'start': dd['eventStartTime'],\n",
    "                'stop':  dd['eventStopTime'],\n",
    "                'name':  dd['eventName'],\n",
    "                'CalSheet': dd['dataSource'],\n",
    "                'assetUid': dd['assetUid'],\n",
    "            }, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration information\n",
    "cal_request_url = asset_url + '/asset/cal'\n",
    "params = {\n",
    "    'beginDT':'2014-03-14T00:00:02.000Z',\n",
    "    'endDT':'2014-03-19T22:37:54.000Z',\n",
    "    'refdes':refdes\n",
    "}\n",
    "\n",
    "r = requests.get(cal_request_url, params=params, auth=(username, token))\n",
    "cal_data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = reformat_cal_data(cal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = df_cal.sort_values(by=['start','name'])\n",
    "df_cal['start'] = df_cal['start'].apply(convert_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Calibration data -> check against the existing calibration file as a basic QA check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_dir = 'C:/Users/areed/Documents/OOI-CGSN/OOI-Integration/asset-management/calibration/DOFSTK/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for c in list(df_cal['CalSheet'].unique()):\n",
    "    dfnew = pd.read_csv(cal_dir + c.split('_C')[0] + '.csv')\n",
    "    dfnew['start'] = pd.to_datetime(c.split('_')[2])\n",
    "    df = df.append(dfnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'value':'calsheet_value'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = df_cal.merge(df, on=['start','name']).sort_values(by='start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_checks = (df_cal['value']==df_cal['calsheet_value'])\n",
    "def check_calibrations(df,inst_cal='value',csv_cal='calsheet_value'):\n",
    "    checks = (df[inst_cal] == df[csv_cal]) \n",
    "    for i,j in enumerate(checks):\n",
    "        if j is False:\n",
    "            print('Cal Name: {}, Inst. Cal: {}, .csv cal: {}'.format(df['name'][i], df[inst_cal][i], df[csv_cal][i]))\n",
    "        else:\n",
    "            pass\n",
    "    df['cal_check'] = checks\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_calibrations(df_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, the calibration values look okay to me. What is the source of the offset?\n",
    "# Lets plot some of the data to see what the oxygen is doing with respect to time.\n",
    "# First, find and get the THREDDS server url\n",
    "method = 'recovered_wfp'\n",
    "data_request_url = '/'.join((data_api,site,node,sensor,method,stream))\n",
    "\n",
    "params = {\n",
    "    'beginDT':'2014-03-14T00:00:00.000Z',\n",
    "    'endDT':'2014-03-20T00:00:00.000Z',\n",
    "}\n",
    "\n",
    "r = requests.get(data_request_url, params=params, auth=(username,token))\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['allURLs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = data['allURLs'][0]\n",
    "tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC/'\n",
    "datasets = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "nc = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "for i in nc:\n",
    "    if i.endswith('.nc') == False:\n",
    "        nc.remove(i)\n",
    "for i in nc:\n",
    "    try:\n",
    "        float(i[-4])\n",
    "    except:\n",
    "        nc.remove(i)\n",
    "nc_datasets = [os.path.join(tds_url, i) for i in nc]\n",
    "nc_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_data = xr.open_mfdataset([nc_datasets[0]])\n",
    "dofstk_data = xr.open_mfdataset([nc_datasets[1]])                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dofstk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dofstk_data = dofstk_data.swap_dims({'obs':'time'})\n",
    "dofstk_data = dofstk_data.chunk({'time':100})\n",
    "dofstk_data = dofstk_data.sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dofstk_data.int_ctd_pressure.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1)\n",
    "fig.set_size_inches(16, 6)\n",
    "dofstk_data['dofst_k_oxygen_l2'].plot(linestyle = 'None', marker='.', markersize=1, ax=ax)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(dofstk_data['dofst_k_oxygen_l2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
