{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA/QC Process Development - CTDBP Example\n",
    "\n",
    "## Summary\n",
    "This is a practice of developing a review process, review, and report on the CTD. The goal here is to help develop processes for both Quality Assurance of the data, and algorithms for Quality Control. First, this will start from established methods, processes, and examples. We will want to follow on some of the steps before:\n",
    "\n",
    "1. Data Availability\n",
    "    * What data are available?\n",
    "    * Is the data relevant?\n",
    "2. Metadata\n",
    "    * What metadata is available?\n",
    "    * Is the metadata complete?\n",
    "    * What does it tell you about the dataset (for good or bad)?\n",
    "3. Understand the context\n",
    "    * Plot a large range of data. Does it look right based on what you would expect?\n",
    "    * What are the ranges?\n",
    "    * Do the ranges make sense?\n",
    "4. Focus on one or more smaller subsets of data\n",
    "    * Plot some smaller periods (in time or space) to see if they look correct or have issues\n",
    "5. Environmental Comparisons\n",
    "    * Compare the instrument with independent datasets (such as from CTD casts, satellites, gliders, etc.)\n",
    "    * How do they compare?\n",
    "    * Is there anything wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, requests\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'OOIAPI-C9OSZAQABG1H3U'\n",
    "token = 'JA48WUQVG7F'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Set up the sensor names, url names, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lay out the different api urls to use for data requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://ooinet.oceanobservatories.org/api/m2m/12576/sensor/inv'\n",
    "anno_url = 'https://ooinet.oceanobservatories.org/api/m2m/12580/anno/find'\n",
    "vocab_url = 'https://ooinet.oceanobservatories.org/api/m2m/12586/vocab/inv'\n",
    "asset_url = 'https://ooinet.oceanobservatories.org/api/m2m/12587'\n",
    "deploy_url = asset_url + '/events/deployment/query'\n",
    "cal_url = asset_url + '/asset/cal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the data:\n",
    "The first step is to access the data in a systematic, automatic way, using the M2M interface with the apis. The key is to identify where and what I want to access. I can look at the inventory using the port 12576/sensor/inv systematically find and drill down into the data directories. \n",
    "\n",
    "I want to utilize the **CTDBP** on the Coastal Pioneer Central Surface Mooring **CP01CNSM**, which is mounted on the Near-Surface Instrument Frame **RID27**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the site, node, instrument names\n",
    "site = 'CP01CNSM'\n",
    "node = 'RID27'\n",
    "sensor = '03-CTDBPC000'\n",
    "method = 'recovered_host' # 'recovered_inst' 'telemetered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make an API request and print the results\n",
    "def get_and_print_api(url):\n",
    "    r = requests.get(url, auth=(username, token))\n",
    "    data = r.json()\n",
    "    for d in data:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify some functions to convert timestamps\n",
    "ntp_epoch = datetime.datetime(1900, 1, 1)\n",
    "unix_epoch = datetime.datetime(1970, 1, 1)\n",
    "ntp_delta = (unix_epoch - ntp_epoch).total_seconds()\n",
    "\n",
    "def ntp_seconds_to_datetime(ntp_seconds):\n",
    "    return datetime.datetime.utcfromtimestamp(ntp_seconds - ntp_delta).replace(microsecond=0)\n",
    "  \n",
    "def convert_time(ms):\n",
    "    if ms is None:\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.utcfromtimestamp(ms/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_time(1449014400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Metadata:\n",
    "Check out basic instrument vocab (metadata), which will return the reference designator, and allow us to make sure we have the correct instrument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_and_print_api(data_url+'/'+site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api(url):\n",
    "    r = requests.get(url, auth=(username, token))\n",
    "    data = r.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_api(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve vocabulary information for a given instrument\n",
    "request_url = '/'.join((vocab_url, site, node, sensor))\n",
    "r = requests.get(request_url, auth=(username, token))\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the instrument on the CP01CNSM NSIR is a SBE 16plusV2 at 7 meters of depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdes = data[0]['refdes']\n",
    "refdes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Information\n",
    "Next, we will get some of the information about the deployments for this instrument. We will get all the deployments available in the system, and output the following: date ranges, latitude/longitude, asset ID, and sensor ID for each. Note that the **reference designator** specified above represents the geographical location of an instrument across all deployments (e.g. the CTD on the Pioneer Central Surface Mooring), the **Sensor ID** (and its Asset ID equivalent) represents the specific instrument used for a given deployment (i.e. a unique make, model, and serial numbered instrument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the API request url\n",
    "deploy_request_url = deploy_url\n",
    "params = {\n",
    "    'refdes':refdes,\n",
    "}\n",
    "\n",
    "# Get the information from the server\n",
    "r = requests.get(deploy_request_url, params=params, auth=(username, token))\n",
    "deploy_data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_deployment_data(deploy_data):\n",
    "    df = pd.DataFrame()\n",
    "    for d in deploy_data:\n",
    "        df = df.append({\n",
    "            'deployment': d['deploymentNumber'],\n",
    "            'start': convert_time(d['eventStartTime']),\n",
    "            'stop': convert_time(d['eventStopTime']),\n",
    "            'latitude': d['location']['latitude'],\n",
    "            'longitude': d['location']['longitude'],\n",
    "            'sensor': d['sensor']['assetId'],\n",
    "        }, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_df = reformat_deployment_data(deploy_data)\n",
    "deploy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(deploy_df['sensor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the deployment information, there have been 10 deployments of  4 different CTDs on the CP01CNSM NSIF, with asset IDs of 1451, 2059, 2345, 2659. The deployments started on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(deploy_df['stop'].iloc[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop a function to plot a timeline of deployments\n",
    "def plot_deployment_timeline(df):\n",
    "    import matplotlib.dates as mdates\n",
    "    levels = np.array([-5, 5, -3, 3, -1, 1])\n",
    "    fig, (ax) = plt.subplots(figsize=(12,6))\n",
    "    \n",
    "    # Create a baseline for plotting\n",
    "    start = min(df['start'])\n",
    "    stop  = max(df['stop'])\n",
    "    ax.plot((start, stop), (0, 0), 'k', alpha=0.5)\n",
    "    \n",
    "    # Now, iterate through the dates in order to plot and annotate\n",
    "    deployment = df['deployment']\n",
    "    asset = df['sensor']\n",
    "    xdates = df['start']\n",
    "    ydates = df['stop']\n",
    "    \n",
    "    \n",
    "    for ii, (iname, idate, jdate) in enumerate(zip(deployment, xdates, ydates)):\n",
    "        # Set some plotting parameters\n",
    "        level = levels[ii % 6]      # Not sure why/what this is doing\n",
    "        vert = 'top' if level < 0 else 'bottom'\n",
    "#        vert2 = 'bottom' if level < 0 else 'top'\n",
    "        \n",
    "        # Plot!!!\n",
    "#        if str(jdate) == 'NaT':\n",
    "#            pass\n",
    "#        else:\n",
    "#            # Plot the stop points\n",
    "#            ax.scatter(jdate, 0, s=100, marker='s', facecolor='k', edgecolor='k', zorder = 999)\n",
    "#            # Plot a line to the text\n",
    "#            ax.plot((jdate, jdate), (0, -level), c='k', alpha=1.0)\n",
    "#            # Align the stop text properly\n",
    "#            ax.text(jdate, -level, iname, horizontalalignment='right', verticalalignment=vert2, fontsize=16)\n",
    "        ax.scatter(idate, 0, s=100, facecolor='w', edgecolor='k',  zorder=9999)\n",
    "        # Plot a line to the text\n",
    "        ax.plot((idate, idate), (0, level), c='r', alpha=1.0)\n",
    "        # Align the text properly\n",
    "        ax.text(idate, level, iname,\n",
    "                horizontalalignment='right', verticalalignment=vert, fontsize=16)\n",
    "    \n",
    "    ax.set(title='Deployments')\n",
    "    ax.get_xaxis().set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    ax.get_xaxis().set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    # Remove components for easier read\n",
    "    plt.setp((ax.get_yticklabels() + ax.get_yticklines() + list(ax.spines.values())), visible=False)\n",
    "    plt.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_deployment_timeline(deploy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table and timeline above about the deployments, there are some time periods where deployments overlap. How to deal with this issue, because it will cause a problem when loading the data due to conflicting \"obs\" coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Information\n",
    "When Uframe delivers data, it often uses a number of calibration coefficients to generate derived data products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the API request\n",
    "cal_request_url = cal_url\n",
    "params = {\n",
    "    'refdes':refdes,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the information from the server\n",
    "r = requests.get(cal_request_url, params=params, auth=(username, token))\n",
    "cal_data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_cal_data(cal_data):\n",
    "    df = pd.DataFrame()\n",
    "    for d in cal_data:\n",
    "        for dd in d['sensor']['calibration']:\n",
    "            for ddd in dd['calData']:\n",
    "                df = df.append({\n",
    "                    'value': ddd['value'],\n",
    "                    'start': convert_time(ddd['eventStartTime']),\n",
    "                    'stop': convert_time(ddd['eventStopTime']),\n",
    "                    'name': ddd['eventName'],\n",
    "                    'assetUid': ddd['assetUid'],\n",
    "                    'calSheet': ddd['dataSource'],\n",
    "                }, ignore_index=True)\n",
    "    df = df.sort_values(by=['start','name'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_df = reformat_cal_data(cal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cal_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Data Requests\n",
    "* Return netCDF data from the desired sensor for a desired time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_netcdf_datasets(thredds_url):\n",
    "    import time\n",
    "    datasets = []\n",
    "    tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC/'\n",
    "    while not datasets:\n",
    "        datasets = requests.get(thredds_url).text\n",
    "        urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "        x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "        for i in x:\n",
    "            if i.endswith('.nc') == False:\n",
    "                x.remove(i)\n",
    "        for i in x:\n",
    "            try:\n",
    "                float(i[-4])\n",
    "            except:\n",
    "                x.remove(i)\n",
    "        datasets = [os.path.join(tds_url, i) for i in x]\n",
    "        if not datasets: \n",
    "            time.sleep(10)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an URL parser that only keeps your\n",
    "def parse_dataset_names(dataset_names,refdes):\n",
    "    for x in dataset_names:\n",
    "        if x.count(refdes) > 1:\n",
    "            pass\n",
    "        else:\n",
    "            dataset_names.remove(x)\n",
    "    return dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vocab requests doesn't seem to be working\n",
    "# Try the instrument information\n",
    "site = 'CP01CNSM'\n",
    "node = 'RID27'\n",
    "sensor = '03-CTDBPC000'\n",
    "method = 'recovered_inst' # recovered_inst, telemetered\n",
    "stream = 'ctdbp_cdef_instrument_recovered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_and_print_api(data_url+'/'+site+'/'+node+'/'+sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data API requests\n",
    "data_request_url = '/'.join((data_url, site, node, sensor, method, stream))\n",
    "params = {\n",
    "    'include_provenance':'true',\n",
    "    'include_annotations':'true',\n",
    "}\n",
    "r = requests.get(data_request_url, params=params, auth=(username, token))\n",
    "if r.status_code == 200:\n",
    "    data_urls = r.json()\n",
    "else:\n",
    "    print(r.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_urls['allURLs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = get_netcdf_datasets(data_urls['allURLs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = parse_dataset_names(datasets,refdes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_ds = xr.open_mfdataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_ds = ctd_ds.swap_dims({'obs':'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_ds.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ctd_ds.deployment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot where I have data and where I do not. Will need two things\n",
    "ctd_ds.data_vars['ctdbp_seawater_pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_ds.data_vars['temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some checks on the difference between the different salinity and temperature fields\n",
    "ctd_ds.data_vars['preferred_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctd_ds.coords['time'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Exploration\n",
    "With the different CTDBP deployment data loaded into datasets, now we'll take a preliminary look at some of the data. This includes plotting L0, L1, and L2 data products for visual comparison and compute some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets plot the raw conductivity, temperature, and pressure\n",
    "import matplotlib.dates as mdates\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(12, 6))\n",
    "\n",
    "# Plot the raw conductivity\n",
    "ax1.plot_date(x=ctd_ds.coords['time'].values, y=ctd_ds.data_vars['conductivity'].values, marker = '.', color = 'blue')\n",
    "ax1.set_ylabel('Conductivity')\n",
    "ax1.grid()\n",
    "ax1.set_title('Raw Data (Counts) from CP01CNSM NSIF CTDBP')\n",
    "# Plot the raw temperature\n",
    "ax2.plot_date(x=ctd_ds.coords['time'].values, y=ctd_ds.data_vars['temperature'].values, marker='.', color = 'red')\n",
    "ax2.set_ylabel('Temperature')\n",
    "ax2.grid()\n",
    "# Plot the raw pressure\n",
    "ax3.plot_date(x=ctd_ds.coords['time'].values, y=ctd_ds.coords['pressure'].values, marker='.', color='black')\n",
    "ax3.set_ylabel('Pressure')\n",
    "ax3.grid()\n",
    "\n",
    "ax3.get_xaxis().set_major_locator(mdates.MonthLocator(interval=3))\n",
    "ax3.get_xaxis().set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = ctd_ds.data_vars['conductivity']\n",
    "cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = ctd_ds.data_vars['conductivity'].to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond.sort_index(inplace=True)\n",
    "cond.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_rolling_mean=cond.rolling(window='365D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot_date(x=cond.index, y=cond['conductivity'], marker='.', color='blue')\n",
    "ax.plot_date(x=cond_rolling_mean.index, y=cond_rolling_mean['conductivity'], marker='.', color='red')\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
