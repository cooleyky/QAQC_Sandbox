{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis for Metadata Review in OOI Asset Management System\n",
    "\n",
    "### Motivation:\n",
    "The Asset Management system for OOI is primarly housed on GitHub in a variety of csv files. Until now, the calibration coefficients stored in the csv files have been manually entered. While we have utilized a \"human-in-the-loop\" review approach to catch errors, some errors have slipped through (e.g. truncation of significant figures).\n",
    "\n",
    "### Approach:\n",
    "My goal is to develop an automated approach to catch possible errors which already exist within the asset management system. To accomplish this, I will compare the csv files loaded into the GitHub asset management system with the original vendor files as well as the QCT (quality control testing) documents which capture the coefficients loaded onto the instrument at the time of reception at WHOI from the vendor.\n",
    "\n",
    "### Data Sources:\n",
    "* **GitHub**: CSV files containing the calibration coefficients. Directory organization by sensor+class. The files are named as \"(CGINS)-(sensor+class)-(serial number)-(YYYYMMDD)\" where YYYYMMDD is the calibration date.\n",
    "* **Vault**: Version-controlled storage location of the vendor calibrations, in the Records/Instrument Records/Instrument directories. Within the relevant directory, calibration files are stored as either .cal, .xmlcon, .pdf, or within zipped directories.\n",
    "* **Alfresco**: Version-controlled web-accessed. The calibrations loaded onto the instrument during the initial checkin-in upon receipt (the QCT process) are stored here as either .cap or .txt files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import likely important packages, etc.\n",
    "import sys, os, csv, re\n",
    "from wcmatch import fnmatch\n",
    "import datetime\n",
    "import time\n",
    "import xml.etree.ElementTree as et\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import self-written functions from utils package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration_files(serial_nums,dirpath):\n",
    "    calibration_files = {}\n",
    "    for uid,sn in serial_nums.items():\n",
    "        files = []\n",
    "        for file in os.listdir(dirpath):\n",
    "            if sn in file:\n",
    "                if 'Calibration_File' in file:\n",
    "                    files.append(file)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        calibration_files.update({uid:files})\n",
    "        \n",
    "    return calibration_files\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try building a function to do the file path generator\n",
    "def generate_file_path(dirpath,filename,ext=['.cap','.txt','.log'],exclude=['_V','_Data_Workshop']):\n",
    "    \"\"\"\n",
    "    Function which searches for the location of the given file and returns\n",
    "    the full path to the file.\n",
    "    \n",
    "    Args:\n",
    "        dirpath - parent directory path under which to search\n",
    "        filename - the name of the file to search for\n",
    "        ext - \n",
    "        exclude - optional list which allows for excluding certain\n",
    "            directories from the search\n",
    "    Returns:\n",
    "        fpath - the file path to the filename from the current\n",
    "            working directory.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(dirpath):\n",
    "        dirs[:] = [d for d in dirs if d not in exclude]\n",
    "        for fname in files:\n",
    "            if fnmatch.fnmatch(fname, [filename+'*'+x for x in ext]):\n",
    "                fpath = os.path.join(root, fname)\n",
    "                return fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHOI Asset Tracking Spreadsheet\n",
    "First, I want to load and examine exactly what type of data is stored in the WHOI Asset Tracking Spreadsheet and what information it has that may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel_spreadsheet = 'C:/Users/areed/Documents/Project_Files/Documentation/System/System Notebook/WHOI_Asset_Tracking.xlsx'\n",
    "excel_spreadsheet = '/media/andrew/OS/Users/areed/Documents/Project_Files/Documentation/System/System Notebook/WHOI_Asset_Tracking.xlsx'\n",
    "sheet_name = 'Sensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instrument\n",
       "Class</th>\n",
       "      <th>Series</th>\n",
       "      <th>Supplier\n",
       "Serial Number</th>\n",
       "      <th>WHOI #</th>\n",
       "      <th>OOI #</th>\n",
       "      <th>UID</th>\n",
       "      <th>Model</th>\n",
       "      <th>CGSN PN</th>\n",
       "      <th>Firmware Version</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>...</th>\n",
       "      <th>QCT Testing</th>\n",
       "      <th>PreDeployment</th>\n",
       "      <th>Post Deployment</th>\n",
       "      <th>Refurbishment/ Repair</th>\n",
       "      <th>DO Number</th>\n",
       "      <th>Date Received</th>\n",
       "      <th>Deployment History</th>\n",
       "      <th>Current Deployment</th>\n",
       "      <th>Instrument Location on Current Deployment</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CTDBP</td>\n",
       "      <td>F</td>\n",
       "      <td>16-50001</td>\n",
       "      <td>116098</td>\n",
       "      <td>A00635</td>\n",
       "      <td>CGINS-CTDBPF-50001</td>\n",
       "      <td>16PlusV2</td>\n",
       "      <td>1336-00001-00006</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>SeaBird</td>\n",
       "      <td>...</td>\n",
       "      <td>3305-00102-00016\\n3305-00102-00091\\n3305-00102...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305-00900-00080\\n3305-00900-00280</td>\n",
       "      <td>WH-SC11-01-CTD-1007</td>\n",
       "      <td>2014-01-23 00:00:00</td>\n",
       "      <td>GI01SUMO-00001\\nGI01SUMO-00003\\nGI01SUMO-00005</td>\n",
       "      <td>GI01SUMO-00005</td>\n",
       "      <td>NSIF</td>\n",
       "      <td>(NSIF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>CTDBP</td>\n",
       "      <td>F</td>\n",
       "      <td>16-50060</td>\n",
       "      <td>116830</td>\n",
       "      <td>A01092</td>\n",
       "      <td>CGINS-CTDBPF-50060</td>\n",
       "      <td>16PlusV2</td>\n",
       "      <td>1336-00001-00006</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>SeaBird</td>\n",
       "      <td>...</td>\n",
       "      <td>3305-00102-00039\\n3305-00102-00092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305-00900-00103</td>\n",
       "      <td>WH-SC11-01-CTD-1013</td>\n",
       "      <td>2014-09-29 00:00:00</td>\n",
       "      <td>GS01SUMO-00001\\nGS01SUMO-00003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CTDBP</td>\n",
       "      <td>F</td>\n",
       "      <td>16-50061</td>\n",
       "      <td>116831</td>\n",
       "      <td>A01093</td>\n",
       "      <td>CGINS-CTDBPF-50061</td>\n",
       "      <td>16PlusV2</td>\n",
       "      <td>1336-00001-00006</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>SeaBird</td>\n",
       "      <td>...</td>\n",
       "      <td>3305-00102-00040\\n3305-00102-00113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305-00900-00155</td>\n",
       "      <td>WH-SC11-01-CTD-1013</td>\n",
       "      <td>2014-09-29 00:00:00</td>\n",
       "      <td>GI01SUMO-00002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>CTDBP</td>\n",
       "      <td>F</td>\n",
       "      <td>16-50062</td>\n",
       "      <td>116832</td>\n",
       "      <td>A01094</td>\n",
       "      <td>CGINS-CTDBPF-50062</td>\n",
       "      <td>16PlusV2</td>\n",
       "      <td>1336-00001-00006</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>SeaBird</td>\n",
       "      <td>...</td>\n",
       "      <td>3305-00102-00041\\n3305-00102-00093\\n3305-00102...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305-00900-00097\\n3305-00900-00329</td>\n",
       "      <td>WH-SC11-01-CTD-1013</td>\n",
       "      <td>2014-09-29 00:00:00</td>\n",
       "      <td>GA01SUMO-00001\\nGA01SUMO-00003</td>\n",
       "      <td>GS01SUMO-00004</td>\n",
       "      <td>NSIF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>CTDBP</td>\n",
       "      <td>F</td>\n",
       "      <td>16-50065</td>\n",
       "      <td>116833</td>\n",
       "      <td>A01095</td>\n",
       "      <td>CGINS-CTDBPF-50065</td>\n",
       "      <td>16PlusV2</td>\n",
       "      <td>1336-00001-00006</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>SeaBird</td>\n",
       "      <td>...</td>\n",
       "      <td>3305-00102-00042\\n3305-00102-00072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305-00900-00050</td>\n",
       "      <td>WH-SC11-01-CTD-1013</td>\n",
       "      <td>2014-09-29 00:00:00</td>\n",
       "      <td>GI Spare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Battery voltage diminished to \"!!!Low Battery!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>CTDBP</td>\n",
       "      <td>F</td>\n",
       "      <td>16-50116</td>\n",
       "      <td>117285</td>\n",
       "      <td>A01420</td>\n",
       "      <td>CGINS-CTDBPF-50116</td>\n",
       "      <td>16PlusV2</td>\n",
       "      <td>1336-00001-00006</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>SeaBird</td>\n",
       "      <td>...</td>\n",
       "      <td>3305-00102-00060\\n3305-00102-00133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305-00900-00203</td>\n",
       "      <td>WH-SC11-01-CTD-1017</td>\n",
       "      <td>2015-05-14 00:00:00</td>\n",
       "      <td>GA01SUMO-00002\\nIrminger 5 Spare</td>\n",
       "      <td>GS 5 spare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CTDBP</td>\n",
       "      <td>F</td>\n",
       "      <td>16-50142</td>\n",
       "      <td>117448</td>\n",
       "      <td>A01573</td>\n",
       "      <td>CGINS-CTDBPF-50142</td>\n",
       "      <td>16PlusV2</td>\n",
       "      <td>1336-00001-00006</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>SeaBird</td>\n",
       "      <td>...</td>\n",
       "      <td>3305-00102-00061\\n3305-00102-00132\\n3305-00102...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305-00900-00194\\n3305-00900-00395</td>\n",
       "      <td>WH-SC11-01-CTD-1018</td>\n",
       "      <td>2015-07-01 00:00:00</td>\n",
       "      <td>GS01SUMO-00002\\nGI01SUMO-00004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSIF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>CTDBP</td>\n",
       "      <td>F</td>\n",
       "      <td>16-50143</td>\n",
       "      <td>117447</td>\n",
       "      <td>A01572</td>\n",
       "      <td>CGINS-CTDBPF-50143</td>\n",
       "      <td>16PlusV2</td>\n",
       "      <td>1336-00001-00006</td>\n",
       "      <td>2.5.2</td>\n",
       "      <td>SeaBird</td>\n",
       "      <td>...</td>\n",
       "      <td>3305-00102-00062\\n3305-00102-00187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3305-00900-00345</td>\n",
       "      <td>WH-SC11-01-CTD-1018</td>\n",
       "      <td>2015-07-01 00:00:00</td>\n",
       "      <td>GA/GS Spare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Instrument\\nClass Series Supplier\\nSerial Number  WHOI #   OOI #  \\\n",
       "49             CTDBP      F                16-50001  116098  A00635   \n",
       "58             CTDBP      F                16-50060  116830  A01092   \n",
       "59             CTDBP      F                16-50061  116831  A01093   \n",
       "60             CTDBP      F                16-50062  116832  A01094   \n",
       "61             CTDBP      F                16-50065  116833  A01095   \n",
       "74             CTDBP      F                16-50116  117285  A01420   \n",
       "81             CTDBP      F                16-50142  117448  A01573   \n",
       "82             CTDBP      F                16-50143  117447  A01572   \n",
       "\n",
       "                   UID     Model           CGSN PN Firmware Version Supplier  \\\n",
       "49  CGINS-CTDBPF-50001  16PlusV2  1336-00001-00006            2.5.2  SeaBird   \n",
       "58  CGINS-CTDBPF-50060  16PlusV2  1336-00001-00006            2.5.2  SeaBird   \n",
       "59  CGINS-CTDBPF-50061  16PlusV2  1336-00001-00006            2.5.2  SeaBird   \n",
       "60  CGINS-CTDBPF-50062  16PlusV2  1336-00001-00006            2.5.2  SeaBird   \n",
       "61  CGINS-CTDBPF-50065  16PlusV2  1336-00001-00006            2.5.2  SeaBird   \n",
       "74  CGINS-CTDBPF-50116  16PlusV2  1336-00001-00006            2.5.2  SeaBird   \n",
       "81  CGINS-CTDBPF-50142  16PlusV2  1336-00001-00006            2.5.2  SeaBird   \n",
       "82  CGINS-CTDBPF-50143  16PlusV2  1336-00001-00006            2.5.2  SeaBird   \n",
       "\n",
       "                          ...                          \\\n",
       "49                        ...                           \n",
       "58                        ...                           \n",
       "59                        ...                           \n",
       "60                        ...                           \n",
       "61                        ...                           \n",
       "74                        ...                           \n",
       "81                        ...                           \n",
       "82                        ...                           \n",
       "\n",
       "                                          QCT Testing PreDeployment  \\\n",
       "49  3305-00102-00016\\n3305-00102-00091\\n3305-00102...           NaN   \n",
       "58                 3305-00102-00039\\n3305-00102-00092           NaN   \n",
       "59                 3305-00102-00040\\n3305-00102-00113           NaN   \n",
       "60  3305-00102-00041\\n3305-00102-00093\\n3305-00102...           NaN   \n",
       "61                 3305-00102-00042\\n3305-00102-00072           NaN   \n",
       "74                 3305-00102-00060\\n3305-00102-00133           NaN   \n",
       "81  3305-00102-00061\\n3305-00102-00132\\n3305-00102...           NaN   \n",
       "82                 3305-00102-00062\\n3305-00102-00187           NaN   \n",
       "\n",
       "   Post Deployment               Refurbishment/ Repair             DO Number  \\\n",
       "49             NaN  3305-00900-00080\\n3305-00900-00280   WH-SC11-01-CTD-1007   \n",
       "58             NaN                    3305-00900-00103   WH-SC11-01-CTD-1013   \n",
       "59             NaN                    3305-00900-00155   WH-SC11-01-CTD-1013   \n",
       "60             NaN  3305-00900-00097\\n3305-00900-00329   WH-SC11-01-CTD-1013   \n",
       "61             NaN                    3305-00900-00050   WH-SC11-01-CTD-1013   \n",
       "74             NaN                    3305-00900-00203   WH-SC11-01-CTD-1017   \n",
       "81             NaN  3305-00900-00194\\n3305-00900-00395  WH-SC11-01-CTD-1018    \n",
       "82             NaN                    3305-00900-00345  WH-SC11-01-CTD-1018    \n",
       "\n",
       "          Date Received                              Deployment History  \\\n",
       "49  2014-01-23 00:00:00  GI01SUMO-00001\\nGI01SUMO-00003\\nGI01SUMO-00005   \n",
       "58  2014-09-29 00:00:00                  GS01SUMO-00001\\nGS01SUMO-00003   \n",
       "59  2014-09-29 00:00:00                                  GI01SUMO-00002   \n",
       "60  2014-09-29 00:00:00                  GA01SUMO-00001\\nGA01SUMO-00003   \n",
       "61  2014-09-29 00:00:00                                        GI Spare   \n",
       "74  2015-05-14 00:00:00                GA01SUMO-00002\\nIrminger 5 Spare   \n",
       "81  2015-07-01 00:00:00                  GS01SUMO-00002\\nGI01SUMO-00004   \n",
       "82  2015-07-01 00:00:00                                     GA/GS Spare   \n",
       "\n",
       "   Current Deployment Instrument Location on Current Deployment  \\\n",
       "49     GI01SUMO-00005                                      NSIF   \n",
       "58                NaN                                       NaN   \n",
       "59                NaN                                       NaN   \n",
       "60     GS01SUMO-00004                                      NSIF   \n",
       "61                NaN                                       NaN   \n",
       "74         GS 5 spare                                       NaN   \n",
       "81                NaN                                      NSIF   \n",
       "82                NaN                                       NaN   \n",
       "\n",
       "                                                Notes  \n",
       "49                                             (NSIF)  \n",
       "58                                                NaN  \n",
       "59                                                NaN  \n",
       "60                                                NaN  \n",
       "61  Battery voltage diminished to \"!!!Low Battery!...  \n",
       "74                                                NaN  \n",
       "81                                                NaN  \n",
       "82                                                NaN  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are all the different series of CTDs?\n",
    "CTDBP = whoi_asset_tracking(excel_spreadsheet,sheet_name,instrument_class='CTDBP',whoi=True,series='F')\n",
    "CTDBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the unique identifiers (UID) of the instruments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CGINS-CTDBPF-50142',\n",
       " 'CGINS-CTDBPF-50001',\n",
       " 'CGINS-CTDBPF-50143',\n",
       " 'CGINS-CTDBPF-50060',\n",
       " 'CGINS-CTDBPF-50061',\n",
       " 'CGINS-CTDBPF-50116',\n",
       " 'CGINS-CTDBPF-50065',\n",
       " 'CGINS-CTDBPF-50062']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uids = list(set(CTDBP['UID']))\n",
    "uids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the QCT file names for the UIDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_dict = {}\n",
    "for uid in uids:\n",
    "    # Get the QCT Document numbers from the asset tracking sheet\n",
    "    CTDBP['UID_match'] = CTDBP['UID'].apply(lambda x: True if uid in x else False)\n",
    "    qct_series = CTDBP[CTDBP['UID_match'] == True]['QCT Testing']\n",
    "    qct_series = list(qct_series.iloc[0].split('\\n'))\n",
    "    qct_dict.update({uid:qct_series})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CGINS-CTDBPF-50142': ['3305-00102-00061',\n",
       "  '3305-00102-00132',\n",
       "  '3305-00102-00194'],\n",
       " 'CGINS-CTDBPF-50001': ['3305-00102-00016',\n",
       "  '3305-00102-00091',\n",
       "  '3305-00102-00153'],\n",
       " 'CGINS-CTDBPF-50143': ['3305-00102-00062', '3305-00102-00187'],\n",
       " 'CGINS-CTDBPF-50060': ['3305-00102-00039', '3305-00102-00092'],\n",
       " 'CGINS-CTDBPF-50061': ['3305-00102-00040', '3305-00102-00113'],\n",
       " 'CGINS-CTDBPF-50116': ['3305-00102-00060', '3305-00102-00133'],\n",
       " 'CGINS-CTDBPF-50065': ['3305-00102-00042', '3305-00102-00072'],\n",
       " 'CGINS-CTDBPF-50062': ['3305-00102-00041',\n",
       "  '3305-00102-00093',\n",
       "  '3305-00102-00174']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_directory = '/media/andrew/OS/Users/areed/Documents/Project_Files/'\n",
    "cal_directory = '/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Instrument_Records/CTDBP/'\n",
    "asset_management_directory = '/home/andrew/Documents/OOI-CGSN/ooi-integration/asset-management/calibration/CTDBPF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the asset management information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CGINS-CTDBPF-50001': ['CGINS-CTDBPF-50001__20140116.csv',\n",
       "  'CGINS-CTDBPF-50001__20151230.csv',\n",
       "  'CGINS-CTDBPF-50001__20170923.csv'],\n",
       " 'CGINS-CTDBPF-50060': ['CGINS-CTDBPF-50060__20150327.csv',\n",
       "  'CGINS-CTDBPF-50060__20140920.csv'],\n",
       " 'CGINS-CTDBPF-50061': ['CGINS-CTDBPF-50061__20140919.csv',\n",
       "  'CGINS-CTDBPF-50061__20161021.csv'],\n",
       " 'CGINS-CTDBPF-50062': ['CGINS-CTDBPF-50062__20140919.csv',\n",
       "  'CGINS-CTDBPF-50062__20180414.csv',\n",
       "  'CGINS-CTDBPF-50062__20160309.csv'],\n",
       " 'CGINS-CTDBPF-50116': ['CGINS-CTDBPF-50116__20150428.csv',\n",
       "  'CGINS-CTDBPF-50116__20170312.csv'],\n",
       " 'CGINS-CTDBPF-50142': ['CGINS-CTDBPF-50142__20170312.csv',\n",
       "  'CGINS-CTDBPF-50142__20150616.csv',\n",
       "  'CGINS-CTDBPF-50142__20181005.csv'],\n",
       " 'CGINS-CTDBPF-50143': ['CGINS-CTDBPF-50143__20150615.csv',\n",
       "  'CGINS-CTDBPF-50143__20180502.csv']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dict = load_asset_management(CTDBP, asset_management_directory)\n",
    "csv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the calibration files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CGINS-CTDBPF-50142': '50142',\n",
       " 'CGINS-CTDBPF-50001': '50001',\n",
       " 'CGINS-CTDBPF-50143': '50143',\n",
       " 'CGINS-CTDBPF-50060': '50060',\n",
       " 'CGINS-CTDBPF-50061': '50061',\n",
       " 'CGINS-CTDBPF-50116': '50116',\n",
       " 'CGINS-CTDBPF-50065': '50065',\n",
       " 'CGINS-CTDBPF-50062': '50062'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serial_nums = get_serial_nums(CTDBP, uids)\n",
    "serial_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CGINS-CTDBPF-50142': ['CTDBP-F_SBE_16PlusV2_SN_16-50142_Calibration_Files_2015-07-01.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50142_Calibration_Files_2017-03-12.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50142_Calibration_Files_2018-10-05.zip'],\n",
       " 'CGINS-CTDBPF-50001': ['CTDBP-F_SBE_16PlusV2_SN_16-50001_Calibration_Files.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50001_Calibration_Files_2016-03-31.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50001_Calibration_Files_2017-09-29.zip'],\n",
       " 'CGINS-CTDBPF-50143': ['CTDBP-F_SBE_16PlusV2_SN_16-50143_Calibration_Files_2015-07-01.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50143_Calibration_Files_2018-05-02.zip'],\n",
       " 'CGINS-CTDBPF-50060': ['CTDBP-F_SBE_16PlusV2_SN_16-50060_Calibration_Files_2014-10-15.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50060_Calibration_Files_2016-05-02.zip'],\n",
       " 'CGINS-CTDBPF-50061': ['CTDBP-F_SBE_16PlusV2_SN_16-50061_Calibration_Files_2014-10-15.zip',\n",
       "  'CTDBP-F_SBE_16plusV2_SN_16-50061_Calibration_Files_2016-10-21.zip'],\n",
       " 'CGINS-CTDBPF-50116': ['CTDBP-F_SBE_16PlusV2_SN_16-50116_Calibration_Files_2015-05-18.pdf',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50116_Calibration_Files_2017-03-12.zip'],\n",
       " 'CGINS-CTDBPF-50065': ['CTDBP-F_SBE_16PlusV2_SN_16-50065_Calibration_Files_2014-10-15.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50065_Calibration_Files_2015-12-08.zip',\n",
       "  'CTDBP-F_SBE_16plusV2_SN_16-50065_Calibration_File_2015-10-28.xmlcon'],\n",
       " 'CGINS-CTDBPF-50062': ['CTDBP-F_SBE_16PlusV2_SN_16-50062_Calibration_Files_2014-10-15.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50062_Calibration_Files_2016-05-11.zip',\n",
       "  'CTDBP-F_SBE_16PlusV2_SN_16-50062_Calibration_Files_2018-04-14.zip']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_dict = get_calibration_files(serial_nums, cal_directory)\n",
    "cal_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CGINS-CTDBPF-50142'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, pick out the first UID\n",
    "uid = uids[0]\n",
    "uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CTD Calibration object\n",
    "CTDcal = CTDCalibration(uid=uid)\n",
    "CTDxml = CTDCalibration(uid=uid)\n",
    "CTDqct = CTDCalibration(uid=uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purge the temp directory\n",
    "shutil.rmtree('/'.join((os.getcwd(),'temp')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the csv files into a similar temp directory for local working\n",
    "for file in csv_dict[uid]:\n",
    "    csv_savepath = '/'.join((os.getcwd(),'temp','csv'))\n",
    "    ensure_dir('/'.join((os.getcwd(),'temp','csv')))\n",
    "    # Now save the csv into the temp directory\n",
    "    shutil.copy('/'.join((asset_management_directory,file)), csv_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CGINS-CTDBPF-50142': ['3305-00102-00061',\n",
       "  '3305-00102-00132',\n",
       "  '3305-00102-00194'],\n",
       " 'CGINS-CTDBPF-50001': ['3305-00102-00016',\n",
       "  '3305-00102-00091',\n",
       "  '3305-00102-00153'],\n",
       " 'CGINS-CTDBPF-50143': ['3305-00102-00062', '3305-00102-00187'],\n",
       " 'CGINS-CTDBPF-50060': ['3305-00102-00039', '3305-00102-00092'],\n",
       " 'CGINS-CTDBPF-50061': ['3305-00102-00040', '3305-00102-00113'],\n",
       " 'CGINS-CTDBPF-50116': ['3305-00102-00060', '3305-00102-00133'],\n",
       " 'CGINS-CTDBPF-50065': ['3305-00102-00042', '3305-00102-00072'],\n",
       " 'CGINS-CTDBPF-50062': ['3305-00102-00041',\n",
       "  '3305-00102-00093',\n",
       "  '3305-00102-00174']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No QCT file found for: 3305-00102-00061\n",
      "No QCT file found for: 3305-00102-00061\n",
      "Write CGINS-CTDBPF-50142__20170312.csv to /home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Metadata_Review/temp/qct? [y/n]: y\n",
      "Write CGINS-CTDBPF-50142__20181005.csv to /home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Metadata_Review/temp/qct? [y/n]: y\n"
     ]
    }
   ],
   "source": [
    "for file in qct_dict[uid]:\n",
    "    # Generate the full file path\n",
    "    qct_path = generate_file_path(qct_directory, file)\n",
    "    # Initialize a CTD object\n",
    "    CTD = CTDCalibration(uid=uid)\n",
    "    # Load the QCT information\n",
    "    try:\n",
    "        CTD.load_qct(qct_path)\n",
    "        # Generate the save file path\n",
    "        qct_savepath = '/'.join((os.getcwd(),'temp','qct'))\n",
    "        ensure_dir('/'.join((os.getcwd(),'temp','qct')))\n",
    "    except:\n",
    "        print(f'No QCT file found for: {file}')\n",
    "    # Now save the qct info to a csv\n",
    "    try:\n",
    "        CTD.write_csv(qct_savepath)\n",
    "    except:\n",
    "        print(f'No QCT file found for: {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3305-00102-00061', '3305-00102-00132', '3305-00102-00194']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qct_dict[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cal file found in CTDBP-F_SBE_16PlusV2_SN_16-50142_Calibration_Files_2015-07-01.zip\n",
      "No cal file found in CTDBP-F_SBE_16PlusV2_SN_16-50142_Calibration_Files_2017-03-12.zip\n",
      "Write CGINS-CTDBPF-50142__20181005.csv to /home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Metadata_Review/temp/cal? [y/n]: y\n"
     ]
    }
   ],
   "source": [
    "for file in cal_dict[uid]:\n",
    "    # Generate the full file path\n",
    "    cal_path = generate_file_path(cal_directory, file, ext=[''])\n",
    "    # Initialize a CTD object\n",
    "    CTD = CTDCalibration(uid=uid)\n",
    "    # Load the QCT information\n",
    "    CTD.load_cal(cal_path)\n",
    "    # Generate the save file path\n",
    "    cal_savepath = '/'.join((os.getcwd(),'temp','cal'))\n",
    "    ensure_dir('/'.join((os.getcwd(),'temp','cal')))\n",
    "    # Now save the qct info to a csv\n",
    "    try:\n",
    "        CTD.write_csv(cal_savepath)\n",
    "    except ValueError:\n",
    "        print(f'No cal file found in {file}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write CGINS-CTDBPF-50142__20150616.csv to /home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Metadata_Review/temp/xml? [y/n]: y\n",
      "Write CGINS-CTDBPF-50142__20170312.csv to /home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Metadata_Review/temp/xml? [y/n]: y\n",
      "Write CGINS-CTDBPF-50142__20181005.csv to /home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Metadata_Review/temp/xml? [y/n]: y\n"
     ]
    }
   ],
   "source": [
    "for file in cal_dict[uid]:\n",
    "    # Generate the full file path\n",
    "    cal_path = generate_file_path(cal_directory, file, ext=[''])\n",
    "    # Initialize a CTD object\n",
    "    CTD = CTDCalibration(uid=uid)\n",
    "    # Load the QCT information\n",
    "    try:\n",
    "        CTD.load_xml(cal_path)\n",
    "        # Generate the save file path\n",
    "        xml_savepath = '/'.join((os.getcwd(),'temp','xml'))\n",
    "        ensure_dir(xml_savepath)\n",
    "        # Now save the qct info to a csv\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        CTD.write_csv(xml_savepath)\n",
    "    except ValueError:\n",
    "        print(f'No xml file found for {file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking instrument calibration values\n",
    "After loading the **WHOI Asset Tracking Sheet**, we now have the following critical data for checking calibration information:\n",
    "* Supplier Serial Number - this links back to the original **.cal**, **.xmlcon**, and vendor docs\n",
    "* OOI UID - this is the link between the instrument and the OOINet\n",
    "* QCT Document Number - this number links the instrument to the QCT screen capture of the calibration values loaded onto the instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process to load the **CSV** calibration file\n",
    "In order to check that the calibrations in asset management, I have to be able to load the asset management calibration csv files into a dataframe. \n",
    "* First, get all the unique CTDBPCs in Asset Management\n",
    "* Next, parse the csv files in asset management to get the unique instrument serial numbers\n",
    "* With the serial numbers, find the associated instrument calibration csvs\n",
    "* For each calibration csv, load the data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_date(x):\n",
    "    x = str(x)\n",
    "    ind1 = x.index('__')\n",
    "    ind2 = x.index('.')\n",
    "    return x[ind1+2:ind2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to compare dataframe\n",
    "csv_files = pd.DataFrame(sorted(csv_dict[uid]),columns=['csv'])\n",
    "csv_files['cal date'] = csv_files['csv'].apply(lambda x: get_file_date(x))\n",
    "csv_files.set_index('cal date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to compare dataframe\n",
    "cal_files = pd.DataFrame(sorted(os.listdir('temp/cal')),columns=['cal'])\n",
    "cal_files['cal date'] = cal_files['cal'].apply(lambda x: get_file_date(x))\n",
    "cal_files.set_index('cal date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to compare dataframe\n",
    "xml_files = pd.DataFrame(sorted(os.listdir('temp/xml')),columns=['xml'])\n",
    "xml_files['cal date'] = xml_files['xml'].apply(lambda x: get_file_date(x))\n",
    "xml_files.set_index('cal date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to compare dataframe\n",
    "qct_files = pd.DataFrame(sorted(os.listdir('temp/qct')),columns=['qct'])\n",
    "qct_files['cal date'] = qct_files['qct'].apply(lambda x: get_file_date(x))\n",
    "qct_files.set_index('cal date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = csv_files.join(cal_files,how='outer').join(xml_files,how='outer').join(qct_files,how='outer').fillna(value='-999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csv</th>\n",
       "      <th>cal</th>\n",
       "      <th>xml</th>\n",
       "      <th>qct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cal date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20150616</th>\n",
       "      <td>CGINS-CTDBPF-50142__20150616.csv</td>\n",
       "      <td>-999</td>\n",
       "      <td>CGINS-CTDBPF-50142__20150616.csv</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170312</th>\n",
       "      <td>CGINS-CTDBPF-50142__20170312.csv</td>\n",
       "      <td>-999</td>\n",
       "      <td>CGINS-CTDBPF-50142__20170312.csv</td>\n",
       "      <td>CGINS-CTDBPF-50142__20170312.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20181005</th>\n",
       "      <td>CGINS-CTDBPF-50142__20181005.csv</td>\n",
       "      <td>CGINS-CTDBPF-50142__20181005.csv</td>\n",
       "      <td>CGINS-CTDBPF-50142__20181005.csv</td>\n",
       "      <td>CGINS-CTDBPF-50142__20181005.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       csv                               cal  \\\n",
       "cal date                                                                       \n",
       "20150616  CGINS-CTDBPF-50142__20150616.csv                              -999   \n",
       "20170312  CGINS-CTDBPF-50142__20170312.csv                              -999   \n",
       "20181005  CGINS-CTDBPF-50142__20181005.csv  CGINS-CTDBPF-50142__20181005.csv   \n",
       "\n",
       "                                       xml                               qct  \n",
       "cal date                                                                      \n",
       "20150616  CGINS-CTDBPF-50142__20150616.csv                              -999  \n",
       "20170312  CGINS-CTDBPF-50142__20170312.csv  CGINS-CTDBPF-50142__20170312.csv  \n",
       "20181005  CGINS-CTDBPF-50142__20181005.csv  CGINS-CTDBPF-50142__20181005.csv  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cal date\n",
       "20150616    CGINS-CTDBPF-50142__20150616.csv\n",
       "20170312    CGINS-CTDBPF-50142__20170312.csv\n",
       "20181005    CGINS-CTDBPF-50142__20181005.csv\n",
       "Name: csv, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files['csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cal_coeffs(coeffs_dict):\n",
    "    \n",
    "    # Part 1: coeff by coeff comparison between each source of coefficients\n",
    "    keys = list(coeffs_dict.keys())\n",
    "    comparison = {}\n",
    "    for i in range(len(keys)):\n",
    "        names = (keys[i], keys[i - (len(keys)-1)])\n",
    "        check = len(coeffs_dict.get(keys[i])['value']) == len(coeffs_dict.get(keys[i - (len(keys)-1)])['value'])\n",
    "        if check:\n",
    "            compare = np.isclose(coeffs_dict.get(keys[i])['value'], coeffs_dict.get(keys[i - (len(keys)-1)])['value'])\n",
    "            comparison.update({names:compare})\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    # Part 2: now do a logical_and comparison between the results from part 1\n",
    "    keys = list(comparison.keys())\n",
    "    i = 0\n",
    "    mask = comparison.get(keys[i])\n",
    "    while i < len(keys)-1:\n",
    "        i = i + 1\n",
    "        mask = np.logical_and(mask, comparison.get(keys[i]))\n",
    "        print(i)\n",
    "       \n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for cal_date in df_files.index:\n",
    "    # Part 1, load all of the csv files\n",
    "    coeffs_dict = {}\n",
    "    for source,fname in df_files.loc[cal_date].items():\n",
    "        if fname != '-999':\n",
    "            load_directory = '/'.join((os.getcwd(),'temp',source,fname))\n",
    "            df_coeffs = pd.read_csv(load_directory)\n",
    "            df_coeffs.set_index(keys='name',inplace=True)\n",
    "            df_coeffs.sort_index(inplace=True)\n",
    "            coeffs_dict.update({source:df_coeffs})\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # Part 2, now check the calibration coefficients\n",
    "    mask = check_cal_coeffs(coeffs_dict)\n",
    "    \n",
    "    # Part 3: get the calibration coefficients are wrong\n",
    "    # and show them\n",
    "    fname = df_files.loc[cal_date]['csv']\n",
    "    if fname == '-999':\n",
    "        incorrect = 'No csv file.'\n",
    "    else:\n",
    "        incorrect = coeffs_dict['csv'][mask == False]\n",
    "    result.update({fname:incorrect})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CGINS-CTDBPF-50142__20150616.csv': Empty DataFrame\n",
       " Columns: [serial, value, notes]\n",
       " Index: [], 'CGINS-CTDBPF-50142__20170312.csv': Empty DataFrame\n",
       " Columns: [serial, value, notes]\n",
       " Index: [], 'CGINS-CTDBPF-50142__20181005.csv': Empty DataFrame\n",
       " Columns: [serial, value, notes]\n",
       " Index: []}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>value</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [serial, value, notes]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = check_cal_coeffs(coeffs_dict)\n",
    "result = coeffs_dict['csv'][mask == False]\n",
    "result.merge(coeffs_dict['qct'][mask == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csv':               serial         value  notes\n",
       " name                                     \n",
       " CC_a0       16-50142  1.250743e-03    NaN\n",
       " CC_a1       16-50142  2.729980e-04    NaN\n",
       " CC_a2       16-50142 -8.672512e-07    NaN\n",
       " CC_a3       16-50142  1.722119e-07    NaN\n",
       " CC_cpcor    16-50142 -9.570000e-08    NaN\n",
       " CC_ctcor    16-50142  3.250000e-06    NaN\n",
       " CC_g        16-50142 -1.001339e+00    NaN\n",
       " CC_h        16-50142  1.549455e-01    NaN\n",
       " CC_i        16-50142 -1.633388e-04    NaN\n",
       " CC_j        16-50142  3.716101e-05    NaN\n",
       " CC_pa0      16-50142 -6.679744e-02    NaN\n",
       " CC_pa1      16-50142  4.836685e-04    NaN\n",
       " CC_pa2      16-50142 -3.215211e-12    NaN\n",
       " CC_ptca0    16-50142  5.245713e+05    NaN\n",
       " CC_ptca1    16-50142 -6.453360e+00    NaN\n",
       " CC_ptca2    16-50142  1.189820e-02    NaN\n",
       " CC_ptcb0    16-50142  2.524618e+01    NaN\n",
       " CC_ptcb1    16-50142 -5.764411e-04    NaN\n",
       " CC_ptcb2    16-50142  0.000000e+00    NaN\n",
       " CC_ptempa0  16-50142 -5.590677e+01    NaN\n",
       " CC_ptempa1  16-50142  5.460593e+01    NaN\n",
       " CC_ptempa2  16-50142 -5.909725e-01    NaN,\n",
       " 'cal':               serial         value  notes\n",
       " name                                     \n",
       " CC_a0       16-50142  1.250743e-03    NaN\n",
       " CC_a1       16-50142  2.729980e-04    NaN\n",
       " CC_a2       16-50142 -8.672512e-07    NaN\n",
       " CC_a3       16-50142  1.722119e-07    NaN\n",
       " CC_cpcor    16-50142 -9.570000e-08    NaN\n",
       " CC_ctcor    16-50142  3.250000e-06    NaN\n",
       " CC_g        16-50142 -1.001339e+00    NaN\n",
       " CC_h        16-50142  1.549455e-01    NaN\n",
       " CC_i        16-50142 -1.633388e-04    NaN\n",
       " CC_j        16-50142  3.716101e-05    NaN\n",
       " CC_pa0      16-50142 -6.679744e-02    NaN\n",
       " CC_pa1      16-50142  4.836685e-04    NaN\n",
       " CC_pa2      16-50142 -3.215211e-12    NaN\n",
       " CC_ptca0    16-50142  5.245713e+05    NaN\n",
       " CC_ptca1    16-50142 -6.453360e+00    NaN\n",
       " CC_ptca2    16-50142  1.189820e-02    NaN\n",
       " CC_ptcb0    16-50142  2.524618e+01    NaN\n",
       " CC_ptcb1    16-50142 -5.764411e-04    NaN\n",
       " CC_ptcb2    16-50142  0.000000e+00    NaN\n",
       " CC_ptempa0  16-50142 -5.590677e+01    NaN\n",
       " CC_ptempa1  16-50142  5.460593e+01    NaN\n",
       " CC_ptempa2  16-50142 -5.909725e-01    NaN,\n",
       " 'xml':               serial         value  notes\n",
       " name                                     \n",
       " CC_a0       16-50142  1.250743e-03    NaN\n",
       " CC_a1       16-50142  2.729980e-04    NaN\n",
       " CC_a2       16-50142 -8.672512e-07    NaN\n",
       " CC_a3       16-50142  1.722119e-07    NaN\n",
       " CC_cpcor    16-50142 -9.570000e-08    NaN\n",
       " CC_ctcor    16-50142  3.250000e-06    NaN\n",
       " CC_g        16-50142 -1.001339e+00    NaN\n",
       " CC_h        16-50142  1.549455e-01    NaN\n",
       " CC_i        16-50142 -1.633388e-04    NaN\n",
       " CC_j        16-50142  3.716101e-05    NaN\n",
       " CC_pa0      16-50142 -6.679744e-02    NaN\n",
       " CC_pa1      16-50142  4.836685e-04    NaN\n",
       " CC_pa2      16-50142 -3.215211e-12    NaN\n",
       " CC_ptca0    16-50142  5.245713e+05    NaN\n",
       " CC_ptca1    16-50142 -6.453360e+00    NaN\n",
       " CC_ptca2    16-50142  1.189820e-02    NaN\n",
       " CC_ptcb0    16-50142  2.524618e+01    NaN\n",
       " CC_ptcb1    16-50142 -5.764411e-04    NaN\n",
       " CC_ptcb2    16-50142  0.000000e+00    NaN\n",
       " CC_ptempa0  16-50142 -5.590677e+01    NaN\n",
       " CC_ptempa1  16-50142  5.460593e+01    NaN\n",
       " CC_ptempa2  16-50142 -5.909725e-01    NaN,\n",
       " 'qct':               serial         value  notes\n",
       " name                                     \n",
       " CC_a0       16-50142  1.250743e-03    NaN\n",
       " CC_a1       16-50142  2.729980e-04    NaN\n",
       " CC_a2       16-50142 -8.672512e-07    NaN\n",
       " CC_a3       16-50142  1.722119e-07    NaN\n",
       " CC_cpcor    16-50142 -9.570000e-08    NaN\n",
       " CC_ctcor    16-50142  3.250000e-06    NaN\n",
       " CC_g        16-50142 -1.001339e+00    NaN\n",
       " CC_h        16-50142  1.549455e-01    NaN\n",
       " CC_i        16-50142 -1.633388e-04    NaN\n",
       " CC_j        16-50142  3.716101e-05    NaN\n",
       " CC_pa0      16-50142 -6.679745e-02    NaN\n",
       " CC_pa1      16-50142  4.836685e-04    NaN\n",
       " CC_pa2      16-50142 -3.215211e-12    NaN\n",
       " CC_ptca0    16-50142  5.245713e+05    NaN\n",
       " CC_ptca1    16-50142 -6.453360e+00    NaN\n",
       " CC_ptca2    16-50142  1.189820e-02    NaN\n",
       " CC_ptcb0    16-50142  2.524618e+01    NaN\n",
       " CC_ptcb1    16-50142 -5.764411e-04    NaN\n",
       " CC_ptcb2    16-50142  0.000000e+00    NaN\n",
       " CC_ptempa0  16-50142 -5.590677e+01    NaN\n",
       " CC_ptempa1  16-50142  5.460593e+01    NaN\n",
       " CC_ptempa2  16-50142 -5.909725e-01    NaN}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = check_cal_coeffs(coeffs_dict)\n",
    "incorrect = coeffs_dict['csv'][mask == False]\n",
    "\n",
    ".reset_index()\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = pd.read_csv('/'.join((asset_management_directory,df_files.loc[indices[0]].loc['csv'])))\n",
    "CSV.set_index(keys='name',inplace=True)\n",
    "CSV.sort_index(inplace=True)\n",
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QCT = pd.read_csv('/'.join((os.getcwd(),'temp','qct',df_files.loc[indices[0]].loc['qct'])))\n",
    "QCT.set_index(keys='name',inplace=True)\n",
    "QCT.sort_index(inplace=True)\n",
    "QCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XML = pd.read_csv('/'.join((os.getcwd(),'temp','xml',df_files.loc[indices[0]].loc['xml'])))\n",
    "XML.set_index(keys='name',inplace=True)\n",
    "XML.sort_index(inplace=True)\n",
    "XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_xml = np.isclose(CSV['value'],XML['value'])\n",
    "csv_qct = np.isclose(CSV['value'],QCT['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (csv_xml | csv_qct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV[mask == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I need to load the all of the csv files based on their UID\n",
    "def load_csv_info(csv_dict,filepath):\n",
    "    \"\"\"\n",
    "    Loads the calibration coefficient information contained in asset management\n",
    "    \n",
    "    Args:\n",
    "        csv_dict - a dictionary which associates an instrument UID to the\n",
    "            calibration csv files in asset management\n",
    "        filepath - the path to the directory containing the calibration csv files\n",
    "    Returns:\n",
    "        csv_cals - a dictionary which associates an instrument UID to a pandas\n",
    "            dataframe which contains the calibration coefficients. The dataframes\n",
    "            are indexed by the date of calibration\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the calibration data into pandas dataframes, which are then placed into\n",
    "    # a dictionary by the UID\n",
    "    csv_cals = {}\n",
    "    for uid in csv_dict:\n",
    "        cals = pd.DataFrame()\n",
    "        for file in csv_dict[uid]:\n",
    "            data = pd.read_csv(filepath+file)\n",
    "            date = file.split('__')[1].split('.')[0]\n",
    "            data['CAL DATE'] = pd.to_datetime(date)\n",
    "            cals = cals.append(data)\n",
    "        csv_cals.update({uid:cals})\n",
    "        \n",
    "    # Pivot the dataframe to be sorted based on calibration date\n",
    "    for uid in csv_cals:\n",
    "        csv_cals[uid] = csv_cals[uid].pivot(index=csv_cals[uid]['CAL DATE'], columns='name')['value']\n",
    "        \n",
    "    return csv_cals\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have successfully loaded the csv calibrations into a pandas dataframe that allows for easy comparison between calibrations based on the calibration date for each calibration coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the QCT values\n",
    "The next step is to take the capture files from the QCT and load them into a comparable pandas dataframe. This involves several steps:\n",
    "* Get the QCT document numbers from the WHOI Asset Tracking Sheet for each individual instrument\n",
    "* Find where the QCT documents are stored\n",
    "* Load the QCT documents\n",
    "* Parse the QCT documents\n",
    "* Translate the parsed QCT values into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = sorted( list( set( CTDBPP['UID'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_dict = {}\n",
    "for uid in uids:\n",
    "    # Get the QCT Document numbers from the asset tracking sheet\n",
    "    CTDBPP['UID_match'] = CTDBPP['UID'].apply(lambda x: True if uid in x else False)\n",
    "    qct_series = CTDBPP[CTDBPP['UID_match'] == True]['QCT Testing']\n",
    "    qct_series = list(qct_series.iloc[0].split('\\n'))\n",
    "    qct_dict.update({uid:qct_series})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try building a function to do the file path generator\n",
    "def generate_file_path(dirpath,filename,ext=['.cap','.txt','.log'],exclude=['_V','_Data_Workshop']):\n",
    "    \"\"\"\n",
    "    Function which searches for the location of the given file and returns\n",
    "    the full path to the file.\n",
    "    \n",
    "    Args:\n",
    "        dirpath - parent directory path under which to search\n",
    "        filename - the name of the file to search for\n",
    "        ext - \n",
    "        exclude - optional list which allows for excluding certain\n",
    "            directories from the search\n",
    "    Returns:\n",
    "        fpath - the file path to the filename from the current\n",
    "            working directory.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(dirpath):\n",
    "        dirs[:] = [d for d in dirs if d not in exclude]\n",
    "        for fname in files:\n",
    "            if fnmatch.fnmatch(fname, [filename+'*'+x for x in ext]):\n",
    "                fpath = os.path.join(root, fname)\n",
    "                return fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD = CTDCalibration(uid=uids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.load_qct(qct_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_filepath = generate_file_path(dirpath,qcts[0])\n",
    "qct_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD = CTDCalibration(uid=uids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.load_qct('/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Instrument_Records/3305-00102-00019-A.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(dirpath):\n",
    "    dirs[:] = [d for d in dirs if d not in exclude]\n",
    "    for fname in files:\n",
    "        if fnmatch.fnmatch(fname, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to develop an automated approach to load all the QCT documents, parse them\n",
    "# into a dictionary, and convert the dictionary into a pandas dataframe\n",
    "def load_qct_data(qct_dict,coefficient_name_map,dirpath='../../../Documents/Project_Files/'):\n",
    "    qct = {}\n",
    "    qct_missing = {}\n",
    "    for uid in qct_dict:\n",
    "        print(uid)\n",
    "        capture_data = {}\n",
    "        missing = []\n",
    "        for capfile in qct_dict[uid]:\n",
    "            # First, find and return the path to the capture file which\n",
    "            # matches the capture file indentifier\n",
    "            cappath = generate_file_path(dirpath, capfile)\n",
    "            \n",
    "            # Function to pull out the coefficients from the capture files. This is a naive implementation\n",
    "            # and splits only on either a \":\" or \"=\", it doesn't do any comprehension of the file\n",
    "            if cappath is None:\n",
    "                missing.append(capfile)\n",
    "            else:\n",
    "                coeffs = {}\n",
    "                with open(cappath) as filename:\n",
    "                    data = filename.read()\n",
    "                    for line in data.splitlines():\n",
    "                        items = re.split(': | =',line)\n",
    "                        key = items[0].strip()\n",
    "                        value = items[-1].strip()\n",
    "                        coeffs.update({key:value})\n",
    "                    \n",
    "                # The best way to do this is to use the CTD name mapping to only get the important values\n",
    "                capture = {}\n",
    "                # With the capture coefficients, now map it to the CTD coefficients\n",
    "                for key in coeffs.keys():\n",
    "                    if key in coefficient_name_map.keys():\n",
    "                        capture[coefficient_name_map[key]] = coeffs[key]\n",
    "            \n",
    "                # Get the calibration date\n",
    "                caldate = coeffs['conductivity']\n",
    "            \n",
    "                # Update the capture file to include the calibration date\n",
    "                capture['CAL DATE'] = pd.to_datetime(caldate)\n",
    "            \n",
    "                # Now, update the parent dictionary\n",
    "                capture_data.update({capfile:capture})\n",
    "            \n",
    "        df = pd.DataFrame.from_dict({i: capture_data[i] for i in capture_data.keys()}, orient='index')\n",
    "        qct.update({uid:df})\n",
    "        qct_missing.update({uid:missing})\n",
    "        \n",
    "    return qct, qct_missing   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct, qct_missing = load_qct_data(qct_dict,coefficient_name_map,dirpath='../../../../Documents/Project_Files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to the calibration date\n",
    "for uid in qct:\n",
    "    qct[uid].set_index('CAL DATE', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vendor Calibration values: .cal and .xmlcon\n",
    "This next step is to load the CTD .cal and .xmlcon files in order to compare the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_nums = get_serial_nums(CTDBPC, uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vendor_files = {}\n",
    "for uid,sn in serial_nums.items():\n",
    "    files = []\n",
    "    for file in os.listdir('../../../../Documents/Project_Files/Records/Instrument_Records/CTDBP/'):\n",
    "        if sn in file:\n",
    "            if 'Calibration_File' in file:\n",
    "                files.append(file)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    vendor_files.update({uid:files})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_dict = get_calibration_files(serial_nums,'/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Instrument_Records/CTDBP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = {}\n",
    "cal_missing = {}\n",
    "filepath = '../../../../Documents/Project_Files/Records/Instrument_Records/CTDBP/'\n",
    "for uid,files in vendor_files.items():\n",
    "    cal_coeffs, missing = load_cal_coeffs(files,filepath,coefficient_name_map,o2_coefficients_map)\n",
    "    cal_df = pd.DataFrame.from_dict({i: cal_coeffs[i] for i in cal_coeffs.keys()}, orient='index')\n",
    "    cal_df.index = pd.to_datetime(cal_df.index)\n",
    "    cal.update({uid:cal_df})\n",
    "    cal_missing.update({uid:missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the above process with the .xmlcon file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = {}\n",
    "xml_missing = {}\n",
    "filepath = '../../../../Documents/Project_Files/Records/Instrument_Records/CTDBP/'\n",
    "for uid,files in vendor_files.items():\n",
    "    xml_coeffs, missing = load_xml_coeffs(files,filepath,coefficient_name_map,o2_coefficients_map)\n",
    "    xml_df = pd.DataFrame.from_dict({i: xml_coeffs[i] for i in xml_coeffs.keys()}, orient='index')\n",
    "    xml_df.drop(columns=[None],axis=1,inplace=True)\n",
    "    xml_df.index = pd.to_datetime(xml_df.index)\n",
    "    xml.update({uid:xml_df})\n",
    "    xml_missing.update({uid:missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons\n",
    "Now that I have .cal, .xmlcon, the qct capture files, and the csv files from asset management, I can begin comparison of the calibration coefficients between the different files. The goal is that the dates, values, and coefficients all match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I need to reindex all of the different dataframes such that they all have two indices:\n",
    "# A dataset index and a datetime index, and set them to uniform name (for concatenation)\n",
    "for uid in uids:\n",
    "    try:\n",
    "        CSV[uid]['Dataset'] = 'CSV'\n",
    "        CSV[uid].set_index(['Dataset',CSV[uid].index],inplace=True)\n",
    "        CSV[uid].index.set_names(['Dataset','Cal Date'],inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in uids:\n",
    "    qct[uid]['Dataset'] = 'QCT'\n",
    "    qct[uid].set_index(['Dataset',qct[uid].index],inplace=True)\n",
    "    qct[uid].index.set_names(['Dataset','Cal Date'],inplace=True)\n",
    "qct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in uids:\n",
    "    cal[uid]['Dataset'] = 'CAL'\n",
    "    cal[uid].set_index(['Dataset',cal[uid].index],inplace=True)\n",
    "    cal[uid].index.set_names(['Dataset','Cal Date'],inplace=True)\n",
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in uids:\n",
    "    xml[uid]['Dataset'] = 'XML'\n",
    "    xml[uid].set_index(['Dataset',xml[uid].index],inplace=True)\n",
    "    xml[uid].index.set_names(['Dataset','Cal Date'],inplace=True)\n",
    "xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All four possible sources of calibration coefficients available for an instrument - the calibration **CSV** loaded into asset management, the calibration coefficients loaded onto the instrument during check-in (**QCT**), the **.cal** file provided by the vendor, and the **XML** file provided by the vendor. \n",
    "\n",
    "The next step is to concatenate the different instruments into a single dataframe and to sort by calibration date. This will allow for comparison based on the date of the calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = {}\n",
    "for uid in uids:\n",
    "    comparison.update({uid:pd.concat([CSV.get(uid), cal.get(uid), xml.get(uid), qct.get(uid)])})\n",
    "    comparison[uid].reset_index(level='Cal Date',inplace=True)\n",
    "    comparison[uid].sort_values(by='Cal Date',inplace=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_type(x):\n",
    "    if type(x) is str:\n",
    "        return float(x)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in uids:\n",
    "    comparison[uid] = comparison[uid].applymap(convert_type)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_the_same(elements):\n",
    "    \"\"\"\n",
    "    This function checks which values in an array are all the same.\n",
    "    \n",
    "    Args:\n",
    "        elements - an array of values\n",
    "    Returns:\n",
    "        error - an array of length (m-1) which checks if\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(elements) < 1:\n",
    "        return True\n",
    "    el = iter(elements)\n",
    "    first = next(el, None)\n",
    "    #check = [element == first for element in el]\n",
    "    error = [np.isclose(element,first) for element in el]\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_cal_error(array):\n",
    "    \"\"\"\n",
    "    This function locates which source file (e.g. xmlcon vs csv vs cal)\n",
    "    have calibration values that are different from the others. It does\n",
    "    NOT identify which is correct, only which is different.\n",
    "    \n",
    "    Args:\n",
    "        array - A numpy array which contains the values for a specific\n",
    "                calibration coefficient for a specific date from all of\n",
    "                the calibration source files\n",
    "    Returns:\n",
    "        dataset - a list containing which calibration sources are different\n",
    "                from the other files\n",
    "        True - if all of the calibration values are the same\n",
    "        False - if the first calibration value is different\n",
    "    \"\"\"\n",
    "    # Call the function to check if there are any differences between each of\n",
    "    # calibration values from the different sheets\n",
    "    error = all_the_same(array)\n",
    "    # If they are all the same, return True\n",
    "    if all(error):\n",
    "        return True\n",
    "    # If there is a mixture of True/False, find the false and return them\n",
    "    elif any(error) == True:\n",
    "        indices = [i+1 for i, j in enumerate(error) if j == False]\n",
    "        dataset = list(array.index[indices])\n",
    "        return dataset\n",
    "    # Last, if all are false, that means the first value \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With all the functions set up, now go through all of the data\n",
    "def search_for_errors(df):\n",
    "    \"\"\"\n",
    "    This function is designed to search through a pandas dataframe\n",
    "    which contains all of the calibration coefficients from all of\n",
    "    the files, and check for differences.\n",
    "    \n",
    "    Args: \n",
    "        df - A dataframe which contains all fo the calibration coefficients\n",
    "        from the asset management csv, qct checkout, and the vendor\n",
    "        files (.cal and .xmlcon)\n",
    "    Returns:\n",
    "        cal_errors - A nested dictionary containing the calibration timestamp, the\n",
    "        relevant calibration coefficient, and which file(s) have the\n",
    "        erroneous calibration file.\n",
    "    \"\"\"\n",
    "    \n",
    "    cal_errors = {}\n",
    "    for date in np.unique(df['Cal Date']):\n",
    "        df2 = df[df['Cal Date'] == date]\n",
    "        wrong_cals = {}\n",
    "        for column in df2.columns.values:\n",
    "            array = df2[column]\n",
    "            array.sort_index()\n",
    "            if array.dtype == 'datetime64[ns]':\n",
    "                pass\n",
    "            else:\n",
    "                error = locate_cal_error(array)\n",
    "                if error == False:\n",
    "                    wrong_cals.update({column:array.index[0]})\n",
    "                elif error == True:\n",
    "                    pass\n",
    "                else:\n",
    "                    wrong_cals.update({column:error})\n",
    "        \n",
    "        if len(wrong_cals) < 1:\n",
    "            cal_errors.update({str(date).split('T')[0]:'No Errors'})\n",
    "        else:\n",
    "            cal_errors.update({str(date).split('T')[0]:wrong_cals})\n",
    "    \n",
    "    return cal_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_errors = {}\n",
    "for uid in uids:\n",
    "    ce = search_for_errors(comparison[uid])\n",
    "    cal_errors.update({uid:ce})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(cal_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame.from_dict({i: cal_errors[i] for i in cal_errors.keys()}, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('CTDBPP_Errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataframe of the missing files\n",
    "df_missing = pd.DataFrame(index=uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing['.CAL FILES'] = cal_missing.values()\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing['.XML FILES'] = xml_missing.values()\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing['.QCT FILES'] = qct_missing.values()\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing.to_csv('CTDBPP_Missing_Files.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check which CTDBP-C Calibration files are not correctly named\n",
    "In order to check the calibration values, need to have the correctly named calibration csv files. We can check this by comparison of deployment dates with the CTDBPC calibration dates. This requires loading both the deployment csv and parsing all the file names, flagging the file names THAT MATCH, and then revisiting them in order to correct the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the deployment csvs fo\n",
    "# Parse for all WHOI CG Deployment Sheets based on 'CP' or CG\n",
    "# Easier to check for non-CG \n",
    "deploy_csvs = []\n",
    "for file in os.listdir('../../GitHub/OOI-Integration/asset-management/deployment/'):\n",
    "    if file[0:2] == 'RS' or file[0:2] == 'CE':\n",
    "        pass\n",
    "    elif 'MOAS' in file:\n",
    "        pass\n",
    "    else:\n",
    "        deploy_csvs.append(file)\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Deployment History from the WHOI Asset Tracking System\n",
    "CTDBPF_Deploy = CTDBPF['Deployment History']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDBPF_Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the string at the newline to generate a list of deployments for each CTDBP-C\n",
    "CTDBPF_Deploy = CTDBPF['Deployment History'].apply(lambda x: x.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDBPF_Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all the individual deployments\n",
    "deploy_list = []\n",
    "for i in range(0,len(CTDBPF_Deploy)):\n",
    "    for item in CTDBPF_Deploy.iloc[i]:\n",
    "        if '-' in item:\n",
    "            deploy_list.append(item)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So I now have a list of the deployments all the CTDBP-Cs were used on.\n",
    "# Now, parse the name of the array to\n",
    "array = list( set( [x.split('-')[0] for x in deploy_list] ) )\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the list of array names, I can now parse the deployment file names to find\n",
    "# the relevant deployment sheets which match where the CTDBP-Cs were deployed\n",
    "deploy_csvs = []\n",
    "for file in os.listdir('../../GitHub/OOI-Integration/asset-management/deployment/'):\n",
    "    if file.split('_')[0] in array:\n",
    "        deploy_csvs.append(file)\n",
    "deploy_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the identified deployment csvs, can now load the deployment csvs into\n",
    "# a pandas dataframe\n",
    "deployments = pd.DataFrame()\n",
    "for file in deploy_csvs:\n",
    "    deployments = deployments.append(pd.read_csv('../../GitHub/OOI-Integration/asset-management/deployment/'+file))\n",
    "deployments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the CTDBPF sensor uids\n",
    "sensor_uids = list( set( CTDBPF['UID'] ) )\n",
    "sensor_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find in the deployment spreadsheets the matching entry for the CTDBP-Cs that I'm looking for\n",
    "deployments['CTDBPF'] = deployments['sensor.uid'].apply(lambda x: True if x in sensor_uids else False)\n",
    "deployments = deployments[deployments['CTDBPF'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, parse out the date string in the format of YYYYMMDD from the startDateTime\n",
    "# in order to compare with the date in the calibration file names\n",
    "deploy_dates = deployments['startDateTime'].apply(lambda x: x.replace('-','').split('T')[0])\n",
    "deploy_dates = list(set(deploy_dates))\n",
    "deploy_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_csvs = []\n",
    "for file in os.listdir('../../GitHub/OOI-Integration/asset-management/calibration/CTDBPF/'):\n",
    "    date = file.split('__')[1].split('.')[0]\n",
    "    print(date)\n",
    "    if date in deploy_dates:\n",
    "        cal_csvs = cal_csvs.append(file)\n",
    "print(cal_csvs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! None of the CTDBP-C have calibration dates which match deployment dates. That is a good sign - it means that the dates in the calibration file name *should* match the calibration dates in the calibration info.\n",
    "\n",
    "However, that is no guarantee that the date in the file name matches the date in the calibration data. This can be check in a future step by comparing the calibration date in the vendor docs, QCT info, and the .cal and .xmlcon file info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, using the \"deploy\" csvs for each node in the various arrays,\n",
    "# need to load into a large pandas dataframe for easy handling\n",
    "import pandas as pd\n",
    "\n",
    "deployments = pd.DataFrame()\n",
    "for file in deploy_csvs:\n",
    "    deployments = deployments.append(pd.read_csv('../GitHub/OOI-Integration/asset-management/deployment/'+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique deployment dates from the deployment csvs and put into the form of \n",
    "# YYYYMMDD. \n",
    "deploy_dates = deployments['startDateTime'].apply(lambda x: x.split('T')[0].replace('-',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_dates = list(set(deploy_dates))\n",
    "deploy_dates[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deploy_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_files = []\n",
    "for root, dirs, files in os.walk('../GitHub/OOI-Integration/asset-management/calibration/'):\n",
    "    for name in files:\n",
    "        if 'CGINS' in name:\n",
    "            cal_date = name.split('__')[1].split('.')[0]\n",
    "            if cal_date in deploy_dates:\n",
    "                check_files.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, there are a potential 1364 files that we need to check on the\n",
    "# calibration date in the file name, because the parsed date in the \n",
    "# file name matches a deployment date.\n",
    "len(list(set(check_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool, now save the file to the local working directory\n",
    "with open('calibration_files_to_check.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(check_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
