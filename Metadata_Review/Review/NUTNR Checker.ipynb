{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUTNRB Checker\n",
    "\n",
    "This notebook is designed to check the NUTNR csv calibration file in pull request. The process I follow is:\n",
    "1. Read in the NUTNR csv from the pull request into a pandas dataframe\n",
    "2. Identify the source file of the calibration coefficients\n",
    "3. Parse the calibration coefficients directly from the source file\n",
    "4. Compare the NUTNR csv from the pull request with the csv parsed from the source file\n",
    "\n",
    "**====================================================================================================================**\n",
    "\n",
    "The first step is to load relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Calibration/Parsers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parsers.NUTNRCalibration import NUTNRCalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "Define the directories where the **csv** file to check is stored, and where the **source** file is stored. Make sure to check the following information on your machine via your terminal first:\n",
    "1. The branch of your local asset-management repository matches the location of the OPTAA cals.\n",
    "2. Your local asset-management repository has the requisite **csv** file to check\n",
    "3. You have downloaded the **source** of the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_directory = '/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Instrument_Records/NUTNR/NUTNR_Results/'\n",
    "cal_directory = '/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Instrument_Records/NUTNR/NUTNR_Cal/'\n",
    "asset_management_directory = '/home/andrew/Documents/OOI-CGSN/ooi-integration/asset-management/calibration/NUTNRB/'\n",
    "glider_directory = '/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Platform_Records/Gliders/Instruments/NUTNR-M/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(glider_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_spreadsheet = '/media/andrew/OS/Users/areed/Documents/Project_Files/Documentation/System/System Notebook/WHOI_Asset_Tracking.xlsx'\n",
    "sheet_name = 'Sensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTNR = whoi_asset_tracking(spreadsheet=excel_spreadsheet,sheet_name=sheet_name,instrument_class='NUTNR',series='B')\n",
    "NUTNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "### Find & Parse the source file\n",
    "Now, we want to find the source file of the calibration coefficients, parse the data using the optaa parser, and read the data into a pandas dataframe. The key pieces of data needed for the parser are:\n",
    "1. Instrument UID: This is needed to initialize the OPTAA parser\n",
    "2. Source file: This is the full path to the source file. Zip files are acceptable input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the predeployment file is not listed in asset tracking, need to hunt through all the predeployment files for the possible candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(doc_directory) if 'A' in file]\n",
    "pre_files = []\n",
    "for file in files:\n",
    "    if '308' in file or '327' in file:\n",
    "        pre_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_paths = []\n",
    "predeployment = {}\n",
    "for file in pre_files:\n",
    "    path = generate_file_path(doc_directory, file, ext=['.zip'])\n",
    "    with ZipFile(path) as zfile:\n",
    "        cal_files = [file for file in zfile.namelist() if file.lower().endswith('.cal')]\n",
    "        if len(cal_files) > 0:\n",
    "            data = zfile.read(cal_files[0]).decode('ascii')\n",
    "            lines = data.splitlines()\n",
    "            _, items, *ignore = lines[0].split(',')\n",
    "            inst, sn, *ignore = items.split()\n",
    "            sn = sn.lstrip('0')\n",
    "            if inst == 'SUNA':\n",
    "                sn = 'NTR-'+sn\n",
    "    if predeployment.get(sn) is None:\n",
    "        predeployment.update({sn: [file]})\n",
    "    else:\n",
    "        predeployment[sn].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predeployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = '1063'\n",
    "file = predeployment.get(sn)\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_path = generate_file_path(doc_directory, file[0], ['.zip'])\n",
    "pre_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(cal_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(doc_directory):\n",
    "    if '3305-00327-00059-A' in file:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = '367'\n",
    "filepath = doc_directory + '/' + '3305-00327-00059-A.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutnr = NUTNRCalibration('CGINS-NUTNRM-'+sn.zfill(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the calibration coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutnr.load_cal(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutnr.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the csv to a temporary local folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_directory = '/'.join((os.getcwd(),'temp'))\n",
    "# Check if the temp directory exists; if it already does, purge and rewrite\n",
    "if os.path.exists(temp_directory):\n",
    "    shutil.rmtree(temp_directory)\n",
    "    ensure_dir(temp_directory)\n",
    "else:\n",
    "    ensure_dir(temp_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutnr.write_csv(temp_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nutnr.uid, nutnr.serial, nutnr.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutnr.source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "### Check the data\n",
    "Now, we have generated local csv and ext files from the data. We can now reload that data into python as a pandas dataframe, which will allow for a direct comparison with the existing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_arrays(array):\n",
    "    # First, need to strip extraneous characters from the array\n",
    "    array = array.replace(\"'\",\"\").replace('[','').replace(']','')\n",
    "    # Next, split the array into a list\n",
    "    array = array.split(',')\n",
    "    # Now, need to eliminate any white space surrounding the individual coeffs\n",
    "    array = [num.strip() for num in array]\n",
    "    # Next, float the nums\n",
    "    array = [float(num) for num in array]\n",
    "    # Check if the array is len == 1; if so, can just return the number\n",
    "    if len(array) == 1:\n",
    "        array = array[0]\n",
    "    # Now we are done\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sn = nutnr.serial.zfill(5)\n",
    "dt = max(nutnr.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv = pd.read_csv(temp_directory+'/CGINS-NUTNRM-00367'+'__'+dt+'.csv')\n",
    "source_csv['value'] = source_csv['value'].apply(lambda x: reformat_arrays(x))\n",
    "#source_csv['serial'] = 1029\n",
    "source_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/andrew/Documents/OOI-CGSN/asset-management/calibration/NUTNRN/CGINS-NUTNRN-00367__20190327.csv'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_csv = pd.read_csv(path)\n",
    "am_csv['value'] = am_csv['value'].apply(lambda x: reformat_arrays(x))\n",
    "am_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_csv['notes'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv['notes'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv == am_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for k,val in enumerate(am_csv['value'].iloc[1]):\n",
    "    check = source_csv['value'].iloc[1][k] == val\n",
    "    if not check:\n",
    "        result.update({k:val})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for k,val in enumerate(am_csv['value'].iloc[3]):\n",
    "    check = source_csv['value'].iloc[3][k] == val\n",
    "    if not check:\n",
    "        result.update({k:val})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv['value'].iloc[0] - am_csv['value'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "class NUTNRCalibration():\n",
    "    # Class that stores calibration values for CTDs.\n",
    "\n",
    "    def __init__(self, uid):\n",
    "        self.serial = None\n",
    "        self.uid = uid\n",
    "        self.coefficients = {\n",
    "            'CC_cal_temp':[],\n",
    "            'CC_di':[],\n",
    "            'CC_eno3':[],\n",
    "            'CC_eswa':[],\n",
    "            'CC_lower_wavelength_limit_for_spectra_fit':'217',\n",
    "            'CC_upper_wavelength_limit_for_spectra_fit':'240',\n",
    "            'CC_wl':[]\n",
    "        }\n",
    "        self.date = []\n",
    "        self.notes = {\n",
    "            'CC_cal_temp':'',\n",
    "            'CC_di':'',\n",
    "            'CC_eno3':'',\n",
    "            'CC_eswa':'',\n",
    "            'CC_lower_wavelength_limit_for_spectra_fit':'217',\n",
    "            'CC_upper_wavelength_limit_for_spectra_fit':'240',\n",
    "            'CC_wl':''\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def uid(self):\n",
    "        return self._uid\n",
    "\n",
    "    @uid.setter\n",
    "    def uid(self, d):\n",
    "        r = re.compile('.{5}-.{6}-.{5}')\n",
    "        if r.match(d) is not None:\n",
    "            self._uid = d\n",
    "        else:\n",
    "            raise Exception(f\"The instrument uid {d} is not a valid uid. Please check.\")\n",
    "            \n",
    "    def load_cal(self, filepath):\n",
    "        \"\"\"\n",
    "        Wrapper function to load all of the calibration coefficients\n",
    "        \n",
    "        Args:\n",
    "            filepath - path to the directory with filename which has the\n",
    "                calibration coefficients to be parsed and loaded\n",
    "        Calls:\n",
    "            open_cal\n",
    "            parse_cal\n",
    "        \"\"\"\n",
    "        \n",
    "        data = self.open_cal(filepath)\n",
    "        \n",
    "        self.parse_cal(data)\n",
    "    \n",
    "    \n",
    "    def open_cal(self, filepath):\n",
    "        \"\"\"\n",
    "        Function that opens and reads in cal file\n",
    "        information for a NUTNR. Zipfiles are acceptable inputs.\n",
    "        \"\"\"\n",
    "        \n",
    "        if filepath.endswith('.zip'):\n",
    "            with ZipFile(filepath) as zfile:\n",
    "                # Check if ISUS or SUNA to get the appropriate name\n",
    "                filename = [name for name in zfile.namelist()\n",
    "                            if name.lower().endswith('.cal') and 'z' not in name.lower()]\n",
    "                \n",
    "                # Get and open the latest calibration file\n",
    "                if len(filename) == 1:\n",
    "                    data = zfile.read(filename[0]).decode('ascii')\n",
    "                    self.source_file(filepath, filename[0])\n",
    "                    \n",
    "                elif len(filename) > 1:\n",
    "                    filename = [max(filename)]\n",
    "                    data = zfile.read(filename[0]).decode('ascii')\n",
    "                    self.source_file(filepath, filename[0])\n",
    "\n",
    "                else:\n",
    "                    FileExistsError(f\"No .cal file found in {filepath}\")\n",
    "                        \n",
    "        elif filepath.lower().endswith('.cal'):\n",
    "            if 'z' not in filepath.lower().split('/')[-1]:\n",
    "                with open(filepath) as file:\n",
    "                    data = file.read()\n",
    "                self.source_file(filepath, file)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        return data\n",
    "            \n",
    "        \n",
    "    def source_file(self, filepath, filename):\n",
    "        \"\"\"\n",
    "        Routine which parses out the source file and filename\n",
    "        where the calibration coefficients are sourced from.\n",
    "        \"\"\"\n",
    "        \n",
    "        if filepath.lower().endswith('.cal'):\n",
    "            dcn = filepath.split('/')[-2]\n",
    "            filename = filepath.split('/')[-1]\n",
    "        else:\n",
    "            dcn = filepath.split('/')[-1]\n",
    "        \n",
    "        self.source = f'Source file: {dcn} > {filename}'\n",
    "        \n",
    "    \n",
    "    def parse_cal(self, data):\n",
    "        \n",
    "        for k,line in enumerate(data.splitlines()):\n",
    "            \n",
    "            if line.startswith('H'):\n",
    "                _, info, *ignore = line.split(',')\n",
    "                \n",
    "                # The first line of the cal file contains the serial number\n",
    "                if k == 0:\n",
    "                    _, sn, *ignore = info.split()\n",
    "                    if 'SUNA' in info:\n",
    "                        self.serial = 'NTR-' + sn\n",
    "                    else:\n",
    "                        self.serial = sn\n",
    "                    \n",
    "                \n",
    "                # File creation time is when the instrument was calibrated.\n",
    "                # May be multiple times for different cal coeffs\n",
    "                if 'file creation time' in info.lower():\n",
    "                    _, _, _, date, time = info.split()\n",
    "                    date_time = pd.to_datetime(date + ' ' + time).strftime('%Y%m%d')\n",
    "                    self.date.append(date_time)\n",
    "                    \n",
    "                # The temperature at which it was calibrated\n",
    "                if 't_cal_swa' in info.lower() or 't_cal' in info.lower():\n",
    "                    _, cal_temp = info.split()\n",
    "                    self.coefficients['CC_cal_temp'] = cal_temp\n",
    "                    \n",
    "            # Now parse the calibration coefficients\n",
    "            if line.startswith('E'):\n",
    "                _, wl, eno3, eswa, _, di = line.split(',')\n",
    "                \n",
    "                self.coefficients['CC_wl'].append(float(wl))\n",
    "                self.coefficients['CC_di'].append(float(di))\n",
    "                self.coefficients['CC_eno3'].append(float(eno3))\n",
    "                self.coefficients['CC_eswa'].append(float(eswa))\n",
    "                \n",
    "                \n",
    "    def write_csv(self, outpath):\n",
    "        \"\"\"\n",
    "        This function writes the correctly named csv file for the ctd to the\n",
    "        specified directory.\n",
    "\n",
    "        Args:\n",
    "            outpath - directory path of where to write the csv file\n",
    "        Raises:\n",
    "            ValueError - raised if the CTD object's coefficient dictionary\n",
    "                has not been populated\n",
    "        Returns:\n",
    "            self.to_csv - a csv of the calibration coefficients which is\n",
    "                written to the specified directory from the outpath.\n",
    "        \"\"\"\n",
    "\n",
    "        # Run a check that the coefficients have actually been loaded\n",
    "        if len(self.coefficients.values()) <= 2:\n",
    "            raise ValueError('No calibration coefficients have been loaded.')\n",
    "\n",
    "        # Create a dataframe to write to the csv\n",
    "        data = {\n",
    "            'serial': [self.serial]*len(self.coefficients),\n",
    "            'name': list(self.coefficients.keys()),\n",
    "            'value': list(self.coefficients.values())\n",
    "        }\n",
    "        df = pd.DataFrame().from_dict(data)\n",
    "\n",
    "        # Define a function to reformat the notes into an uniform system\n",
    "        def reformat_notes(x):\n",
    "            # First, get rid of \n",
    "            try:\n",
    "                np.isnan(x)\n",
    "                x = ''\n",
    "            except:\n",
    "                x = str(x).replace('[','').replace(']','')\n",
    "            return x\n",
    "        \n",
    "        # Now merge the coefficients dataframe with the notes\n",
    "        if len(self.notes) > 0:\n",
    "            notes = pd.DataFrame().from_dict({\n",
    "                'name':list(self.notes.keys()),\n",
    "                'notes':list(self.notes.values())\n",
    "            })\n",
    "            df = df.merge(notes, how='outer', left_on='name', right_on='name')\n",
    "        else:\n",
    "            df['notes'] = ''\n",
    "            \n",
    "        # Add in the source file\n",
    "        df['notes'].iloc[0] = df['notes'].iloc[0] + ' ' + self.source\n",
    "        \n",
    "        # Sort the data by the coefficient name\n",
    "        df = df.sort_values(by='name')\n",
    "\n",
    "        # Generate the csv name\n",
    "        cal_date = max(self.date)\n",
    "        csv_name = self.uid + '__' + cal_date + '.csv'\n",
    "\n",
    "        # Write the dataframe to a csv file\n",
    "        check = input(f\"Write {csv_name} to {outpath}? [y/n]: \")\n",
    "        # check = 'y'\n",
    "        if check.lower().strip() == 'y':\n",
    "            df.to_csv(outpath+'/'+csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
