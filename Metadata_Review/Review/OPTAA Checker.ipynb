{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTAA Checker\n",
    "\n",
    "This notebook is designed to check the SPKIR csv calibration file in pull request. The process I follow is:\n",
    "1. Read in the OPTAA csv from the pull request into a pandas dataframe\n",
    "2. Identify the source file of the calibration coefficients\n",
    "3. Parse the calibration coefficients directly from the source file\n",
    "4. Compare the OPTAA csv from the pull request with the csv parsed from the source file\n",
    "\n",
    "**====================================================================================================================**\n",
    "\n",
    "The first step is to load relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Calibration/Parsers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parsers.OPTAACalibration import OPTAACalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "Define the directories where the **csv** file to check is stored, and where the **source** file is stored. Make sure to check the following information on your machine via your terminal first:\n",
    "1. The branch of your local asset-management repository matches the location of the OPTAA cals.\n",
    "2. Your local asset-management repository has the requisite **csv** file to check\n",
    "3. You have downloaded the **source** of the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = '/home/andrew/Documents/OOI-CGSN/asset-management/calibration/OPTAAD/'\n",
    "source_dir = '/media/andrew/OS/Users/areed/Documents/Project_Files/Records/Instrument_Records/OPTAA/OPTAA_Cal/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "### Find & Parse the source file\n",
    "Now, we want to find the source file of the calibration coefficients, parse the data using the optaa parser, and read the data into a pandas dataframe. The key pieces of data needed for the parser are:\n",
    "1. Instrument UID: This is needed to initialize the OPTAA parser\n",
    "2. Source file: This is the full path to the source file. Zip files are acceptable input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_name = '257'\n",
    "for file in os.listdir(source_dir):\n",
    "    if source_name in file:\n",
    "        source_file = file\n",
    "        print(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = 'OPTAA-D_AC-S_SN_257_Calibration_Files_2019-06-14.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optaa = OPTAACalibration('CGINS-OPTAAD-00257')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the calibration coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optaa.load_cal(source_dir+source_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the csv to a temporary local folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_directory = '/'.join((os.getcwd(),'temp'))\n",
    "# Check if the temp directory exists; if it already does, purge and rewrite\n",
    "if os.path.exists(temp_directory):\n",
    "    shutil.rmtree(temp_directory)\n",
    "    ensure_dir(temp_directory)\n",
    "else:\n",
    "    ensure_dir(temp_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optaa.write_csv(temp_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(temp_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optaa.uid, optaa.serial, optaa.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "### Check the data\n",
    "Now, we have generated local csv and ext files from the data. We can now reload that data into python as a pandas dataframe, which will allow for a direct comparison with the existing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = optaa.serial.split('-')[1].zfill(5)\n",
    "dt = optaa.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv = pd.read_csv(temp_directory+'/CGINS-OPTAAD-'+sn+'__'+dt+'.csv')\n",
    "source_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_arrays(array):\n",
    "    if 'SheetRef:CC_taarray' == array or 'SheetRef:CC_tcarray' == array:\n",
    "        return array\n",
    "    else:\n",
    "        # First, need to strip extraneous characters from the array\n",
    "        array = array.replace(\"'\",\"\").replace('[','').replace(']','')\n",
    "        # Next, split the array into a list\n",
    "        array = array.split(',')\n",
    "        # Now, need to eliminate any white space surrounding the individual coeffs\n",
    "        array = [num.strip() for num in array]\n",
    "        # Next, float the nums\n",
    "        array = [float(num) for num in array]\n",
    "        # Check if the array is len == 1; if so, can just return the number\n",
    "        if len(array) == 1:\n",
    "            array = array[0]\n",
    "        # Now we are done\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv['value'] = source_csv['value'].apply(reformat_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv['notes'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_taarray = pd.read_csv(temp_directory+'/CGINS-OPTAAD-'+sn+'__'+dt+'__CC_taarray.ext',header=None)\n",
    "source_taarray.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tcarray = pd.read_csv(temp_directory+'/CGINS-OPTAAD-'+sn+'__'+dt+'__CC_tcarray.ext',header=None)\n",
    "source_tcarray.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "Load the csv from asset management in order to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = 'CGINS-OPTAAD-00257__20190614.csv'\n",
    "csv_file = pd.read_csv(csv_dir+csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file.sort_values(by='name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file['value'] = csv_file['value'].apply(reformat_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taarray = pd.read_csv(csv_dir + 'CGINS-OPTAAD-00257__20190614__CC_taarray.ext',header=None)\n",
    "tcarray = pd.read_csv(csv_dir + 'CGINS-OPTAAD-00257__20190614__CC_tcarray.ext',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv == csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_taarray == taarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_taarray[source_taarray != taarray].dropna(how='all').dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taarray[source_taarray != taarray].dropna(how='all').dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tcarray == tcarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "# OPTAA Parser\n",
    "Below is a parser for the OPTAA calibration file. The following methods are available as part of the OPTAACalibration class:\n",
    "* **OPTAACalibration.load_cal**:\n",
    "        \n",
    "         Wrapper function to load all of the calibration coefficients\n",
    "        \n",
    "         Args:\n",
    "            filepath - path to the directory with filename which has the\n",
    "                calibration coefficients to be parsed and loaded\n",
    "         Calls:\n",
    "            open_cal\n",
    "            parse_cal\n",
    "            \n",
    "* **OPTAACalibration.load_qct**:\n",
    "\n",
    "        Wrapper function to load the calibration coefficients from\n",
    "        the QCT checkin.\n",
    "            \n",
    "\n",
    "It is used as follows:\n",
    "1. Initialize the OPTAA class using the **UID** for the OPTAA with the following code: OPTAA = OPTAACalibration(UID)\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "class OPTAACalibration():\n",
    "    # Class that stores calibration values for CTDs.\n",
    "\n",
    "    def __init__(self, uid):\n",
    "        self.serial = None\n",
    "        self.nbins = None\n",
    "        self.uid = uid\n",
    "        self.sigfig = 6\n",
    "        self.date = []\n",
    "        self.coefficients = {\n",
    "            'CC_acwo': [],\n",
    "            'CC_awlngth': [],\n",
    "            'CC_ccwo': [],\n",
    "            'CC_cwlngth': [],\n",
    "            'CC_taarray': 'SheetRef:CC_taarray',\n",
    "            'CC_tbins': [],\n",
    "            'CC_tcal': [],\n",
    "            'CC_tcarray': 'SheetRef:CC_tcarray'\n",
    "        }\n",
    "        self.tcarray = []\n",
    "        self.taarray = []\n",
    "        self.notes = {\n",
    "            'CC_acwo': '',\n",
    "            'CC_awlngth': '',\n",
    "            'CC_ccwo': '',\n",
    "            'CC_cwlngth': '',\n",
    "            'CC_taarray': '',\n",
    "            'CC_tbins': '',\n",
    "            'CC_tcal': '',\n",
    "            'CC_taarray': ''\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def uid(self):\n",
    "        return self._uid\n",
    "\n",
    "    @uid.setter\n",
    "    def uid(self, d):\n",
    "        r = re.compile('.{5}-.{6}-.{5}')\n",
    "        if r.match(d) is not None:\n",
    "            self._uid = d\n",
    "            serial = d.split('-')[-1].lstrip('0')\n",
    "            self.serial = 'ACS-' + serial\n",
    "        else:\n",
    "            raise Exception(f\"The instrument uid {d} is not a valid uid. Please check.\")\n",
    "\n",
    "            \n",
    "    def load_cal(self, filepath):\n",
    "        \"\"\"\n",
    "        Wrapper function to load all of the calibration coefficients\n",
    "        \n",
    "        Args:\n",
    "            filepath - path to the directory with filename which has the\n",
    "                calibration coefficients to be parsed and loaded\n",
    "        Calls:\n",
    "            open_cal\n",
    "            parse_cal\n",
    "        \"\"\"\n",
    "        \n",
    "        data = self.open_dev(filepath)\n",
    "        \n",
    "        self.parse_dev(data)\n",
    "        \n",
    "        \n",
    "    def load_qct(self, filepath):\n",
    "        \"\"\"\n",
    "        Wrapper function to load the calibration coefficients from\n",
    "        the QCT checkin.\n",
    "        \"\"\"\n",
    "        \n",
    "        data = self.open_dev(filepath)\n",
    "        \n",
    "        self.parse_qct(data)\n",
    "    \n",
    "    \n",
    "    def open_dev(self, filepath):\n",
    "        \"\"\"\n",
    "        Function that opens and reads in cal file\n",
    "        information for a OPTAA. Zipfiles are acceptable inputs.\n",
    "        \"\"\"\n",
    "        \n",
    "        if filepath.endswith('.zip'):\n",
    "            with ZipFile(filepath) as zfile:\n",
    "                # Check if OPTAA has the .dev file\n",
    "                filename = [name for name in zfile.namelist() if name.lower().endswith('.dev')]\n",
    "                \n",
    "                # Get and open the latest calibration file\n",
    "                if len(filename) == 1:\n",
    "                    data = zfile.read(filename[0]).decode('ascii')\n",
    "                    self.source_file(filepath, filename[0])\n",
    "                    \n",
    "                elif len(filename) > 1:\n",
    "                    raise FileExistsError(f\"Multiple .dev files found in {filepath}.\")\n",
    "\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"No .dev file found in {filepath}.\")\n",
    "                        \n",
    "        elif filepath.lower().endswith('.dev'):\n",
    "            with open(filepath) as file:\n",
    "                data = file.read()\n",
    "            self.source_file(filepath, file)\n",
    "                \n",
    "        elif filepath.lower().endswith('.dat'):\n",
    "            with open(filepath) as file:\n",
    "                data = file.read()\n",
    "            self.source_file(filepath, file)\n",
    "            \n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No .dev file found in {filepath}.\")\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "    def source_file(self, filepath, filename):\n",
    "        \"\"\"\n",
    "        Routine which parses out the source file and filename\n",
    "        where the calibration coefficients are sourced from.\n",
    "        \"\"\"\n",
    "        \n",
    "        if filepath.lower().endswith('.dev'):\n",
    "            dcn = filepath.split('/')[-2]\n",
    "            filename = filepath.split('/')[-1]\n",
    "        else:\n",
    "            dcn = filepath.split('/')[-1]\n",
    "        \n",
    "        self.source = f'Source file: {dcn} > {filename}'\n",
    "        \n",
    "\n",
    "    def parse_dev(self, data):\n",
    "        \"\"\"\n",
    "        Function to parse the .dev file in order to load the\n",
    "        calibration coefficients for the OPTAA.\n",
    "        \n",
    "        Args:\n",
    "            data - opened .dev file in ascii-format\n",
    "        \"\"\"\n",
    "        \n",
    "        for line in data.splitlines():\n",
    "            # Split the data based on data -> header split\n",
    "            parts = line.split(';')\n",
    "                # If the len isn't number 2, \n",
    "            if len(parts) is not 2:\n",
    "                # Find the calibration temperature and date\n",
    "                if 'tcal' in line.lower():\n",
    "                    line = ''.join((x for x in line if x not in [y for y in string.punctuation if y is not '/']))\n",
    "                    parts = line.split()\n",
    "                    # Calibration temperature\n",
    "                    tcal = parts[1].replace('C','')\n",
    "                    tcal = float(tcal)/10\n",
    "                    self.coefficients['CC_tcal'] = tcal\n",
    "                    # Calibration date\n",
    "                    date = parts[-1].strip(string.punctuation)\n",
    "                    self.date = pd.to_datetime(date).strftime('%Y%m%d')\n",
    "        \n",
    "            else:\n",
    "                info, comment = parts\n",
    "                \n",
    "                if comment.strip().startswith('temperature bins'):\n",
    "                    tbins = [float(x) for x in info.split()]\n",
    "                    self.coefficients['CC_tbins'] = tbins\n",
    "                    \n",
    "                elif comment.strip().startswith('number'):\n",
    "                    self.nbins = int(float(info.strip()))\n",
    "                    \n",
    "                elif comment.strip().startswith('C'):\n",
    "                    if self.nbins is None:\n",
    "                        raise AttributeError(f'Failed to load number of temperature bins.')\n",
    "                        \n",
    "                    # Parse out the different calibration coefficients\n",
    "                    parts = info.split()\n",
    "                    cwlngth = float(parts[0][1:])\n",
    "                    awlngth = float(parts[1][1:])\n",
    "                    ccwo = float(parts[3])\n",
    "                    acwo = float(parts[4])\n",
    "                    tcrow = [float(x) for x in parts[5:self.nbins+5]]\n",
    "                    acrow = [float(x) for x in parts[self.nbins+5:2*self.nbins+5]]\n",
    "                \n",
    "                    # Now put the coefficients into the coefficients dictionary\n",
    "                    self.coefficients['CC_acwo'].append(acwo)\n",
    "                    self.coefficients['CC_awlngth'].append(awlngth)\n",
    "                    self.coefficients['CC_ccwo'].append(ccwo)\n",
    "                    self.coefficients['CC_cwlngth'].append(cwlngth)\n",
    "                    self.tcarray.append(tcrow)\n",
    "                    self.taarray.append(acrow)\n",
    "                    \n",
    "                    \n",
    "    def parse_qct(self, data):\n",
    "        \"\"\"\n",
    "        This function is designed to parse the QCT file, which contains the\n",
    "        calibration data in slightly different format than the .dev file\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        for line in data.splitlines():\n",
    "            if 'WetView' in line:\n",
    "                _, _, _, date, time = line.split()\n",
    "                try:\n",
    "                    date_time = date + ' ' + time\n",
    "                    self.date = pd.to_datetime(date_time).strftime('%Y%m%d')\n",
    "                except:\n",
    "                    date_time = from_excel_ordinal(float(date) + float(time))\n",
    "                    self.date = pd.to_datetime(date_time).strftime('%Y%m%d')\n",
    "                continue\n",
    "                \n",
    "            parts = line.split(';')\n",
    "            \n",
    "            if len(parts) == 2:\n",
    "                if comment.strip().startswith('temperature bins'):\n",
    "                    tbins = [float(x) for x in info.split()]\n",
    "                    self.coefficients['CC_tbins'] = tbins\n",
    "                    \n",
    "                elif comment.strip().startswith('number'):\n",
    "                    self.nbins = int(float(info.strip()))\n",
    "                    \n",
    "                elif comment.strip().startswith('C'):\n",
    "                    if self.nbins is None:\n",
    "                        raise AttributeError(f'Failed to load number of temperature bins.')\n",
    "                    # Parse out the different calibration coefficients\n",
    "                    parts = info.split()\n",
    "                    cwlngth = float(parts[0][1:])\n",
    "                    awlngth = float(parts[1][1:])\n",
    "                    ccwo = float(parts[3])\n",
    "                    acwo = float(parts[4])\n",
    "                    tcrow = [float(x) for x in parts[5:self.nbins+5]]\n",
    "                    acrow = [float(x) for x in parts[self.nbins+5:(2*self.nbins)+5]]\n",
    "                    \n",
    "                    # Now put the coefficients into the coefficients dictionary\n",
    "                    self.coefficients['CC_acwo'].append(acwo)\n",
    "                    self.coefficients['CC_awlngth'].append(awlngth)\n",
    "                    self.coefficients['CC_ccwo'].append(ccwo)\n",
    "                    self.coefficients['CC_cwlngth'].append(cwlngth)\n",
    "                    self.tcarray.append(tcrow)\n",
    "                    self.taarray.append(acrow)                \n",
    "    \n",
    "                        \n",
    "    def write_csv(self, outpath):\n",
    "        \"\"\"\n",
    "        This function writes the correctly named csv file for the ctd to the\n",
    "        specified directory.\n",
    "\n",
    "        Args:\n",
    "            outpath - directory path of where to write the csv file\n",
    "        Raises:\n",
    "            ValueError - raised if the CTD object's coefficient dictionary\n",
    "                has not been populated\n",
    "        Returns:\n",
    "            self.to_csv - a csv of the calibration coefficients which is\n",
    "                written to the specified directory from the outpath.\n",
    "        \"\"\"\n",
    "\n",
    "        # Run a check that the coefficients have actually been loaded\n",
    "        if len(self.coefficients.values()) <= 2:\n",
    "            raise ValueError('No calibration coefficients have been loaded.')\n",
    "\n",
    "        # Create a dataframe to write to the csv\n",
    "        data = {\n",
    "            'serial': [self.serial]*len(self.coefficients),\n",
    "            'name': list(self.coefficients.keys()),\n",
    "            'value': list(self.coefficients.values())\n",
    "        }\n",
    "        df = pd.DataFrame().from_dict(data)\n",
    "      \n",
    "        # Now merge the coefficients dataframe with the notes\n",
    "        notes = pd.DataFrame().from_dict({\n",
    "            'name':list(self.notes.keys()),\n",
    "            'notes':list(self.notes.values())\n",
    "        })\n",
    "        df = df.merge(notes, how='outer', left_on='name', right_on='name')\n",
    "            \n",
    "        # Add in the source file\n",
    "        df['notes'].iloc[0] = df['notes'].iloc[0] + ' ' + self.source\n",
    "        \n",
    "        # Sort the data by the coefficient name\n",
    "        df = df.sort_values(by='name')\n",
    "\n",
    "        # Generate the csv names\n",
    "        csv_name = self.uid + '__' + self.date + '.csv'\n",
    "        tca_name = self.uid + '__' + self.date + '__' + 'CC_tcarray.ext'\n",
    "        taa_name = self.uid + '__' + self.date + '__' + 'CC_taarray.ext'\n",
    "        \n",
    "        def write_array(filename, cal_array):\n",
    "            with open(filename, 'w') as out:\n",
    "                array_writer = csv.writer(out)\n",
    "                array_writer.writerows(cal_array)\n",
    "\n",
    "        # Write the dataframe to a csv file\n",
    "        check = input(f\"Write {csv_name} to {outpath}? [y/n]: \")\n",
    "        # check = 'y'\n",
    "        if check.lower().strip() == 'y':\n",
    "            df.to_csv(outpath+'/'+csv_name, index=False)\n",
    "            write_array(outpath+'/'+tca_name, self.tcarray)\n",
    "            write_array(outpath+'/'+taa_name, self.taarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
