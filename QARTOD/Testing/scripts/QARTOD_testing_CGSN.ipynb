{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d0050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os, shutil, sys, time, re, requests, csv, datetime, pytz\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7098b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ooinet import M2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f50ea16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67b84758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the M2M location to ooinet-dev1-west.intra.oceanobservatories.org\n",
    "Dev01_urls = {}\n",
    "for key in M2M.URLS:\n",
    "    url = M2M.URLS.get(key)\n",
    "    if \"opendap\" in url:\n",
    "        dev1_url = re.sub(\"opendap\", \"opendap-dev1-west.intra\", url)\n",
    "    else:\n",
    "        dev1_url = re.sub(\"ooinet\",\"ooinet-dev1-west.intra\", url)\n",
    "    Dev01_urls[key] = dev1_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5524c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching https://ooinet.oceanobservatories.org/api/m2m/12576/sensor/inv/CP01CNSM\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# First, select a reference designator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[43mM2M\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCP01CNSM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstrument\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCTDBP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEnglish_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m datasets\n",
      "File \u001b[0;32m~/Documents/OOI/reedan88/ooinet/ooinet/M2M.py:143\u001b[0m, in \u001b[0;36msearch_datasets\u001b[0;34m(array, node, instrument, English_names)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Get the datasets\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[43mget_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Now, it node is not None, can filter on that\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/OOI/reedan88/ooinet/ooinet/M2M.py:103\u001b[0m, in \u001b[0;36mget_datasets\u001b[0;34m(search_url, datasets, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m             new_search_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((search_url, new_endpoint))\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;66;03m# Get the datasets for the new given endpoint\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m             datasets \u001b[38;5;241m=\u001b[39m \u001b[43mget_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_search_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Once recursion is done, return the datasets\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m datasets\n",
      "File \u001b[0;32m~/Documents/OOI/reedan88/ooinet/ooinet/M2M.py:90\u001b[0m, in \u001b[0;36mget_datasets\u001b[0;34m(search_url, datasets, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mappend(info, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     endpoints \u001b[38;5;241m=\u001b[39m \u001b[43mget_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m endpoints \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(endpoints) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m             \u001b[38;5;66;03m# Get one endpoint\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/OOI/reedan88/ooinet/ooinet/M2M.py:53\u001b[0m, in \u001b[0;36mget_api\u001b[0;34m(url, params)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_api\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124;03m\"\"\"Function which gets OOINet API endpoint\"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mSESSION\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m requests\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m     55\u001b[0m         api \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/sessions.py:600\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    599\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1241\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First, select a reference designator\n",
    "datasets = M2M.search_datasets(array=\"CP01CNSM\", instrument=\"CTDBP\", English_names=True)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b94204",
   "metadata": {},
   "source": [
    "### Production (OOINet) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f22ce9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "refdes = \"CP01CNSM-RID27-03-CTDBPC000\"\n",
    "array, node, sensor = refdes.split(\"-\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3734a5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deploymentNumber</th>\n",
       "      <th>uid</th>\n",
       "      <th>assetId</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>deployStart</th>\n",
       "      <th>deployEnd</th>\n",
       "      <th>deployCruise</th>\n",
       "      <th>recoverCruise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CGINS-CTDBPC-07208</td>\n",
       "      <td>1425</td>\n",
       "      <td>40.13678</td>\n",
       "      <td>-70.76978</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013-11-21 18:16:00</td>\n",
       "      <td>2014-04-18 10:33:00</td>\n",
       "      <td>KN214</td>\n",
       "      <td>KN217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CGINS-CTDBPC-06841</td>\n",
       "      <td>3287</td>\n",
       "      <td>40.1339</td>\n",
       "      <td>-70.7789</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2014-12-13 18:47:00</td>\n",
       "      <td>2014-12-15 20:58:00</td>\n",
       "      <td>KN224</td>\n",
       "      <td>KN224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CGINS-CTDBPC-06841</td>\n",
       "      <td>3287</td>\n",
       "      <td>40.14022</td>\n",
       "      <td>-70.77128</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015-05-07 17:34:00</td>\n",
       "      <td>2015-10-23 19:40:00</td>\n",
       "      <td>AT27</td>\n",
       "      <td>AT31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CGINS-CTDBPC-50002</td>\n",
       "      <td>1517</td>\n",
       "      <td>40.13323</td>\n",
       "      <td>-70.77843</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015-10-23 18:49:00</td>\n",
       "      <td>2016-04-04 12:03:00</td>\n",
       "      <td>AT31</td>\n",
       "      <td>AR1-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CGINS-CTDBPC-06841</td>\n",
       "      <td>3287</td>\n",
       "      <td>40.14037</td>\n",
       "      <td>-70.77133</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-05-13 13:50:00</td>\n",
       "      <td>2016-10-13 19:34:00</td>\n",
       "      <td>AR4</td>\n",
       "      <td>AR8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>CGINS-CTDBPC-50108</td>\n",
       "      <td>3213</td>\n",
       "      <td>40.13342</td>\n",
       "      <td>-70.77847</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-10-13 18:36:00</td>\n",
       "      <td>2017-06-09 16:05:00</td>\n",
       "      <td>AR8</td>\n",
       "      <td>AR18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>CGINS-CTDBPC-50002</td>\n",
       "      <td>1517</td>\n",
       "      <td>40.139817</td>\n",
       "      <td>-70.77115</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017-06-09 14:24:00</td>\n",
       "      <td>2017-11-01 20:33:00</td>\n",
       "      <td>AR18</td>\n",
       "      <td>AR24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>CGINS-CTDBPC-07208</td>\n",
       "      <td>1425</td>\n",
       "      <td>40.133383</td>\n",
       "      <td>-70.7783</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017-10-29 14:15:00</td>\n",
       "      <td>2018-03-29 19:37:00</td>\n",
       "      <td>AR24</td>\n",
       "      <td>AR28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>CGINS-CTDBPC-50002</td>\n",
       "      <td>1517</td>\n",
       "      <td>40.13975</td>\n",
       "      <td>-70.77128</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018-03-24 21:32:00</td>\n",
       "      <td>2018-10-29 12:31:00</td>\n",
       "      <td>AR28</td>\n",
       "      <td>AR31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>CGINS-CTDBPC-50108</td>\n",
       "      <td>3213</td>\n",
       "      <td>40.133367</td>\n",
       "      <td>-70.7777</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018-10-30 01:48:00</td>\n",
       "      <td>2019-04-07 18:08:00</td>\n",
       "      <td>AR31</td>\n",
       "      <td>AR34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>CGINS-CTDBPC-50002</td>\n",
       "      <td>1517</td>\n",
       "      <td>40.1401</td>\n",
       "      <td>-70.77137</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-04-06 14:35:00</td>\n",
       "      <td>2019-09-26 17:15:00</td>\n",
       "      <td>AR34</td>\n",
       "      <td>AR39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>CGINS-CTDBPC-07208</td>\n",
       "      <td>1425</td>\n",
       "      <td>40.1332</td>\n",
       "      <td>-70.7783</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-09-27 18:30:00</td>\n",
       "      <td>2020-11-06 13:17:00</td>\n",
       "      <td>AR39</td>\n",
       "      <td>AR48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>CGINS-CTDBPC-06841</td>\n",
       "      <td>3287</td>\n",
       "      <td>40.140517</td>\n",
       "      <td>-70.769643</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2020-10-29 14:57:00</td>\n",
       "      <td>2021-04-03 12:05:00</td>\n",
       "      <td>AR48</td>\n",
       "      <td>AR52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>CGINS-CTDBPC-50109</td>\n",
       "      <td>3215</td>\n",
       "      <td>40.132833</td>\n",
       "      <td>-70.778</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021-03-31 15:36:00</td>\n",
       "      <td>2021-11-03 17:00:00</td>\n",
       "      <td>AR52</td>\n",
       "      <td>AR61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>CGINS-CTDBPC-50003</td>\n",
       "      <td>1522</td>\n",
       "      <td>40.139823</td>\n",
       "      <td>-70.771173</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021-11-03 14:45:00</td>\n",
       "      <td>2022-04-13 12:05:00</td>\n",
       "      <td>AR61</td>\n",
       "      <td>AR66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>CGINS-CTDBPC-50109</td>\n",
       "      <td>3215</td>\n",
       "      <td>40.13325</td>\n",
       "      <td>-70.778317</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-04-10 14:35:00</td>\n",
       "      <td>2022-11-11 13:21:00</td>\n",
       "      <td>AR66</td>\n",
       "      <td>AR70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deploymentNumber                 uid assetId   latitude  longitude depth  \\\n",
       "0                 1  CGINS-CTDBPC-07208    1425   40.13678  -70.76978   7.0   \n",
       "1                 2  CGINS-CTDBPC-06841    3287    40.1339   -70.7789   7.0   \n",
       "2                 3  CGINS-CTDBPC-06841    3287   40.14022  -70.77128   7.0   \n",
       "3                 4  CGINS-CTDBPC-50002    1517   40.13323  -70.77843   7.0   \n",
       "4                 5  CGINS-CTDBPC-06841    3287   40.14037  -70.77133   7.0   \n",
       "5                 6  CGINS-CTDBPC-50108    3213   40.13342  -70.77847   7.0   \n",
       "6                 7  CGINS-CTDBPC-50002    1517  40.139817  -70.77115   7.0   \n",
       "7                 8  CGINS-CTDBPC-07208    1425  40.133383   -70.7783   7.0   \n",
       "8                 9  CGINS-CTDBPC-50002    1517   40.13975  -70.77128   7.0   \n",
       "9                10  CGINS-CTDBPC-50108    3213  40.133367   -70.7777   7.0   \n",
       "10               11  CGINS-CTDBPC-50002    1517    40.1401  -70.77137   7.0   \n",
       "11               12  CGINS-CTDBPC-07208    1425    40.1332   -70.7783   7.0   \n",
       "12               13  CGINS-CTDBPC-06841    3287  40.140517 -70.769643   7.0   \n",
       "13               14  CGINS-CTDBPC-50109    3215  40.132833    -70.778   7.0   \n",
       "14               15  CGINS-CTDBPC-50003    1522  40.139823 -70.771173   7.0   \n",
       "15               16  CGINS-CTDBPC-50109    3215   40.13325 -70.778317   7.0   \n",
       "\n",
       "           deployStart           deployEnd deployCruise recoverCruise  \n",
       "0  2013-11-21 18:16:00 2014-04-18 10:33:00        KN214         KN217  \n",
       "1  2014-12-13 18:47:00 2014-12-15 20:58:00        KN224         KN224  \n",
       "2  2015-05-07 17:34:00 2015-10-23 19:40:00         AT27          AT31  \n",
       "3  2015-10-23 18:49:00 2016-04-04 12:03:00         AT31        AR1-07  \n",
       "4  2016-05-13 13:50:00 2016-10-13 19:34:00          AR4           AR8  \n",
       "5  2016-10-13 18:36:00 2017-06-09 16:05:00          AR8          AR18  \n",
       "6  2017-06-09 14:24:00 2017-11-01 20:33:00         AR18          AR24  \n",
       "7  2017-10-29 14:15:00 2018-03-29 19:37:00         AR24          AR28  \n",
       "8  2018-03-24 21:32:00 2018-10-29 12:31:00         AR28          AR31  \n",
       "9  2018-10-30 01:48:00 2019-04-07 18:08:00         AR31          AR34  \n",
       "10 2019-04-06 14:35:00 2019-09-26 17:15:00         AR34          AR39  \n",
       "11 2019-09-27 18:30:00 2020-11-06 13:17:00         AR39          AR48  \n",
       "12 2020-10-29 14:57:00 2021-04-03 12:05:00         AR48          AR52  \n",
       "13 2021-03-31 15:36:00 2021-11-03 17:00:00         AR52          AR61  \n",
       "14 2021-11-03 14:45:00 2022-04-13 12:05:00         AR61          AR66  \n",
       "15 2022-04-10 14:35:00 2022-11-11 13:21:00         AR66          AR70  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployments = M2M.get_deployments(refdes)\n",
    "deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a423c826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>refdes</th>\n",
       "      <th>method</th>\n",
       "      <th>stream</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP01CNSM-RID27-03-CTDBPC000</td>\n",
       "      <td>recovered_host</td>\n",
       "      <td>ctdbp_cdef_dcl_instrument_recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP01CNSM-RID27-03-CTDBPC000</td>\n",
       "      <td>recovered_inst</td>\n",
       "      <td>ctdbp_cdef_instrument_recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP01CNSM-RID27-03-CTDBPC000</td>\n",
       "      <td>telemetered</td>\n",
       "      <td>ctdbp_cdef_dcl_instrument</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        refdes          method  \\\n",
       "0  CP01CNSM-RID27-03-CTDBPC000  recovered_host   \n",
       "1  CP01CNSM-RID27-03-CTDBPC000  recovered_inst   \n",
       "2  CP01CNSM-RID27-03-CTDBPC000     telemetered   \n",
       "\n",
       "                                stream  \n",
       "0  ctdbp_cdef_dcl_instrument_recovered  \n",
       "1      ctdbp_cdef_instrument_recovered  \n",
       "2            ctdbp_cdef_dcl_instrument  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastreams = M2M.get_datastreams(refdes)\n",
    "datastreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aee6a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data for a given deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ee85591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog(refdes, method, stream, deployments, goldCopy):\n",
    "    thredds_url = M2M.get_thredds_url(refdes, method, stream, goldCopy=goldCopy)\n",
    "    catalog = M2M.get_thredds_catalog(thredds_url)\n",
    "    catalog = M2M.clean_catalog(catalog, stream, deployments)\n",
    "    return catalog\n",
    "\n",
    "def get_netCDF_files(refdes, datastreams, deployments, goldCopy=True):\n",
    "    files = {}\n",
    "    for index in datastreams.index:\n",
    "        # Get the method and stream\n",
    "        method = datastreams.loc[index][\"method\"]\n",
    "        stream = datastreams.loc[index][\"stream\"]\n",
    "        \n",
    "        # Get the catalog\n",
    "        catalog = get_catalog(refdes, method, stream, deployments, goldCopy)\n",
    "        \n",
    "        # Replace the \n",
    "        if goldCopy:\n",
    "            dodsC = M2M.URLS[\"goldCopy_dodsC\"]\n",
    "        else:\n",
    "            dodsC = M2M.URLS[\"dodsC\"]\n",
    "            \n",
    "        catalog = sorted([re.sub(\"catalog.html\\?dataset=\", dodsC, file) for file in catalog])\n",
    "        \n",
    "        # Return the results\n",
    "        files.update({\n",
    "            method: catalog\n",
    "        })\n",
    "        \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03d6940f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recovered_host': ['https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0001_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20131121T181605.230000-20140217T132707.209000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0004_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20151023T191525.437000-20160402T034836.977000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0007_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20170609T142934.081000-20171031T115935.773000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0008_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20171029T141520.153000-20180329T190309.914000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0009_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20180324T213200.691000-20180423T191810.666000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0010_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20181030T014802.079000-20190407T131811.908000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0011_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20190406T144520.122000-20190926T161811.322000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0012_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20190927T183020.148000-20201106T114811.171000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0013_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20201029T150019.401000-20210403T110300.314000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0014_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20210331T154521.863000-20211103T160259.105000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered/deployment0015_CP01CNSM-RID27-03-CTDBPC000-recovered_host-ctdbp_cdef_dcl_instrument_recovered_20211103T144520.809000-20220413T111800.156000.nc'],\n",
       " 'recovered_inst': ['https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0001_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20131121T181601-20140217T132711.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0004_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20151023T191528-20160402T034848.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0005_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20160513T135001-20161013T193001.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0006_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20161013T183731-20161122T190001.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0007_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20170609T142931-20171101T202931.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0008_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20171029T141519-20180329T190320.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0009_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20180324T213207-20180502T203844.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0010_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20181030T014808-20190407T131809.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0011_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20190406T144517-20190926T161808.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0012_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20190927T183018-20201106T114826.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0013_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20201029T150015-20210403T110053.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0014_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20210331T154518-20211103T160251.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/deployment0015_CP01CNSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered_20211103T144517-20220413T111757.nc'],\n",
       " 'telemetered': ['https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0001_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20131121T181605.230000-20140217T120215.207000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0007_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20170609T142934.081000-20171101T175935.781000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0008_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20171029T141520.153000-20180329T150309.909000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0009_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20180324T213200.691000-20180423T183312.719000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0010_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20181030T014802.079000-20190407T131811.908000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0011_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20190406T144520.122000-20190926T150309.324000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0012_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20190927T183020.148000-20201106T050308.168000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0013_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20201029T150019.401000-20210403T100300.284000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0014_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20210331T154521.863000-20211017T230259.753000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0015_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20211103T144520.809000-20220413T110300.156000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220410T144521.898000-20220908T130252.514000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220908T130252.514000-20220922T231508.657000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220923T051508.662000-20220924T231508.696000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220924T231508.696000-20220925T111508.739000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220925T111508.739000-20220925T171508.711000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220925T171508.711000-20220926T171508.729000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220926T171508.729000-20220927T171508.744000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220927T171508.744000-20220928T171508.763000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220928T171508.763000-20220929T171508.782000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220929T171508.782000-20220930T171508.804000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20220930T171508.804000-20221001T171508.824000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221001T171508.824000-20221002T171508.843000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221002T171508.843000-20221003T171508.863000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221003T171508.863000-20221004T171508.885000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221004T171508.885000-20221005T171508.906000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221005T171508.906000-20221006T171508.929000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221006T171508.929000-20221007T171508.958000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221007T171508.958000-20221008T171508.968000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221008T171508.968000-20221009T171508.990000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221009T171508.990000-20221010T111509.006000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221010T111509.006000-20221011T171509.079000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221011T171509.079000-20221012T171509.052000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221012T171509.052000-20221014T111509.088000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221014T111509.088000-20221014T171509.092000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221014T171509.092000-20221015T171509.113000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221015T171509.113000-20221015T231509.120000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221015T231509.120000-20221017T171509.150000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221017T171509.150000-20221018T171509.171000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221018T171509.171000-20221019T171509.192000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221019T171509.192000-20221020T171509.213000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221020T171509.213000-20221021T171509.234000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221021T171509.234000-20221022T171509.254000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221022T171509.254000-20221023T171509.275000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221023T171509.275000-20221024T171509.295000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221024T171509.295000-20221025T171509.314000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221025T171509.314000-20221026T171509.333000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221026T171509.333000-20221027T171509.354000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221027T171509.354000-20221028T171509.374000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221028T171509.374000-20221029T171509.392000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221029T171509.392000-20221030T171509.412000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221030T171509.412000-20221031T171509.429000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221031T171509.429000-20221101T171509.450000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221101T171509.450000-20221102T171509.468000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221102T171509.468000-20221103T171509.486000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221103T171509.486000-20221104T171509.507000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221104T171509.507000-20221105T171509.524000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221105T171509.524000-20221106T171509.542000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221106T171509.542000-20221107T171509.559000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221107T171509.559000-20221108T171509.577000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221108T171509.577000-20221109T171509.594000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221109T171509.594000-20221110T171509.615000.nc',\n",
       "  'https://thredds.dataexplorer.oceanobservatories.org/thredds/dodsC/ooigoldcopy/public/CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument/deployment0016_CP01CNSM-RID27-03-CTDBPC000-telemetered-ctdbp_cdef_dcl_instrument_20221110T171509.615000-20221111T111509.630000.nc']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_netCDF_files(refdes, datastreams, deployments)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c40200",
   "metadata": {},
   "outputs": [],
   "source": [
    "depNum=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cbf207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = str(8).zfill(4)\n",
    "for key in files.keys():\n",
    "    files[key] = [f for f in files[key] if f'deployment{str(deployment).zfill(4)}' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f346bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9293012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def preprocess_datalogger(ds):\n",
    "    ds = process_file(ds)\n",
    "    ds = ctdbp_datalogger(ds)\n",
    "    ds = swap_timestamps(ds)\n",
    "    gc.collect()\n",
    "    return ds\n",
    "\n",
    "@dask.delayed\n",
    "def preprocess_instrument(ds):\n",
    "    ds = process_file(ds)\n",
    "    ds = ctdbp_instrument(ds)\n",
    "    gc.collect()\n",
    "    return ds\n",
    "\n",
    "def swap_timestamps(ds):\n",
    "    \"\"\"\n",
    "    Swaps the timestamps from the host to the instrument timestamp\n",
    "    for the CTDBPs\n",
    "    \"\"\"\n",
    "    if \"internal_timestamp\" in ds.variables:\n",
    "        # Calculate the timestamp\n",
    "        inst_time = ds.internal_timestamp.to_pandas()\n",
    "        attrs = ds.internal_timestamp.attrs\n",
    "        # Convert the time\n",
    "        inst_time = inst_time.apply(lambda x: np.datetime64(int(x), 's'))\n",
    "        # Create a DataArary\n",
    "        da = xr.DataArray(inst_time, attrs=attrs)\n",
    "        ds['internal_timestamp'] = da\n",
    "    ds = ds.set_coords([\"internal_timestamp\"])\n",
    "    ds = ds.swap_dims({\"time\":\"internal_timestamp\"})\n",
    "    ds = ds.reset_coords(\"time\")\n",
    "    ds = ds.rename_vars({\"time\":\"host_time\"})\n",
    "    ds[\"host_time\"].attrs = {\n",
    "        \"long_name\": \"DCL Timestamp\",\n",
    "        \"comment\": (\"The timestamp that the instrument data as recorded by the mooring data \"\n",
    "                    \"concentration logger (DCL)\")\n",
    "    }\n",
    "    ds = ds.rename({\"internal_timestamp\":\"time\"})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bda6f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Load recovered_host-ctdbp_cdef_dcl_instrument_recovered data -----\n",
      "[                                        ] | 0% Completed | 103.27 ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'process_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----- Load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstream\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data -----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar():\n\u001b[0;32m---> 45\u001b[0m         host_data \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat([ds\u001b[38;5;241m.\u001b[39mchunk() \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mzs\u001b[49m\u001b[43m)\u001b[49m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecovered_inst\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     inst_files \u001b[38;5;241m=\u001b[39m [re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatalog.html\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m?dataset=\u001b[39m\u001b[38;5;124m\"\u001b[39m, dodsC, file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m catalog]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dask/base.py:603\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    601\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 603\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m, in \u001b[0;36mpreprocess_datalogger\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@dask\u001b[39m\u001b[38;5;241m.\u001b[39mdelayed\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_datalogger\u001b[39m(ds):\n\u001b[0;32m----> 3\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_file\u001b[49m(ds)\n\u001b[1;32m      4\u001b[0m     ds \u001b[38;5;241m=\u001b[39m ctdbp_datalogger(ds)\n\u001b[1;32m      5\u001b[0m     ds \u001b[38;5;241m=\u001b[39m swap_timestamps(ds)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_file' is not defined"
     ]
    }
   ],
   "source": [
    "for index in datastreams.index:\n",
    "    # Get the method and stream\n",
    "    method = datastreams.loc[index][\"method\"]\n",
    "    stream = datastreams.loc[index][\"stream\"]\n",
    "\n",
    "    # Get the URL - first try the goldCopy thredds server\n",
    "    thredds_url = M2M.get_thredds_url(refdes, method, stream, goldCopy=True)\n",
    "\n",
    "    # Get the catalog\n",
    "    catalog = M2M.get_thredds_catalog(thredds_url)\n",
    "\n",
    "    # Clean the catalog\n",
    "    catalog = M2M.clean_catalog(catalog, stream, deployments)\n",
    "    \n",
    "    # Get the links to the THREDDs server and load the data\n",
    "    dodsC = M2M.URLS[\"goldCopy_dodsC\"]\n",
    "    \n",
    "    # Not all datasets have made it into the goldCopy THREDDS - in that case, need to request\n",
    "    # from OOINet\n",
    "    if len(catalog) == 0:\n",
    "        # Get the URL - first try the goldCopy thredds server\n",
    "        thredds_url = M2M.get_thredds_url(refdes, method, stream, goldCopy=False)\n",
    "\n",
    "        # Get the catalog\n",
    "        catalog = M2M.get_thredds_catalog(thredds_url)\n",
    "\n",
    "        # Clean the catalog\n",
    "        catalog = M2M.clean_catalog(catalog, stream, deployments)\n",
    "\n",
    "        # Get the links to the THREDDs server and load the data\n",
    "        dodsC = M2M.URLS[\"dodsC\"]\n",
    "    \n",
    "    # Now load the data\n",
    "    if method == \"telemetered\":\n",
    "        tele_files = [re.sub(\"catalog.html\\?dataset=\", dodsC, file) for file in catalog]\n",
    "        zs = [preprocess_datalogger(xr.open_dataset(tfile)) for tfile in tele_files]\n",
    "        print(f\"----- Load {method}-{stream} data -----\")\n",
    "        with ProgressBar():\n",
    "            tele_data = xr.concat([ds.chunk() for ds in dask.compute(*zs)], dim=\"time\")\n",
    "    elif method == \"recovered_host\":\n",
    "        host_files = [re.sub(\"catalog.html\\?dataset=\", dodsC, file) for file in catalog]\n",
    "        zs = [preprocess_datalogger(xr.open_dataset(hfile)) for hfile in host_files]\n",
    "        print(f\"----- Load {method}-{stream} data -----\")\n",
    "        with ProgressBar():\n",
    "            host_data = xr.concat([ds.chunk() for ds in dask.compute(*zs)], dim=\"time\")\n",
    "    elif method == \"recovered_inst\":\n",
    "        inst_files = [re.sub(\"catalog.html\\?dataset=\", dodsC, file) for file in catalog]\n",
    "        zs = [preprocess_instrument(xr.open_dataset(ifile)) for ifile in inst_files]\n",
    "        print(f\"----- Load {method}-{stream} data -----\")\n",
    "        with ProgressBar():\n",
    "            inst_data = xr.concat([ds.chunk() for ds in dask.compute(*zs)], dim=\"time\")\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f03e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = combine_datasets(tele_data, host_data, inst_data, None)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372ac4c",
   "metadata": {},
   "source": [
    "### Dev01 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev01_thredds_url = Dev01.get_thredds_url(refdes, method, stream)\n",
    "#dev01_thredds_url = 'https://opendap-dev1-west.intra.oceanobservatories.org/thredds/catalog/ooi/areed@whoi.edu/20220329T173040530Z-CP03ISSM-RID27-03-CTDBPC000-recovered_inst-ctdbp_cdef_instrument_recovered/catalog.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeced90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev01_catalog = Dev01.get_thredds_catalog(dev01_thredds_url)\n",
    "dev01_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9656e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev01_catalog = clean_catalog(dev01_catalog, stream, deployments)\n",
    "dev01_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0df7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev01_catalog = [x for x in dev01_catalog if \"blank\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c12a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dev01.REFDES = refdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e089d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev01_data = Dev01.load_netCDF_datasets(dev01_catalog)\n",
    "dev01_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec2bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31366849",
   "metadata": {},
   "source": [
    "### Load netCDF files from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"/home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/QARTOD/Testing/data/testing/{refdes}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555047cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "netCDF_files = [save_dir+f for f in os.listdir(save_dir)]\n",
    "#water_files = [x for x in netCDF_files if \"water_recovered\" in x.split(\"/\")[-1]]\n",
    "#air_files = [x for x in netCDF_files if \"air_recovered\" in x.split(\"/\")[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e044d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "netCDF_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ce8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76cc361",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOINet.REFDES = refdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0267c",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Third, check and remove any files which are malformed\n",
    "# and remove the bad ones\n",
    "netCDF_files = OOINet._check_files(netCDF_files)\n",
    "\n",
    "# Load the datasets into a concatenated xarray DataSet\n",
    "with ProgressBar():\n",
    "    print(\"\\n\"+f\"Loading netCDF_files for {OOINet.REFDES}:\")\n",
    "    ds = xr.open_mfdataset(netCDF_files, preprocess=OOINet._preprocess, parallel=True)\n",
    "\n",
    "# Add in the English name of the dataset\n",
    "refdes = \"-\".join(ds.attrs[\"id\"].split(\"-\")[:4])\n",
    "vocab = OOINet.get_vocab(refdes)\n",
    "ds.attrs[\"Location_name\"] = \" \".join((vocab[\"tocL1\"].iloc[0],\n",
    "                                      vocab[\"tocL2\"].iloc[0],\n",
    "                                      vocab[\"tocL3\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532060f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25d2525",
   "metadata": {},
   "source": [
    "## QARTOD Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = \"partial_pressure_co2_ssw\"\n",
    "data_variables = []\n",
    "for var in ds.variables:\n",
    "    if param in var and \"qc\" not in var:\n",
    "        print(var)\n",
    "        data_variables.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99eba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, cut down the dataset size to be more managable\n",
    "ds = ds[data_variables]\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e71606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del ds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb37bb",
   "metadata": {},
   "source": [
    "### Production vs Dev01\n",
    "First, check that Dev01 datasets matched released production datasets flagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = \"practical_salinity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the production data down to the size of the dev01 data\n",
    "tmin = dev01_data[\"time\"].min()\n",
    "tmax = dev01_data[\"time\"].max()\n",
    "production_data = production_data.sel(time=slice(tmin, tmax))\n",
    "dev01_data = dev01_data.sel(time=slice(tmin, tmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = (production_data[f\"{param}_qartod_results\"] == dev01_data[f\"{param}_qartod_results\"])\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fca72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(~comparison).sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058df6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_check = (production_data[param] == dev01_data[param])\n",
    "value_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76921846",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data[f\"{param}_qartod_results\"][~comparison]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev01_data[f\"{param}_qartod_results\"][~comparison]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a476dc9",
   "metadata": {},
   "source": [
    "### QARTOD values\n",
    "Next, load the QARTOD tables from github and parse them into dictionaries.\n",
    "\n",
    "Changes: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0849c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = \"CTDMO\"\n",
    "#param = \"ctdbp_seawater_temperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "def loadQARTOD(refDes,param,sensorType):\n",
    "    \n",
    "    (site,node,sensor1,sensor2) = refDes.split('-')\n",
    "    sensor = sensor1 + '-' + sensor2\n",
    "    \n",
    "    ### Load climatology and gross range values\n",
    "    githubBaseURL = 'https://raw.githubusercontent.com/oceanobservatories/qc-lookup/master/qartod/'\n",
    "    if 'ph_seawater' in param:\n",
    "        ClimParam = 'seawater_ph'\n",
    "    else:\n",
    "        ClimParam = param\n",
    "    clim_URL = githubBaseURL + sensorType + '/climatology_tables/' + refDes + '-' + ClimParam + '.csv'\n",
    "    grossRange_URL = githubBaseURL + sensorType + '/' + sensorType + '_qartod_gross_range_test_values.csv'\n",
    "    download = requests.get(grossRange_URL)\n",
    "    if download.status_code == 200:\n",
    "        df_grossRange = pd.read_csv(io.StringIO(download.content.decode('utf-8')))\n",
    "        paramString = \"{'inp': '\" + param + \"'}\"\n",
    "        qcConfig = df_grossRange.qcConfig[(df_grossRange.subsite == site) \n",
    "                                          & (df_grossRange.node == node) \n",
    "                                          & (df_grossRange.sensor == sensor) \n",
    "                                          & (df_grossRange.parameters == paramString)]\n",
    "        qcConfig_json = qcConfig.values[0].replace(\"'\", \"\\\"\")\n",
    "        grossRange_dict = json.loads(qcConfig_json)\n",
    "    else:\n",
    "        print('error retriving gross range data')\n",
    "        grossRange_dict = {}\n",
    "\n",
    "    download = requests.get(clim_URL)\n",
    "    if download.status_code == 200:\n",
    "        df_clim = pd.read_csv(io.StringIO(download.content.decode('utf-8')))\n",
    "        climRename = {\n",
    "                'Unnamed: 0':'depth',\n",
    "                '[1, 1]':'1',\n",
    "                '[2, 2]':'2',\n",
    "                '[3, 3]':'3',\n",
    "                '[4, 4]':'4',\n",
    "                '[5, 5]':'5',\n",
    "                '[6, 6]':'6',\n",
    "                '[7, 7]':'7',\n",
    "                '[8, 8]':'8',\n",
    "                '[9, 9]':'9',\n",
    "                '[10, 10]':'10',\n",
    "                '[11, 11]':'11',\n",
    "                '[12, 12]':'12'           \n",
    "            } \n",
    "        \n",
    "        df_clim.rename(columns=climRename, inplace=True)\n",
    "        clim_dict = df_clim.set_index('depth').to_dict()\n",
    "    else:\n",
    "        print('error retriving climatology data')\n",
    "        clim_dict = {}\n",
    "    \n",
    "    return(grossRange_dict,clim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grossRange_dict, clim_dict = loadQARTOD(refdes, param, inst.lower())\n",
    "grossRange_dict, clim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64889814",
   "metadata": {},
   "source": [
    "### Add Climatology Values\n",
    "Next, add the climatology min and max values to the dataset as new data variables, based on the month of the data.\n",
    "\n",
    "Changes:\n",
    "* Renamed \"climatologyMin/climatologyMax\" to \"{parameter name}\\_climatologyMin/climatologyMax\" in order to allow multiple parameter climatologies to be stored in an given dataset\n",
    "* Preallocated the climatology arrays with nans instead of zeros to skip the later step of backfilling nans.\n",
    "* Utilize dask to get the months (as integers) in the time variable of the dataset. This avoids loading the data into memory.\n",
    "* Utilize direct assignment of the climatologyMin/Max values for each month on the dataset variable arrays. This again keeps the dataset out-of-memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd39ceb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import ast\n",
    "\n",
    "def add_climatology_values(ds, param, clim_dict):\n",
    "    \"\"\"Adds climatology mins and maxes to the dataset timeseries\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: xarray.Dataset\n",
    "        Dataset to add climatology values to, with primary dimension \"time\"\n",
    "    param: str\n",
    "        Name of parameter in the passed xarray.Dataset which to add\n",
    "        climatology values to\n",
    "    clim_dict: dict\n",
    "        A dictionary of the climatology values for the given dataset\n",
    "        loaded from the qartod gitHub repo\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ds: xarray.Dataset\n",
    "        An xarray dataset with climatology mins and maxes added for the given\n",
    "        parameter (param) to the dataset\n",
    "        \n",
    "    Note: Will need to add a pressure function to make this match the original functionality\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, create a variable name to store the data\n",
    "    varNameMin = f\"{param}_climatologyMin\"\n",
    "    varNameMax = f\"{param}_climatologyMax\"\n",
    "    \n",
    "    # Next, pre-allocate an array with the data\n",
    "    ds[varNameMin] = ds[param].astype(float) * np.nan\n",
    "    ds[varNameMax] = ds[param].astype(float) * np.nan\n",
    "    \n",
    "    # Get the months\n",
    "    time = da.from_array(ds.time.dt.month)\n",
    "    months = np.unique(time).compute()\n",
    "    \n",
    "    # Add the climatology min and max based on the month of the measurement\n",
    "    for month in months:\n",
    "        climatology = ast.literal_eval(clim_dict[str(month)][str([0, 0])])\n",
    "        ds[varNameMin][(ds.time.dt.month == month)] = climatology[0]\n",
    "        ds[varNameMax][(ds.time.dt.month == month)] = climatology[1]\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db0f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import ast\n",
    "\n",
    "def build_climatology_array(ds, clim_dict, press_param, param_name, platform):\n",
    "    \"\"\"Adds climatology mins and maxes to the dataset timeseries\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ds: xarray.Dataset\n",
    "        Dataset to add climatology values to, with primary dimension \"time\"\n",
    "    param: str\n",
    "        Name of parameter in the passed xarray.Dataset which to add\n",
    "        climatology values to\n",
    "    press_param: str\n",
    "        Name of the pressure parameter for profilers and other vehicles with\n",
    "        climatology values that are pressure dependent\n",
    "    clim_dict: dict\n",
    "        A dictionary of the climatology values for the given dataset\n",
    "        loaded from the qartod gitHub repo\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ds: xarray.Dataset\n",
    "        An xarray dataset with climatology mins and maxes added for the given\n",
    "        parameter (param) to the dataset\n",
    "        \n",
    "    Note: Will need to add a pressure function to make this match the original functionality\n",
    "    \"\"\"\n",
    "    ds['climatologyMin'] = ds[param_name].astype('float') * np.nan\n",
    "    ds['climatologyMax'] = ds[param_name].astype('float') * np.nan\n",
    "    \n",
    "    # Get the months\n",
    "    time = da.from_array(ds.time.dt.month)\n",
    "    months = np.unique(time).compute()\n",
    "    \n",
    "    # Iterate through the months\n",
    "    # This is the slow part - it takes 12*num_press_brackets*O(NlogN) time\n",
    "    for month in months:\n",
    "        # First, check if need to filter again by pressure\n",
    "        if platform == \"profiler\":\n",
    "            # Get the pressure dictionary for the given month\n",
    "            pres_dict = clim_dict.get(str(month))\n",
    "            for pressure_range in pres_dict.keys():\n",
    "                # Parse the pressure range\n",
    "                p = re.search(r'\\[(.+),(.+)\\]', pressure_range)\n",
    "                pmin, pmax = float(p.group(1)), float(p.group(2))\n",
    "                # Parse the climatology\n",
    "                climatology = pres_dict.get(pressure_range)\n",
    "                c = re.search(r'\\[(.+),(.+)\\]', climatology)\n",
    "                cmin, cmax = float(c.group(1)), float(c.group(2))\n",
    "                # Now assign the climatology min/max\n",
    "                ds[\"climatologyMin\"][(ds.time.dt.month == month) &\n",
    "                                     (ds[press_param] >= pmin) & \n",
    "                                     (ds[press_param] <= pmax)] = cmin\n",
    "                ds[\"climatologyMax\"][(ds.time.dt.month == month) &\n",
    "                                     (ds[press_param] >= pmin)  &\n",
    "                                     (ds[press_param] <= pmax)] = cmax\n",
    "        elif platform == \"fixed\":\n",
    "            climatology = ast.literal_eval(clim_dict[str(month)][str([0, 0])])\n",
    "            cmin, cmax = climatology[0], climatology[1]\n",
    "            ds[\"climatologyMin\"][(ds.time.dt.month == month)] = cmin\n",
    "            ds[\"climatologyMax\"][(ds.time.dt.month == month)] = cmax\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55335df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_param = None\n",
    "platform = \"fixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3634f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data = production_data\n",
    "toy_data[\"practical_salinity_qartod_results\"][0:10] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data = build_climatology_array(production_data, clim_dict, press_param, param, platform)\n",
    "dev01_data = build_climatology_array(dev01_data, clim_dict, press_param, param, platform)\n",
    "toy_data = build_climatology_array(toy_data, clim_dict, press_param, param, platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3703df",
   "metadata": {},
   "source": [
    "### Add QARTOD flags\n",
    "Next, want to calculate the QARTOD flags for the gross range and climatology values and add them to the dataset. \n",
    "Changes:\n",
    "* Renamed the \"gr_flag/clim_flag\" to \"{parameter name}\\_gr_flag/\\_clim_flag\" in order to allow multiple parameters to be tested in a single dataset.\n",
    "* Utilize direct assignment of the QARTOD flags to avoid loading data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd79404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_QARTOD_flags(ds, param, grossRange):\n",
    "    \"\"\"Function to add the gross range and climatology flags\"\"\"\n",
    "    \n",
    "    # Add the gross range flags for a param\n",
    "    gr_flag = f\"{param}_gr_flag\"\n",
    "    ds[gr_flag] = ds[param].astype(\"int64\") * 0 + 1\n",
    "    gr_suspect = grossRange[\"qartod\"][\"gross_range_test\"][\"suspect_span\"]\n",
    "    gr_fail = grossRange[\"qartod\"][\"gross_range_test\"][\"fail_span\"]\n",
    "    ds[gr_flag][(ds[param] < gr_suspect[0]) | (ds[param] > gr_suspect[1])] = 3\n",
    "    ds[gr_flag][(ds[param] < gr_fail[0]) | (ds[param] > gr_fail[1])] = 4\n",
    "     \n",
    "    # Climatology flags\n",
    "    clim_flag = f\"{param}_clim_flag\"\n",
    "    ds[clim_flag] = ds[param].astype(\"int64\") * 0 + 1\n",
    "    ds[clim_flag][(ds[\"climatologyMin\"].isnull()) | (ds[\"climatologyMax\"].isnull())] = 2\n",
    "    ds[clim_flag][(ds[param] < ds[\"climatologyMin\"]) | (ds[param] > ds[\"climatologyMax\"])] = 3\n",
    "    \n",
    "    # Check for not evaluated locations\n",
    "    not_eval = ds[param].isnull()\n",
    "    ds[gr_flag][not_eval] = 9\n",
    "    ds[clim_flag][not_eval] = 9\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb271d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data = create_QARTOD_flags(production_data, param, grossRange_dict)\n",
    "dev01_data = create_QARTOD_flags(dev01_data, param, grossRange_dict)\n",
    "toy_data = create_QARTOD_flags(toy_data, param, grossRange_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3400c416",
   "metadata": {},
   "source": [
    "### Compare test values\n",
    "Now, want to compare the values calculated locally with the values returned by OOINet in the \"qartod_executed\" variables.\n",
    "\n",
    "Changes:\n",
    "* Don't iterate through each data point\n",
    "* Change the data type of the {parameter name}\\_qartod_executed data array to string to be interperable\n",
    "* With the type changed to string, can use the xarray built-in string methods (.str) to parse each value in the \"qartod_executed\" array\n",
    "* Changed the name of \"qartod_gr/qartod_clim\" to \"{parameter name}\\_qartod_gr/\\_qartod_clim\" to allow multiple parameters to be stored in the same dataset\n",
    "* Run the test comparison and store as \"{parameter name}\\_gr_comparison/\\_clim_comparison\" as a boolean array. This will allow us to quickly count the comparison (using sum) and mask the parameter being tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ae47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(ds, param):\n",
    "    \n",
    "    # First, identify the test order of the qartod tests run\n",
    "    qartod_name = f\"{param}_qartod_executed\"\n",
    "    test_order = ds[qartod_name].attrs[\"tests_executed\"].strip(\"'\").replace(\" \", \"\").split(\",\")\n",
    "    \n",
    "    # Second, identify the index of each test\n",
    "    clim_index = test_order.index(\"climatology_test\")\n",
    "    gr_index = test_order.index(\"gross_range_test\")\n",
    "    \n",
    "    # Next, convert the OOINet-run QARTOD flags to interperable strings\n",
    "    ds[qartod_name] = ds[qartod_name].astype(str)\n",
    "    \n",
    "    # Parse the qartod flags into the separate test flags\n",
    "    ds[f\"{param}_qartod_gr\"] = ds[qartod_name].str.get(gr_index).astype(\"int\")\n",
    "    ds[f\"{param}_qartod_clim\"] = ds[qartod_name].str.get(clim_index).astype(\"int\")\n",
    "    \n",
    "    # Compare the OOI Qartod with local Qartod\n",
    "    ds[f\"{param}_gr_comparison\"] = ds[f\"{param}_qartod_gr\"] != ds[f\"{param}_gr_flag\"]\n",
    "    ds[f\"{param}_clim_comparison\"] = ds[f\"{param}_qartod_clim\"] != ds[f\"{param}_clim_flag\"]\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_data[f\"{param}_qartod_executed\"][0:10] = '33'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41939d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "production_data = run_comparison(production_data, param)\n",
    "dev01_data = run_comparison(dev01_data, param)\n",
    "toy_data = run_comparison(toy_data, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86804e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in production_data.practical_salinity_qartod_executed:\n",
    "    if x.values != '11' | x.values:\n",
    "        print(x.time.values)\n",
    "        print(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev01_data.practical_salinity_qartod_executed.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dev01_data.practical_salinity_qartod_executed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data.practical_salinity_qartod_executed.where((production_data.practical_salinity_qartod_executed == \"Bad HeapObject.dataSize=id=16, refCount=0, dataSize=452117892851\") |\n",
    "                                                        (production_data.practical_salinity_qartod_executed == \"Bad HeapObject.dataSize=id=16, refCount=0, dataSize=533495497202\"), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1770f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f685269",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.values.dtype == '<U2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43904abb",
   "metadata": {},
   "source": [
    "### Execute the comparison\n",
    "So far, all the work we've done hasn't actually run any processing. Everything has been done as a set of dask instructions to execute when we call compute().\n",
    "\n",
    "Below, I first just count the number of missed flags by summing the comparison results, since each \"missed\" flag is stored as a boolean ```True```, which ```.sum()``` counts as a 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d768f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    for var in production_data.variables:\n",
    "        if \"comparison\" in var:\n",
    "            result = production_data[var].sum().compute()\n",
    "            print(f\"Missed flags for {var}: {result.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31979e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    for var in dev01_data.variables:\n",
    "        if \"comparison\" in var:\n",
    "            result = dev01_data[var].sum().compute()\n",
    "            print(f\"Missed flags for {var}: {result.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    for var in toy_data.variables:\n",
    "        if \"comparison\" in var:\n",
    "            result = toy_data[var].sum().compute()\n",
    "            print(f\"Missed flags for {var}: {result.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615caa4",
   "metadata": {},
   "source": [
    "### Plot some data with bad data flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e26c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb37660",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 10))\n",
    "\n",
    "ax[0].plot(production_data.time, production_data[param], linestyle=\"\", marker=\".\", color=\"tab:blue\")\n",
    "ax[0].plot(production_data.where((production_data[f\"{param}_qartod_clim\"] == 3))[\"time\"],\n",
    "           production_data.where((production_data[f\"{param}_qartod_clim\"] == 3))[param],\n",
    "           color=\"tab:red\", marker=\".\", linestyle=\"\")\n",
    "ax[0].grid()\n",
    "ax[0].set_ylim()\n",
    "\n",
    "ax[1].plot(production_data.time, production_data[param], linestyle=\"\", marker=\".\", color=\"tab:blue\")\n",
    "ax[1].plot(production_data.where(production_data[f\"{param}_clim_flag\"] == 3)[\"time\"],\n",
    "           production_data.where(production_data[f\"{param}_clim_flag\"] == 3)[param],\n",
    "           color=\"tab:red\", marker=\".\", linestyle=\"\")\n",
    "ax[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 10))\n",
    "\n",
    "ax[0].plot(dev01_data.time, dev01_data[param], linestyle=\"\", marker=\".\", color=\"tab:blue\")\n",
    "ax[0].plot(dev01_data.where((dev01_data[f\"{param}_qartod_clim\"] == 3))[\"time\"],\n",
    "           dev01_data.where((dev01_data[f\"{param}_qartod_clim\"] == 3))[param],\n",
    "           color=\"tab:red\", marker=\".\", linestyle=\"\")\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].plot(dev01_data.time, dev01_data[param], linestyle=\"\", marker=\".\", color=\"tab:blue\")\n",
    "ax[1].plot(dev01_data.where(dev01_data[f\"{param}_clim_flag\"] == 3)[\"time\"],\n",
    "           dev01_data.where(dev01_data[f\"{param}_clim_flag\"] == 3)[param],\n",
    "           color=\"tab:red\", marker=\".\", linestyle=\"\")\n",
    "ax[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26740cad",
   "metadata": {},
   "source": [
    "### To Do\n",
    "Need to add in pressure bracket handling so that I can do profilers (although I don't have any profilers for CGSN up on Dev1). \n",
    "\n",
    "Also need to add in function to print out the time-stamp of when qartod flags are mis-flaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ad04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pressureBracket(pressure,clim_dict):\n",
    "    bracketList = []\n",
    "    pressBracket = 'notFound'\n",
    "\n",
    "    for bracket in clim_dict['1'].keys():\n",
    "        x = re.search(r'\\[(.+),(.+)\\]', bracket)\n",
    "        if x:\n",
    "            bracketList.append([int(x.group(1)),int(x.group(2))])\n",
    "        else:\n",
    "            print('bracket parsing error for ' + bracket)\n",
    "    for bracket in bracketList:\n",
    "        if (pressure >= bracket[0]) & (pressure < bracket[1]):\n",
    "            pressBracket = bracket\n",
    "            break\n",
    "    \n",
    "    return pressBracket"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
