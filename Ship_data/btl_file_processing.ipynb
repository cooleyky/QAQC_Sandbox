{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottle Processing\n",
    "Author: Andrew Reed\n",
    "\n",
    "### Motivation:\n",
    "Independent verification of the suite of physical and chemical observations provided by OOI are critical for the observations to be of use for scientifically valid investigations. Consequently, CTD casts and Niskin water samples are made during deployment and recovery of OOI platforms, vehicles, and instrumentation. The water samples are subsequently analyzed by independent labs for  comparison with the OOI telemetered and recovered data.\n",
    "\n",
    "However, currently the water sample data routinely collected and analyzed as part of the OOI program are not available in a standardized format which maps the different chemical analyses to the physical measurements taken at bottle closure. Our aim is to make these physical and chemical analyses of collected water samples available to the end-user in a standardized format for easy comprehension and use, while maintaining the source data files. \n",
    "\n",
    "### Approach:\n",
    "Generating a summary of the water sample analyses involves preprocessing and concatenating multiple data sources, and accurately matching samples with each other. To do this, I first preprocess the ctd casts to generate bottle (.btl) files using the SeaBird vendor software following the SOP available on Alfresco. \n",
    "\n",
    "Next, the bottle files are parsed using python code and the data renamed following SeaBird's naming guide. This creates a series of individual cast summary (.sum) files. These files are then loaded into pandas dataframes, appended to each other, and exported as a csv file containing all of the bottle data in a single data file.\n",
    "\n",
    "### Data Sources/Software:\n",
    "\n",
    "* **sbe_name_map**: This is a spreadsheet which maps the short names generated by the SeaBird SBE DataProcessing Software to the associated full names. The name mapping originates from SeaBird's SBE DataProcessing support documentation.\n",
    "\n",
    "* **Alfresco**: The Alfresco CMS for OOI at alfresco.oceanobservatories.org is the source of the ctd hex, xmlcon, and psa files necessary for generating the bottle files needed to create the sample summary sheet.\n",
    "\n",
    "* **SBEDataProcessing-Win32**: SeaBird vendor software for processing the raw ctd files and generating the .btl files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages used in this notebook\n",
    "import os, sys, re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the name mapping for the column names\n",
    "# Specifiy the local directory\n",
    "sbe_name_map = pd.read_excel('/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Reference_Files/seabird_ctd_name_map.xlsx')\n",
    "# sbe_name_map = pd.read_excel('C:/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Reference_Files/seabird_ctd_name_map.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/'\n",
    "array = 'Pioneer/'\n",
    "cruise = 'Pioneer-01/'\n",
    "water_dir = 'Water Sampling/'\n",
    "ctd_dir = 'KN-214_CTD/'\n",
    "leg = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OOI Nov. 2013 DIC and TA data.eml',\n",
       " 'OOIchl.xls',\n",
       " 'OOI_2013_Nov_DIC and TA data.xlsx',\n",
       " 'OOI_chl_labNB.pdf',\n",
       " 'Pioneer Nutrient Lab sample data 2014.xlsx',\n",
       " 'Pioneer-1_KN-214_Sampling_Log-written.pdf',\n",
       " 'Pioneer-1_KN-214_Sampling_Log.xlsx',\n",
       " 'Salts and O2']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(basepath+array+cruise+water_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the local directory where the bottle (.btl) files are stored for a particular cruise\n",
    "# dirpath = 'C:/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/Irminger/Irminger-5/ctd/'\n",
    "btlpath = basepath+array+cruise+'KN-214_CTD/'\n",
    "summary_sheet_path = basepath+array+cruise+'/Water Sampling/Pioneer-1_KN-214_Sampling_Log.xlsx'\n",
    "salts_and_o2_path = basepath+array+cruise+'/Water Sampling/Salts and O2/'\n",
    "nutrients_path = basepath+array+cruise+'/Water Sampling/Pioneer Nutrient Lab sample data 2014.xlsx'\n",
    "chl_path = basepath+array+cruise+'/Water Sampling/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data for the start_time\n",
    "def parse_header(header):\n",
    "    \"\"\"\n",
    "    Parse the header of bottle (.btl) files to get critical information\n",
    "    for the summary spreadsheet.\n",
    "    \n",
    "    Args:\n",
    "        header - an object containing the header of the bottle file as a list of\n",
    "            strings, split at the newline.\n",
    "    Returns:\n",
    "        hdr - a dictionary object containing the start_time, filename, latitude,\n",
    "            longitude, and cruise id.\n",
    "    \"\"\"\n",
    "    hdr = {}\n",
    "    for line in header:\n",
    "        if 'start_time' in line.lower():\n",
    "            start_time = pd.to_datetime(re.split('= |\\[',line)[1])\n",
    "            hdr.update({'Start Time':start_time.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "        elif 'filename' in line.lower():\n",
    "            hex_name = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Hex name':hex_name})\n",
    "        elif 'latitude' in line.lower():\n",
    "            start_lat = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Start Latitude':start_lat})\n",
    "        elif 'longitude' in line.lower():\n",
    "            start_lon = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Start Longitude':start_lon})\n",
    "        elif 'cruise id' in line.lower():\n",
    "            cruise_id = re.split(':',line)[1].strip()\n",
    "            hdr.update({'Cruise ID':cruise_id})\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return hdr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write a function to autopopulate the bottle summary sample sheet\n",
    "files = [x for x in os.listdir(btlpath) if '.btl' in x]\n",
    "for filename in files:\n",
    "    filepath = os.path.abspath(btlpath+filename)\n",
    "    \n",
    "    # Load the raw content into memory\n",
    "    with open(filepath) as file:\n",
    "        content = file.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    \n",
    "    # Now parse the file content\n",
    "    header = []\n",
    "    columns = []\n",
    "    data = []\n",
    "    for line in content:\n",
    "        if line.startswith('*') or line.startswith('#'):\n",
    "            header.append(line)\n",
    "        else:\n",
    "            try:\n",
    "                float(line[0])\n",
    "                data.append(line)\n",
    "            except:\n",
    "                columns.append(line)\n",
    "    \n",
    "    # Parse the header\n",
    "    hdr = parse_header(header)\n",
    "    \n",
    "    # Parse the column identifiers\n",
    "    column_dict = {}\n",
    "    for line in columns:\n",
    "        for i,x in enumerate(line.split()):\n",
    "            try:\n",
    "                column_dict[i] = column_dict[i] + ' ' + x\n",
    "            except:\n",
    "                column_dict.update({i:x})\n",
    "    \n",
    "    # Parse the bottle data based on the column header locations\n",
    "    data_dict = {x:[] for x in column_dict.keys()}\n",
    "\n",
    "    for line in data:\n",
    "        if line.endswith('(avg)'):\n",
    "            values = list(filter(None,re.split('  |\\t', line) ) )\n",
    "            for i,x in enumerate(values):\n",
    "                data_dict[i].append(x)\n",
    "        elif line.endswith('(sdev)'):\n",
    "            values = list(filter(None,re.split('  |\\t', line) ) )\n",
    "            data_dict[1].append(values[0])\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    data_dict[1] = [' '.join(item) for item in zip(data_dict[1][::2],data_dict[1][1::2])]\n",
    "    \n",
    "    # With the parsed data and column names, match up the data and column\n",
    "    # based on the location\n",
    "    results = {}\n",
    "    for key,item in column_dict.items():\n",
    "        values = data_dict[key]\n",
    "        results.update({item:values})\n",
    "        \n",
    "    # Put the results into a dataframe\n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "        \n",
    "    # Now add the parsed info from the header files into the dataframe\n",
    "    for key,item in hdr.items():\n",
    "        df[key] = item\n",
    "        \n",
    "    # Get the cast number\n",
    "    cast = filename[filename.index('.')-3:filename.index('.')]\n",
    "    df['Cast #'] = str(cast).zfill(3)\n",
    "    \n",
    "    # Generate a filename for the summary file\n",
    "    outname = filename.split('.')[0] + '.sum'\n",
    "    \n",
    "    # Save the results\n",
    "    df.to_csv(btlpath+outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, for each \"summary\" file, load and append to each other\n",
    "df = pd.DataFrame()\n",
    "for file in os.listdir(btlpath):\n",
    "    if '.sum' in file:\n",
    "        df = df.append(pd.read_csv(btlpath+file))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_name_map['Short Name'].apply(lambda x: str(x).lower());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column title using the sbe_name_mapping \n",
    "for colname in list(df.columns.values):\n",
    "    try:\n",
    "        fullname = list(sbe_name_map[sbe_name_map['Short Name'].apply(lambda x: str(x).lower() == colname.lower()) == True]['Full Name'])[0]\n",
    "        df.rename({colname:fullname},axis='columns',inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Bottle Position':'Niskin #'},inplace=True)\n",
    "df['Niskin #'] = df['Niskin #'].apply(lambda x: str( int(x) ) )\n",
    "df.drop(columns='Unnamed: 0',inplace=True)\n",
    "df['Cast #'] = df['Cast #'].apply(lambda x: str(x).zfill(3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oxygen & Salinity \n",
    "Now, we need to add the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sal_files(dirpath):\n",
    "    \n",
    "    # Run check if files are held in excel format or csvs\n",
    "    csv_flag = any(files.endswith('.SAL') for files in os.listdir(dirpath))\n",
    "    if csv_flag:\n",
    "        for files in os.listdir(dirpath):\n",
    "            sample = []\n",
    "            salinity = []\n",
    "            with open(basepath+array+cruise+'Water Sampling/Salts and O2/'+leg+files) as file:\n",
    "                data = file.readlines()\n",
    "                for ind1,line in enumerate(data):\n",
    "                    if ind1 == 0:\n",
    "                        strs = data[0].replace('\"','').split(',')\n",
    "                        cruisename = strs[0]\n",
    "                        station = strs[1]\n",
    "                        cast = strs[2]\n",
    "                        case = strs[8]\n",
    "                    elif int(line.split()[0]) == 0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        strs = line.split()\n",
    "                        sample.append(strs[0])\n",
    "                        salinity.append(strs[2]) \n",
    "                # Generate a pandas dataframe to populate data\n",
    "                data_dict = {'Cruise ID':cruisename,'Station #':station,'Cast #':cast,'Case':case,'Sample ID':sample,'Salinity [psu]':salinity}\n",
    "                df = pd.DataFrame.from_dict(data_dict)\n",
    "                df.to_csv(file.name.replace('.','')+'.csv')\n",
    "    \n",
    "    else:\n",
    "        # If the files are already in excel spreadsheets, they've been cleaned into a\n",
    "        # logical tabular format\n",
    "        pass\n",
    "    \n",
    "\n",
    "def process_sal_files(dirpath):\n",
    "    \n",
    "    # Check if the files are excel files or not\n",
    "    excel_flag = any(files.endswith('SAL.xlsx') for files in os.listdir(dirpath))\n",
    "    # Initialize a dataframe for processing the salinity files\n",
    "    df = pd.DataFrame()\n",
    "    if excel_flag:\n",
    "        for file in os.listdir(dirpath):\n",
    "            if 'SAL.xlsx' in file:\n",
    "                df = df.append(pd.read_csv(dirpath+file))\n",
    "        df.rename({'Cruise':'Cruise ID','Station':'Station #','Sample':'Sample ID','Salinity':'Salinity [psu]'},\n",
    "          axis='columns',inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df['Station #'] = df['Station #'].apply(lambda x: str( int(x)).zfill(3))\n",
    "        df['Niskin #'] = df['Niskin #'].apply(lambda x: str( int(x)))\n",
    "        df['Sample ID'] = df['Sample ID'].apply(lambda x: str( int(x)))\n",
    "    else:\n",
    "        for file in os.listdir(dirpath):\n",
    "            if 'SAL.csv' in file:\n",
    "                df = df.append(pd.read_csv(dirpath+file))\n",
    "        df.dropna(inplace=True)\n",
    "        df['Station #'] = df['Station #'].apply(lambda x: str( int(x)).zfill(3))\n",
    "        df['Sample ID'] = df['Sample ID'].apply(lambda x: str( int(x)))\n",
    "        df.drop(columns=[x for x in list(df.columns.values) if 'unnamed' in x.lower()],inplace=True)\n",
    "\n",
    "    # Save the processed summary file for salinity\n",
    "    df.to_csv(dirpath+'SAL_Summary.csv')\n",
    "    \n",
    "    \n",
    "def process_oxy_files(dirpath):\n",
    "    df = pd.DataFrame()\n",
    "    for file in os.listdir(dirpath):\n",
    "        if 'OXY' in file:\n",
    "            df = df.append(pd.read_excel(dirpath+file))\n",
    "    # Rename and clean up the oxygen data to be uniform across data sets\n",
    "    df.rename({'Cruise':'Cruise ID','Station':'Station #','Sample#':'Sample ID','Oxy':'Oxygen [mL/L]','Unit':'Units'},\n",
    "          axis='columns',inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df['Station #'] = df['Station #'].apply(lambda x: str( int(x)).zfill(3))\n",
    "    df['Niskin #'] = df['Niskin #'].apply(lambda x: str( int(x)))\n",
    "    df['Sample ID'] = df['Sample ID'].apply(lambda x: str( int(x)))\n",
    "    df['Cruise ID'] = df['Cruise ID'].apply(lambda x: x.replace('O','0'))\n",
    "    \n",
    "    # Save the processed summary file for oxygen\n",
    "    df.to_csv(dirpath+'OXY_Summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = basepath+array+cruise+'Water Sampling/'\n",
    "os.listdir(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Pioneer-1_KN-214_Sampling_Log.xlsx'\n",
    "sample_log = pd.read_excel(dirpath+file,sheet_name='Summary',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(basepath+array+cruise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = []\n",
    "for x in list(sample_log.columns.values):\n",
    "    y = 'Cast #'\n",
    "    match.append(fuzz.token_set_ratio(x,y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column headers\n",
    "sample_log.rename(columns=lambda x: 'Sample Log: ' + x.strip(), inplace=True)\n",
    "sample_log['Sample Log: Niskin #'] = sample_log['Sample Log: Niskin #'].apply(lambda x: int(x.replace('*','')) if type(x) == str else x )\n",
    "sample_log['Sample Log: Niskin #'] = sample_log['Sample Log: Niskin #'].apply(lambda x: x if np.isnan(x) else str( int(x) ) )\n",
    "sample_log['Sample Log: Cast #'] = sample_log['Sample Log: Station-Cast #'].apply(lambda x: str(x).zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(sample_log['Sample Log: Niskin #']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutrient Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/'\n",
    "array = 'Pioneer/'\n",
    "cruise = 'Pioneer-01/'\n",
    "leg = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(basepath+array+cruise+'Water Sampling/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = basepath+array+cruise+'Water Sampling/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutfile = [x for x in os.listdir(dirpath) if 'nutrient' in x.lower()]\n",
    "chlfile = [x for x in os.listdir(dirpath) if 'chl' in x.lower() and x.endswith('.pdf') == False]\n",
    "nutfile, chlfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = pd.read_excel(basepath+array+cruise+'Water Sampling/'+nutfile[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl = pd.read_excel(dirpath+chlfile[0])\n",
    "chl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl[['Station-Cast #','Niskin #','Brown Bottle #','Chl (ug/l)','Phaeo (ug/l)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_df.rename(columns=lambda x: 'SAL: ' + x.strip(), inplace=True)\n",
    "sal_df.dropna(subset=['SAL: Cruise'], inplace=True)\n",
    "sal_df.fillna(-999, inplace=True)\n",
    "sal_df['SAL: Station'] = sal_df['SAL: Station'].apply(lambda x: str( int(x) ).zfill(3) )\n",
    "sal_df['SAL: Niskin #'] = sal_df['SAL: Niskin #'].apply(lambda x: str( int(x) ) )\n",
    "sal_df['SAL: Sample'] = sal_df['SAL: Sample'].apply(lambda x: str( int(x) ) )\n",
    "sal_df['SAL: Sample'] = sal_df['SAL: Case ID'] + sal_df['SAL: Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxy_df.rename(columns=lambda x: 'OXY: ' + x.strip(), inplace=True)\n",
    "oxy_df.dropna(subset=['OXY: Cruise'], inplace=True)\n",
    "oxy_df.fillna(-999, inplace=True)\n",
    "oxy_df['OXY: Station'] = oxy_df['OXY: Station'].apply(lambda x: str( int(x) ).zfill(3) )\n",
    "oxy_df['OXY: Niskin #'] = oxy_df['OXY: Niskin #'].apply(lambda x: str( int(x) ) )\n",
    "oxy_df['OXY: Sample#'] = oxy_df['OXY: Sample#'].apply(lambda x: str( int(x) ) )\n",
    "oxy_df['OXY: Sample#'] = oxy_df['OXY: Case'] + oxy_df['OXY: Sample#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I need to merge dataframes together\n",
    "sample_log = sample_log.merge(sal_df, how='left', left_on=['Sample Log: Cast #','Sample Log: Salts Bottle #'], right_on=['SAL: Station','SAL: Sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log = sample_log.merge(oxy_df, how='left', left_on=['Sample Log: Cast #','Sample Log: Oxygen Bottle #'],\n",
    "                              right_on=['OXY: Station','OXY: Sample#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('Irminger/Irminger-5/Water Sampling/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = pd.read_excel(nutrients_path,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_bottles = sample_log['Sample Log: Nitrate Bottle 1'].str.split(',').apply(pd.Series, 1).stack()\n",
    "nutrient_bottles.index = nutrient_bottles.index.droplevel(-1)\n",
    "nutrient_bottles.name = 'Nitrate Bottle #'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_bottles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the nutrient bottle number back into the sample log, and remove the excess '.'\n",
    "sample_log = sample_log.join(nutrient_bottles)\n",
    "sample_log['Nitrate Bottle #'] = sample_log['Nitrate Bottle #'].apply(lambda x: x.replace('.','') if type(x) == str else x)\n",
    "sample_log['Nitrate Bottle #'] = sample_log['Nitrate Bottle #'].apply(lambda x: x.replace(' ','') if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I can add the nutrient bottle data to the sample log before loading\n",
    "sample_log = sample_log.merge(nutrients, how='left', left_on='Nitrate Bottle #', right_on='Sample ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_columns = ['Sample Log: Cast #','Sample Log: Niskin #','SAL: Salinity','OXY: Oxy','Avg: Nitrate+Nitrite [µmol/L]', 'Avg: Ammonium [µmol/L]',\n",
    "    'Avg: Phosphate [µmol/L]', 'Avg: Silicate [µmol/L]', 'Avg: Nitrite [µmol/L]', 'Avg: Nitrate [µmol/L]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.merge(sample_log[sample_columns], how='left',\n",
    "                  left_on=['Cast #','Niskin #'], right_on=['Sample Log: Cast #','Sample Log: Niskin #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_unit = '[' + list(set(sal_df['SAL: Unit']) )[0] + ']'\n",
    "oxy_unit = '[' + list(set(oxy_df['OXY: Unit']) )[0] + ']'\n",
    "sal_unit, oxy_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(['Sample Log: Cast #','Sample Log: Niskin #'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns=lambda x: x.replace('SAL:','Bottle') + ' ' + sal_unit if 'SAL:' in x else x, inplace=True)\n",
    "result.rename(columns=lambda x: x.replace('OXY:','Bottle') + ' ' + oxy_unit if 'OXY:' in x else x, inplace=True)\n",
    "result.rename(columns=lambda x: x.replace('Avg:','Bottle') if 'Avg:' in x else x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all of the nans with -999999 and save to a csv\n",
    "result.fillna(str(-9999999),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(salts_and_o2_path+'Irminger-3_Summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
