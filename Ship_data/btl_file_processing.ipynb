{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottle Processing\n",
    "Author: Andrew Reed\n",
    "\n",
    "### Motivation:\n",
    "Independent verification of the suite of physical and chemical observations provided by OOI are critical for the observations to be of use for scientifically valid investigations. Consequently, CTD casts and Niskin water samples are made during deployment and recovery of OOI platforms, vehicles, and instrumentation. The water samples are subsequently analyzed by independent labs for  comparison with the OOI telemetered and recovered data.\n",
    "\n",
    "However, currently the water sample data routinely collected and analyzed as part of the OOI program are not available in a standardized format which maps the different chemical analyses to the physical measurements taken at bottle closure. Our aim is to make these physical and chemical analyses of collected water samples available to the end-user in a standardized format for easy comprehension and use, while maintaining the source data files. \n",
    "\n",
    "### Approach:\n",
    "Generating a summary of the water sample analyses involves preprocessing and concatenating multiple data sources, and accurately matching samples with each other. To do this, I first preprocess the ctd casts to generate bottle (.btl) files using the SeaBird vendor software following the SOP available on Alfresco. \n",
    "\n",
    "Next, the bottle files are parsed using python code and the data renamed following SeaBird's naming guide. This creates a series of individual cast summary (.sum) files. These files are then loaded into pandas dataframes, appended to each other, and exported as a csv file containing all of the bottle data in a single data file.\n",
    "\n",
    "### Data Sources/Software:\n",
    "\n",
    "* **sbe_name_map**: This is a spreadsheet which maps the short names generated by the SeaBird SBE DataProcessing Software to the associated full names. The name mapping originates from SeaBird's SBE DataProcessing support documentation.\n",
    "\n",
    "* **Alfresco**: The Alfresco CMS for OOI at alfresco.oceanobservatories.org is the source of the ctd hex, xmlcon, and psa files necessary for generating the bottle files needed to create the sample summary sheet.\n",
    "\n",
    "* **SBEDataProcessing-Win32**: SeaBird vendor software for processing the raw ctd files and generating the .btl files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages used in this notebook\n",
    "import os, sys, re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the name mapping for the column names\n",
    "# Specifiy the local directory\n",
    "sbe_name_map = pd.read_excel('/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Reference_Files/seabird_ctd_name_map.xlsx')\n",
    "# sbe_name_map = pd.read_excel('C:/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Reference_Files/seabird_ctd_name_map.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = 'Pioneer/'\n",
    "cruise = 'Pioneer-01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0002A001.SAL',\n",
       " '0003A001.SAL',\n",
       " '0005A001.SAL',\n",
       " '0006A001.SAL',\n",
       " '0007A001.SAL',\n",
       " 'All Oxy.xlsx']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(array+cruise+'Water Sampling/Salt and O2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa0 in position 22: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-698b4f36b815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msalinity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcruise\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Water Sampling/Salt and O2/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mstrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa0 in position 22: invalid start byte"
     ]
    }
   ],
   "source": [
    "for files in os.listdir(array+cruise+'Water Sampling/Salt and O2/'):\n",
    "    niskin = []\n",
    "    cast = []\n",
    "    sample = []\n",
    "    salinity = []\n",
    "    with open(array+cruise+'Water Sampling/Salt and O2/'+files) as file:\n",
    "        for line in file.readlines():\n",
    "            line = line.replace(',',' ')\n",
    "            strs = line.split()\n",
    "            if line.startswith('\"'):\n",
    "                cast = strs[1].replace('\"','')\n",
    "            else:\n",
    "                niskin.append(strs[0])\n",
    "                sample.append(strs[1])\n",
    "                salinity.append(strs[2])\n",
    "    data = {'Cast #':cast,'Niskin #':niskin,'Sample':sample,'Salinity':salinity}\n",
    "    df = pd.DataFrame(data=data)\n",
    "    df = df[df['Salinity'] != '-9.0000']\n",
    "    df.to_excel(file.name+'.xlsx')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cast #</th>\n",
       "      <th>Niskin #</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Salinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007</td>\n",
       "      <td>1</td>\n",
       "      <td>1.98072</td>\n",
       "      <td>34.6209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007</td>\n",
       "      <td>2</td>\n",
       "      <td>1.98100</td>\n",
       "      <td>34.6264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007</td>\n",
       "      <td>3</td>\n",
       "      <td>1.95948</td>\n",
       "      <td>34.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007</td>\n",
       "      <td>4</td>\n",
       "      <td>1.95946</td>\n",
       "      <td>34.2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007</td>\n",
       "      <td>5</td>\n",
       "      <td>1.91482</td>\n",
       "      <td>33.3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>007</td>\n",
       "      <td>6</td>\n",
       "      <td>1.91488</td>\n",
       "      <td>33.3312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>007</td>\n",
       "      <td>7</td>\n",
       "      <td>1.90670</td>\n",
       "      <td>33.1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>007</td>\n",
       "      <td>8</td>\n",
       "      <td>1.90656</td>\n",
       "      <td>33.1688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cast # Niskin #   Sample Salinity\n",
       "0    007        1  1.98072  34.6209\n",
       "1    007        2  1.98100  34.6264\n",
       "2    007        3  1.95948  34.2040\n",
       "3    007        4  1.95946  34.2036\n",
       "4    007        5  1.91482  33.3301\n",
       "5    007        6  1.91488  33.3312\n",
       "6    007        7  1.90670  33.1715\n",
       "7    007        8  1.90656  33.1688"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the local directory where the bottle (.btl) files are stored for a particular cruise\n",
    "# dirpath = 'C:/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/Irminger/Irminger-5/ctd/'\n",
    "btlpath = '/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/'+array+cruise+'KN-214_CTD/'\n",
    "summary_sheet_path = '/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data'+array+cruise+'/Water Sampling/Pioneer-1_KN-214_Sampling_Log.xlsx'\n",
    "salts_and_o2_path = '/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/'+array+cruise+'/Water Sampling/Irminger_Sea-02_AT-30-01_Oxygen_and_Salnity_Sample_Data/'\n",
    "nutrients_path = '/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/'+array+cruise+'/Water Sampling/Irminger_Sea-02_AT-30-01_Nutrients_Sample_Data_2016-09-01_ver_1-00.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data for the start_time\n",
    "def parse_header(header):\n",
    "    \"\"\"\n",
    "    Parse the header of bottle (.btl) files to get critical information\n",
    "    for the summary spreadsheet.\n",
    "    \n",
    "    Args:\n",
    "        header - an object containing the header of the bottle file as a list of\n",
    "            strings, split at the newline.\n",
    "    Returns:\n",
    "        hdr - a dictionary object containing the start_time, filename, latitude,\n",
    "            longitude, and cruise id.\n",
    "    \"\"\"\n",
    "    hdr = {}\n",
    "    for line in header:\n",
    "        if 'start_time' in line.lower():\n",
    "            start_time = pd.to_datetime(re.split('= |\\[',line)[1])\n",
    "            hdr.update({'Start Time':start_time.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "        elif 'filename' in line.lower():\n",
    "            hex_name = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Hex name':hex_name})\n",
    "        elif 'latitude' in line.lower():\n",
    "            start_lat = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Start Latitude':start_lat})\n",
    "        elif 'longitude' in line.lower():\n",
    "            start_lon = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Start Longitude':start_lon})\n",
    "        elif 'cruise id' in line.lower():\n",
    "            cruise_id = re.split(':',line)[1].strip()\n",
    "            hdr.update({'Cruise ID':cruise_id})\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return hdr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write a function to autopopulate the bottle summary sample sheet\n",
    "files = [x for x in os.listdir(btlpath) if '.btl' in x]\n",
    "for filename in files:\n",
    "    filepath = os.path.abspath(btlpath+filename)\n",
    "    \n",
    "    # Load the raw content into memory\n",
    "    with open(filepath) as file:\n",
    "        content = file.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    \n",
    "    # Now parse the file content\n",
    "    header = []\n",
    "    columns = []\n",
    "    data = []\n",
    "    for line in content:\n",
    "        if line.startswith('*') or line.startswith('#'):\n",
    "            header.append(line)\n",
    "        else:\n",
    "            try:\n",
    "                float(line[0])\n",
    "                data.append(line)\n",
    "            except:\n",
    "                columns.append(line)\n",
    "    \n",
    "    # Parse the header\n",
    "    hdr = parse_header(header)\n",
    "    \n",
    "    # Parse the column identifiers\n",
    "    column_dict = {}\n",
    "    for line in columns:\n",
    "        for i,x in enumerate(line.split()):\n",
    "            try:\n",
    "                column_dict[i] = column_dict[i] + ' ' + x\n",
    "            except:\n",
    "                column_dict.update({i:x})\n",
    "    \n",
    "    # Parse the bottle data based on the column header locations\n",
    "    data_dict = {x:[] for x in column_dict.keys()}\n",
    "\n",
    "    for line in data:\n",
    "        if line.endswith('(avg)'):\n",
    "            values = list(filter(None,re.split('  |\\t', line) ) )\n",
    "            for i,x in enumerate(values):\n",
    "                data_dict[i].append(x)\n",
    "        elif line.endswith('(sdev)'):\n",
    "            values = list(filter(None,re.split('  |\\t', line) ) )\n",
    "            data_dict[1].append(values[0])\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    data_dict[1] = [' '.join(item) for item in zip(data_dict[1][::2],data_dict[1][1::2])]\n",
    "    \n",
    "    # With the parsed data and column names, match up the data and column\n",
    "    # based on the location\n",
    "    results = {}\n",
    "    for key,item in column_dict.items():\n",
    "        values = data_dict[key]\n",
    "        results.update({item:values})\n",
    "        \n",
    "    # Put the results into a dataframe\n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "        \n",
    "    # Now add the parsed info from the header files into the dataframe\n",
    "    for key,item in hdr.items():\n",
    "        df[key] = item\n",
    "        \n",
    "    # Get the cast number\n",
    "    cast = filename[filename.index('.')-3:filename.index('.')]\n",
    "    df['Cast #'] = str(cast).zfill(3)\n",
    "    \n",
    "    # Generate a filename for the summary file\n",
    "    outname = filename.split('.')[0] + '.sum'\n",
    "    \n",
    "    # Save the results\n",
    "    df.to_csv(btlpath+outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, for each \"summary\" file, load and append to each other\n",
    "df = pd.DataFrame()\n",
    "for file in os.listdir(btlpath):\n",
    "    if '.sum' in file:\n",
    "        df = df.append(pd.read_csv(btlpath+file))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_name_map['Short Name'].apply(lambda x: str(x).lower());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column title using the sbe_name_mapping \n",
    "for colname in list(df.columns.values):\n",
    "    try:\n",
    "        fullname = list(sbe_name_map[sbe_name_map['Short Name'].apply(lambda x: str(x).lower() == colname.lower()) == True]['Full Name'])[0]\n",
    "        df.rename({colname:fullname},axis='columns',inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Bottle Position':'Niskin #'},inplace=True)\n",
    "df['Niskin #'] = df['Niskin #'].apply(lambda x: str( int(x) ) )\n",
    "df.drop(columns='Unnamed: 0',inplace=True)\n",
    "df['Cast #'] = df['Cast #'].apply(lambda x: str(x).zfill(3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(dirpath+'Irminger-5_Summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oxygen & Salinity \n",
    "Now, we need to add the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a way to map the oxygen and salinity samples to the CTD samples\n",
    "# Load the CTD sample logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log = pd.read_excel(summary_sheet_path,sheet_name='Summary',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column headers\n",
    "sample_log.rename(columns=lambda x: 'Sample Log: ' + x.strip(), inplace=True)\n",
    "sample_log['Sample Log: Niskin #'] = sample_log['Sample Log: Niskin #'].apply(lambda x: int(x.replace('*','')) if type(x) == str else x )\n",
    "sample_log['Sample Log: Niskin #'] = sample_log['Sample Log: Niskin #'].apply(lambda x: x if np.isnan(x) else str( int(x) ) )\n",
    "sample_log['Sample Log: Cast #'] = sample_log['Sample Log: Cast #'].apply(lambda x: str(x).zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(sample_log['Sample Log: Niskin #']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the oxygen data\n",
    "sal_dir = salts_and_o2_path\n",
    "sal_df = pd.DataFrame()\n",
    "oxy_df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(sal_dir):\n",
    "    if 'SAL' in file:\n",
    "        sal_df = sal_df.append(pd.read_excel(sal_dir+file))\n",
    "    elif 'OXY' in file:\n",
    "        oxy_df = oxy_df.append(pd.read_excel(sal_dir+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_df.rename(columns=lambda x: 'SAL: ' + x.strip(), inplace=True)\n",
    "sal_df.dropna(subset=['SAL: Cruise'], inplace=True)\n",
    "sal_df.fillna(-999, inplace=True)\n",
    "sal_df['SAL: Station'] = sal_df['SAL: Station'].apply(lambda x: str( int(x) ).zfill(3) )\n",
    "sal_df['SAL: Niskin #'] = sal_df['SAL: Niskin #'].apply(lambda x: str( int(x) ) )\n",
    "sal_df['SAL: Sample'] = sal_df['SAL: Sample'].apply(lambda x: str( int(x) ) )\n",
    "sal_df['SAL: Sample'] = sal_df['SAL: Case ID'] + sal_df['SAL: Sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxy_df.rename(columns=lambda x: 'OXY: ' + x.strip(), inplace=True)\n",
    "oxy_df.dropna(subset=['OXY: Cruise'], inplace=True)\n",
    "oxy_df.fillna(-999, inplace=True)\n",
    "oxy_df['OXY: Station'] = oxy_df['OXY: Station'].apply(lambda x: str( int(x) ).zfill(3) )\n",
    "oxy_df['OXY: Niskin #'] = oxy_df['OXY: Niskin #'].apply(lambda x: str( int(x) ) )\n",
    "oxy_df['OXY: Sample#'] = oxy_df['OXY: Sample#'].apply(lambda x: str( int(x) ) )\n",
    "oxy_df['OXY: Sample#'] = oxy_df['OXY: Case'] + oxy_df['OXY: Sample#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I need to merge dataframes together\n",
    "sample_log = sample_log.merge(sal_df, how='left', left_on=['Sample Log: Cast #','Sample Log: Salts Bottle #'], right_on=['SAL: Station','SAL: Sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log = sample_log.merge(oxy_df, how='left', left_on=['Sample Log: Cast #','Sample Log: Oxygen Bottle #'],\n",
    "                              right_on=['OXY: Station','OXY: Sample#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('Irminger/Irminger-5/Water Sampling/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = pd.read_excel(nutrients_path,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_bottles = sample_log['Sample Log: Nitrate Bottle 1'].str.split(',').apply(pd.Series, 1).stack()\n",
    "nutrient_bottles.index = nutrient_bottles.index.droplevel(-1)\n",
    "nutrient_bottles.name = 'Nitrate Bottle #'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_bottles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the nutrient bottle number back into the sample log, and remove the excess '.'\n",
    "sample_log = sample_log.join(nutrient_bottles)\n",
    "sample_log['Nitrate Bottle #'] = sample_log['Nitrate Bottle #'].apply(lambda x: x.replace('.','') if type(x) == str else x)\n",
    "sample_log['Nitrate Bottle #'] = sample_log['Nitrate Bottle #'].apply(lambda x: x.replace(' ','') if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I can add the nutrient bottle data to the sample log before loading\n",
    "sample_log = sample_log.merge(nutrients, how='left', left_on='Nitrate Bottle #', right_on='Sample ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_columns = ['Sample Log: Cast #','Sample Log: Niskin #','SAL: Salinity','OXY: Oxy','Avg: Nitrate+Nitrite [µmol/L]', 'Avg: Ammonium [µmol/L]',\n",
    "    'Avg: Phosphate [µmol/L]', 'Avg: Silicate [µmol/L]', 'Avg: Nitrite [µmol/L]', 'Avg: Nitrate [µmol/L]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.merge(sample_log[sample_columns], how='left',\n",
    "                  left_on=['Cast #','Niskin #'], right_on=['Sample Log: Cast #','Sample Log: Niskin #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_unit = '[' + list(set(sal_df['SAL: Unit']) )[0] + ']'\n",
    "oxy_unit = '[' + list(set(oxy_df['OXY: Unit']) )[0] + ']'\n",
    "sal_unit, oxy_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop(['Sample Log: Cast #','Sample Log: Niskin #'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns=lambda x: x.replace('SAL:','Bottle') + ' ' + sal_unit if 'SAL:' in x else x, inplace=True)\n",
    "result.rename(columns=lambda x: x.replace('OXY:','Bottle') + ' ' + oxy_unit if 'OXY:' in x else x, inplace=True)\n",
    "result.rename(columns=lambda x: x.replace('Avg:','Bottle') if 'Avg:' in x else x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all of the nans with -999999 and save to a csv\n",
    "result.fillna(str(-9999999),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(salts_and_o2_path+'Irminger-3_Summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
