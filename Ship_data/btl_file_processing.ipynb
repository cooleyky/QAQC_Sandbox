{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottle Processing\n",
    "Author: Andrew Reed\n",
    "\n",
    "### Motivation:\n",
    "Independent verification of the suite of physical and chemical observations provided by OOI are critical for the observations to be of use for scientifically valid investigations. Consequently, CTD casts and Niskin water samples are made during deployment and recovery of OOI platforms, vehicles, and instrumentation. The water samples are subsequently analyzed by independent labs for  comparison with the OOI telemetered and recovered data.\n",
    "\n",
    "However, currently the water sample data routinely collected and analyzed as part of the OOI program are not available in a standardized format which maps the different chemical analyses to the physical measurements taken at bottle closure. Our aim is to make these physical and chemical analyses of collected water samples available to the end-user in a standardized format for easy comprehension and use, while maintaining the source data files. \n",
    "\n",
    "### Approach:\n",
    "Generating a summary of the water sample analyses involves preprocessing and concatenating multiple data sources, and accurately matching samples with each other. To do this, I first preprocess the ctd casts to generate bottle (.btl) files using the SeaBird vendor software following the SOP available on Alfresco. \n",
    "\n",
    "Next, the bottle files are parsed using python code and the data renamed following SeaBird's naming guide. This creates a series of individual cast summary (.sum) files. These files are then loaded into pandas dataframes, appended to each other, and exported as a csv file containing all of the bottle data in a single data file.\n",
    "\n",
    "### Data Sources/Software:\n",
    "\n",
    "* **sbe_name_map**: This is a spreadsheet which maps the short names generated by the SeaBird SBE DataProcessing Software to the associated full names. The name mapping originates from SeaBird's SBE DataProcessing support documentation.\n",
    "\n",
    "* **Alfresco**: The Alfresco CMS for OOI at alfresco.oceanobservatories.org is the source of the ctd hex, xmlcon, and psa files necessary for generating the bottle files needed to create the sample summary sheet.\n",
    "\n",
    "* **SBEDataProcessing-Win32**: SeaBird vendor software for processing the raw ctd files and generating the .btl files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Import packages which will be used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the name mapping for the column names based on SeaBird's manual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_name_map = pd.read_excel('/media/andrew/OS/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Reference_Files/seabird_ctd_name_map.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Short Name</th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Friendly Name</th>\n",
       "      <th>Units</th>\n",
       "      <th>Notes/Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accM</td>\n",
       "      <td>Acceleration [m/s^2]</td>\n",
       "      <td>acc M</td>\n",
       "      <td>m/s^2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accF</td>\n",
       "      <td>Acceleration [ft/s^2]</td>\n",
       "      <td>acc F</td>\n",
       "      <td>ft/s^2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>altM</td>\n",
       "      <td>Altimeter [m]</td>\n",
       "      <td>alt M</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altF</td>\n",
       "      <td>Altimeter [ft]</td>\n",
       "      <td>alt F</td>\n",
       "      <td>ft</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avgsvCM</td>\n",
       "      <td>Average Sound Velocity [Chen-Millero, m/s]</td>\n",
       "      <td>avgsv-C M</td>\n",
       "      <td>Chen-Millero, m/s</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Short Name                                   Full Name Friendly Name  \\\n",
       "0       accM                        Acceleration [m/s^2]         acc M   \n",
       "1       accF                       Acceleration [ft/s^2]         acc F   \n",
       "2       altM                               Altimeter [m]         alt M   \n",
       "3       altF                              Altimeter [ft]         alt F   \n",
       "4    avgsvCM  Average Sound Velocity [Chen-Millero, m/s]     avgsv-C M   \n",
       "\n",
       "               Units Notes/Comments  \n",
       "0              m/s^2            NaN  \n",
       "1             ft/s^2            NaN  \n",
       "2                  m            NaN  \n",
       "3                 ft            NaN  \n",
       "4  Chen-Millero, m/s            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbe_name_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the directories where the different data sets are stored locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/home/andrew/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/'\n",
    "array = 'Irminger/'\n",
    "cruise = 'Irminger-3/'\n",
    "leg = ''\n",
    "water_dir = 'Water Sampling/'\n",
    "ctd_dir = 'ctd/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salts and O2',\n",
       " 'CTD_Station_Log_Sta002.docx',\n",
       " 'CTD_Station_Log_Sta003.docx',\n",
       " 'Irminger_Sea-03_AR-07-01_DIC_Sample_Data_2019-01-02_ver_1-00.xlsx',\n",
       " 'Irminger_Sea-03_AR-07-01_CTD_Sampling_Log_2017-09-28_ver_1-00.xlsx',\n",
       " 'Irminger_Sea-03_AR-07-01_Nutrients_Sample_Data_2016-11-16_ver-1-00.xlsx',\n",
       " 'CTD_Station_Log_Sta004.docx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.listdir(basepath+array+cruise+water_dir)\n",
    "os.listdir(basepath+array+cruise+water_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(basepath+array+cruise+water_dir)\n",
    "for f in files:\n",
    "    if 'Leg_2' in f:\n",
    "        print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the full directory paths for the relevant data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the local directory where the bottle (.btl) files are stored for a particular cruise\n",
    "# dirpath = 'C:/Users/areed/Documents/OOI-CGSN/QAQC_Sandbox/Ship_data/Irminger/Irminger-5/ctd/'\n",
    "btlpath = basepath+array+cruise+leg+ctd_dir\n",
    "summary_sheet_path = basepath+array+cruise+water_dir+'Irminger_Sea-02_AT-30-01_CTD_Sampling_Logs_2016-07-12_ver_1-00.xlsx'\n",
    "salts_and_o2_path = basepath+array+cruise+water_dir+'Salts and O2/'+leg\n",
    "nutrients_path = basepath+array+cruise+water_dir+'Irminger_Sea-02_AT-30-01_Nutrients_Sample_Data_2016-09-01_ver_1-00.xlsx'\n",
    "chl_path = basepath+array+cruise+water_dir+'Irminger_Sea-02_AT-30-01_Chlorophyll_Sample_Data_2017-09-21_ver_1-00.xlsx'\n",
    "dic_path = basepath+array+cruise+water_dir+'Irminger_Sea-02_AT-30-01_DIC_Sample_Data_2019-01-02_ver_1-00.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data for the start_time\n",
    "def parse_header(header):\n",
    "    \"\"\"\n",
    "    Parse the header of bottle (.btl) files to get critical information\n",
    "    for the summary spreadsheet.\n",
    "    \n",
    "    Args:\n",
    "        header - an object containing the header of the bottle file as a list of\n",
    "            strings, split at the newline.\n",
    "    Returns:\n",
    "        hdr - a dictionary object containing the start_time, filename, latitude,\n",
    "            longitude, and cruise id.\n",
    "    \"\"\"\n",
    "    hdr = {}\n",
    "    for line in header:\n",
    "        if 'start_time' in line.lower():\n",
    "            start_time = pd.to_datetime(re.split('= |\\[',line)[1])\n",
    "            hdr.update({'Start Time [UTC]':start_time.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "        elif 'filename' in line.lower():\n",
    "            hex_name = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Filename':hex_name})\n",
    "        elif 'latitude' in line.lower():\n",
    "            start_lat = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Start Latitude [degrees]':start_lat})\n",
    "        elif 'longitude' in line.lower():\n",
    "            start_lon = re.split('=',line)[1].strip()\n",
    "            hdr.update({'Start Longitude [degrees]':start_lon})\n",
    "        elif 'cruise id' in line.lower():\n",
    "            cruise_id = re.split(':',line)[1].strip()\n",
    "            hdr.update({'Cruise':cruise_id})\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return hdr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write a function to autopopulate the bottle summary sample sheet\n",
    "files = [x for x in os.listdir(btlpath) if '.btl' in x]\n",
    "for filename in files:\n",
    "    filepath = os.path.abspath(btlpath+filename)\n",
    "    \n",
    "    # Load the raw content into memory\n",
    "    with open(filepath) as file:\n",
    "        content = file.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    \n",
    "    # Now parse the file content\n",
    "    header = []\n",
    "    columns = []\n",
    "    data = []\n",
    "    for line in content:\n",
    "        if line.startswith('*') or line.startswith('#'):\n",
    "            header.append(line)\n",
    "        else:\n",
    "            try:\n",
    "                float(line[0])\n",
    "                data.append(line)\n",
    "            except:\n",
    "                columns.append(line)\n",
    "    \n",
    "    # Parse the header\n",
    "    hdr = parse_header(header)\n",
    "    \n",
    "    # Parse the column identifiers\n",
    "    column_dict = {}\n",
    "    for line in columns:\n",
    "        for i,x in enumerate(line.split()):\n",
    "            try:\n",
    "                column_dict[i] = column_dict[i] + ' ' + x\n",
    "            except:\n",
    "                column_dict.update({i:x})\n",
    "    \n",
    "    # Parse the bottle data based on the column header locations\n",
    "    data_dict = {x:[] for x in column_dict.keys()}\n",
    "\n",
    "    for line in data:\n",
    "        if line.endswith('(avg)'):\n",
    "            values = list(filter(None,re.split('  |\\t', line) ) )\n",
    "            for i,x in enumerate(values):\n",
    "                data_dict[i].append(x)\n",
    "        elif line.endswith('(sdev)'):\n",
    "            values = list(filter(None,re.split('  |\\t', line) ) )\n",
    "            data_dict[1].append(values[0])\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    data_dict[1] = [' '.join(item) for item in zip(data_dict[1][::2],data_dict[1][1::2])]\n",
    "    \n",
    "    # With the parsed data and column names, match up the data and column\n",
    "    # based on the location\n",
    "    results = {}\n",
    "    for key,item in column_dict.items():\n",
    "        values = data_dict[key]\n",
    "        results.update({item:values})\n",
    "        \n",
    "    # Put the results into a dataframe\n",
    "    df = pd.DataFrame.from_dict(results)\n",
    "        \n",
    "    # Now add the parsed info from the header files into the dataframe\n",
    "    for key,item in hdr.items():\n",
    "        df[key] = item\n",
    "        \n",
    "    # Get the cast number\n",
    "    cast = filename[filename.index('.')-3:filename.index('.')]\n",
    "    df['Cast'] = str(cast).zfill(3)\n",
    "    \n",
    "    # Generate a filename for the summary file\n",
    "    outname = filename.split('.')[0] + '.sum'\n",
    "    \n",
    "    # Save the results\n",
    "    df.to_csv(btlpath+outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, for each \"summary\" file, load and append to each other\n",
    "df = pd.DataFrame()\n",
    "for file in os.listdir(btlpath):\n",
    "    if '.sum' in file:\n",
    "        df = df.append(pd.read_csv(btlpath+file))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbe_name_map['Short Name'].apply(lambda x: str(x).lower());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column title using the sbe_name_mapping \n",
    "for colname in list(df.columns.values):\n",
    "    try:\n",
    "        fullname = list(sbe_name_map[sbe_name_map['Short Name'].apply(lambda x: str(x).lower() == colname.lower()) == True]['Full Name'])[0]\n",
    "        df.rename({colname:fullname},axis='columns',inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bottle Position'] = df['Bottle Position'].apply(lambda x: str( int(x) ) )\n",
    "df.drop(columns='Unnamed: 0',inplace=True)\n",
    "df['Cast'] = df['Cast'].apply(lambda x: str(x).zfill(3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(btlpath+'CTD_Summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oxygen & Salinity \n",
    "Now, we need to add the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sal_files(dirpath):\n",
    "\n",
    "    # Run check if files are held in excel format or csvs\n",
    "    csv_flag = any(files.endswith('.SAL') for files in os.listdir(dirpath))\n",
    "    if csv_flag:\n",
    "        for filename in os.listdir(dirpath):\n",
    "            sample = []\n",
    "            salinity = []\n",
    "            if filename.endswith('.SAL'):\n",
    "                with open(dirpath+filename) as file:\n",
    "                    data = file.readlines()\n",
    "                    for ind1,line in enumerate(data):\n",
    "                        if ind1 == 0:\n",
    "                            strs = data[0].replace('\"','').split(',')\n",
    "                            cruisename = strs[0]\n",
    "                            station = strs[1]\n",
    "                            cast = strs[2]\n",
    "                            case = strs[8]\n",
    "                        elif int(line.split()[0]) == 0:\n",
    "                            pass\n",
    "                        else:\n",
    "                            strs = line.split()\n",
    "                            sample.append(strs[0])\n",
    "                            salinity.append(strs[2])\n",
    "                \n",
    "                    # Generate a pandas dataframe to populate data\n",
    "                    data_dict = {'Cruise':cruisename,'Station':station,'Cast':cast,'Case':case,'Sample ID':sample,'Salinity [psu]':salinity}\n",
    "                    df = pd.DataFrame.from_dict(data_dict)\n",
    "                    df.to_csv(file.name.replace('.','')+'.csv')\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    else:\n",
    "        # If the files are already in excel spreadsheets, they've been cleaned into a\n",
    "        # logical tabular format\n",
    "        pass\n",
    "    \n",
    "\n",
    "def process_sal_files(dirpath):\n",
    "    \n",
    "    # Check if the files are excel files or not\n",
    "    excel_flag = any(files.endswith('SAL.xlsx') for files in os.listdir(dirpath))\n",
    "    # Initialize a dataframe for processing the salinity files\n",
    "    df = pd.DataFrame()\n",
    "    if excel_flag:\n",
    "        for file in os.listdir(dirpath):\n",
    "            if 'SAL.xlsx' in file:\n",
    "                df = df.append(pd.read_excel(dirpath+file))\n",
    "        df.rename({'Sample':'Sample ID','Salinity':'Salinity [psu]','Niskin #':'Niskin','Case ID':'Case'}, \n",
    "                  axis='columns',inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df['Station'] = df['Station'].apply(lambda x: str( int(x)).zfill(3))\n",
    "        df['Niskin'] = df['Niskin'].apply(lambda x: str( int(x)))\n",
    "        df['Sample ID'] = df['Sample ID'].apply(lambda x: str( int(x)))\n",
    "    else:\n",
    "        for file in os.listdir(dirpath):\n",
    "            if 'SAL.csv' in file:\n",
    "                df = df.append(pd.read_csv(dirpath+file))\n",
    "        df.dropna(inplace=True)\n",
    "        df['Station'] = df['Station'].apply(lambda x: str( int(x)).zfill(3))\n",
    "        df['Sample ID'] = df['Sample ID'].apply(lambda x: str( int(x)))\n",
    "        df.drop(columns=[x for x in list(df.columns.values) if 'unnamed' in x.lower()],inplace=True)\n",
    "\n",
    "    # Save the processed summary file for salinity\n",
    "    df.to_csv(dirpath+'SAL_Summary.csv')\n",
    "    \n",
    "    \n",
    "def process_oxy_files(dirpath):\n",
    "    df = pd.DataFrame()\n",
    "    for filename in os.listdir(dirpath):\n",
    "        if 'oxy' in filename.lower() and filename.endswith('.xlsx'):\n",
    "            df = df.append(pd.read_excel(dirpath+filename)) \n",
    "            # Rename and clean up the oxygen data to be uniform across data sets\n",
    "    df.rename({'Niskin #':'Niskin','Sample#':'Sample ID','Oxy':'Oxygen [mL/L]','Unit':'Units'},\n",
    "              axis='columns',inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df['Station'] = df['Station'].apply(lambda x: str( int(x)).zfill(3))\n",
    "    df['Niskin'] = df['Niskin'].apply(lambda x: str( int(x)))\n",
    "    df['Sample ID'] = df['Sample ID'].apply(lambda x: str( int(x)))\n",
    "    df['Cruise'] = df['Cruise'].apply(lambda x: x.replace('O','0'))\n",
    "    \n",
    "    # Save the processed summary file for oxygen\n",
    "    df.to_csv(dirpath+'OXY_Summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now process the salts and oxygen data\n",
    "    # Clean the salinity\n",
    "clean_sal_files(salts_and_o2_path)\n",
    "    # Process the salinity files\n",
    "process_sal_files(salts_and_o2_path)\n",
    "    # Process the oxygen files\n",
    "process_oxy_files(salts_and_o2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTD Sampling Log\n",
    "Load in the CTD sampling log summary sheet. The summary sheet needs to be manually created and the data cleaned before attempting to import. Additionally, ensure that there is only one header line and that it is at the top of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sample_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log = pd.read_excel(summary_sheet_path,sheet_name='Summary',header=0)\n",
    "sample_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the Comments field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.rename(columns={'Chlorophyll Comments':'Comments'},inplace=True)\n",
    "sample_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nutrient & Chlorophyll Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    nutrients = pd.read_excel(nutrients_path,header=0)\n",
    "    nutrients\n",
    "except IsADirectoryError:\n",
    "    nutrients = pd.DataFrame(data=sample_log['Nitrate Bottle 1'])\n",
    "    nutrients.rename(columns={'Nitrate Bottle 1':'Sample ID'}, inplace=True)\n",
    "    columns = ['Sample ID','Cruise','Avg: Nitrate + Nitrite [µmol/L]','Avg: Ammonium [µmol/L]',\n",
    "               'Avg: Phosphate [µmol/L]','Avg: Silicate [µmol/L]','Avg: Nitrite [µmol/L]','Avg: Nitrate [µmol/L]']\n",
    "    for col in columns:\n",
    "        if col not in nutrients.columns.values:\n",
    "            nutrients[col] = nutrients['Sample ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.rename(columns={'Unnamed: 0':'Sample ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log['Chlorophyll Filter Sample # \\nCast #/Depth/Bottle #/\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chl = pd.read_excel(chl_path)\n",
    "    chl.head()\n",
    "except IsADirectoryError:\n",
    "    # If there is no chlorophyll sheet yet, need to copy the bottle data into the final sample log\n",
    "    chl = sample_log[['Station-Cast #','Chlorophyll Brown Bottle #','Chlorophyll Filter Sample #','Chlorophyll LN Tube']]\n",
    "    chl.rename(columns={\n",
    "        'Chlorophyll Brown Bottle #': 'Brown Bottle #',\n",
    "        'Chlorophyll Filter Sample #': 'Chl (ug/l)',\n",
    "        'Chlorophyll LN Tube':'Phaeo (ug/l)'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Salinity and oxygen summaries\n",
    "sal = pd.read_csv(salts_and_o2_path+'SAL_Summary.csv')\n",
    "if 'case' in [x.lower() for x in sal.columns.values]:\n",
    "    sal['Sample ID'] = sal['Case'] + sal['Sample ID'].apply(lambda x: str(x)) \n",
    "oxy = pd.read_csv(salts_and_o2_path+'OXY_Summary.csv')\n",
    "if 'case' in [x.lower() for x in oxy.columns.values]:\n",
    "    oxy['Sample ID'] = oxy['Case'] + oxy['Sample ID'].apply(lambda x: str(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "### Carbon-System Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dic = pd.read_excel(dic_path,header=0)\n",
    "    dic\n",
    "except IsADirectoryError:\n",
    "    dic = sample_log[['Station-Cast #','Niskin #','Ph Bottle #','DIC/TA Bottle #']]\n",
    "    dic.rename(columns={\n",
    "        'Station-Cast #':'CAST_NO',\n",
    "        'Niskin #':'NISKIN_NO',\n",
    "        'DIC/TA Bottle #':'DIC_UMOL_KG',\n",
    "        'Ph Bottle #':'PH_TOT_MEA',\n",
    "    }, inplace=True)\n",
    "    columns = ['CAST_NO', 'NISKIN_NO','DIC_UMOL_KG', 'DIC_FLAG_W', 'TA_UMOL_KG',\n",
    "       'TA_FLAG_W', 'PH_TOT_MEA', 'TMP_PH_DEG_C', 'PH_FLAG_W']\n",
    "    for col in columns:\n",
    "        if col not in dic.columns.values:\n",
    "            if 'dic' in col.lower() or 'ta' in col.lower():\n",
    "                dic[col] = dic['DIC_UMOL_KG']\n",
    "            elif 'ph' in col.lower():\n",
    "                dic[col] = dic['PH_TOT_MEA']\n",
    "            else:\n",
    "                dic[col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "### Sample Log \n",
    "Next, we need to merge the sample log with the individual oxygen, salinity, nutrient, chlorophyll, and carbon sampling sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Merge the **salinity** information with the sample_log based on cast # and salts sampling bottle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to mak\n",
    "sample_log = sample_log.merge(sal[['Station','Sample ID','Salinity [psu]']], how='left', left_on=['Station-Cast #','Salts Bottle #'], right_on=['Station','Sample ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.rename({'Salinity [psu]':'Discrete Salinity [psu]'},axis='columns',inplace=True)\n",
    "sample_log.drop(['Station','Sample ID'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.rename(columns=lambda x: x.strip(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Next, merge the **oxygen** data into the sample log based on cast # and oxygen sampling bottle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log = sample_log.merge(oxy[['Station','Sample ID','Oxygen [mL/L]']], how='left', left_on=['Station-Cast #','Oxygen Bottle #'], right_on=['Station','Sample ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.rename({'Oxygen [mL/L]':'Discrete Oxygen [mL/L]'},axis='columns',inplace=True)\n",
    "sample_log.drop(['Station','Sample ID'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Merge the **nutrients** data into the sample log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log['Nitrate Bottle 1'] = sample_log['Nitrate Bottle 1'].apply(lambda x: x.strip() if type(x) == str else x)\n",
    "sample_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log = sample_log.merge(nutrients, how='left', left_on=['Nitrate Bottle 1'], right_on=['Sample ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the avg values to discrete, and drop unneeded columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.rename(columns=lambda x: x.replace('Avg:', 'Discrete'), inplace=True)\n",
    "sample_log.drop(['Sample ID'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Merge the **chlorophyll** data into the sampling sheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_df = chl[['Station-Cast #','Brown Bottle #','Chl (ug/l)','Phaeo (ug/l)']]#,'Comments']]\n",
    "chl_df.rename(columns={'Comments':'Chl Comments'}, inplace = True)\n",
    "chl_df.rename(columns=lambda x: 'Discrete ' + x, inplace=True)\n",
    "#chl_df.rename({'Discrete quality_flag':'Discrete Chl quality flag'},axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log = sample_log.merge(chl_df, how='left', left_on=['Station-Cast #','Chlorophyll Brown Bottle #'], right_on=['Discrete Station-Cast #','Discrete Brown Bottle #'])\n",
    "sample_log.drop(['Discrete Station-Cast #','Discrete Brown Bottle #'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Merge the **Carbon** data into the sampling sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_df = dic[['CAST_NO', 'NISKIN_NO','DIC_UMOL_KG', 'DIC_FLAG_W', 'TA_UMOL_KG',\n",
    "       'TA_FLAG_W', 'PH_TOT_MEA', 'TMP_PH_DEG_C', 'PH_FLAG_W']]\n",
    "dic_df.rename(columns = {'DIC_UMOL_KG':'DIC [µmol/kg]',\n",
    "               'DIC_FLAG_W':'DIC Flag',\n",
    "               'TA_UMOL_KG':'Alkalinity [µmol/kg]',\n",
    "               'TA_FLAG_W':'Alkalinity Flag',\n",
    "               'PH_TOT_MEA':'pH [Total Scale]',\n",
    "               'TMP_PH_DEG_C':'pH Analysis Temp [C]', \n",
    "              'PH_FLAG_W':'pH Flag'}, inplace=True)\n",
    "# Add in the pCO2 columns, which we don't measure\n",
    "dic_df['pCO2'] = np.nan\n",
    "dic_df['pCO2 Flag'] = np.nan\n",
    "dic_df['pCO2 Analysis Temp [C]'] = np.nan\n",
    "\n",
    "dic_df.rename(columns=lambda x: 'Discrete ' + x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log = sample_log.merge(dic_df, how='left', left_on=['Station-Cast #','Niskin #'], right_on=['Discrete CAST_NO','Discrete NISKIN_NO'])\n",
    "sample_log.drop(['Discrete CAST_NO','Discrete NISKIN_NO'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "### CTD Data\n",
    "Now, we want to load the CTD bottle summary data and merge it with the water sampling data in the sample log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD = pd.read_csv(basepath+array+cruise+leg+ctd_dir+'CTD_Summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.rename({'Target Station':'Target Asset'},axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_log.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of columns to merge from the water sampling log with the CTD bottle summary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = []\n",
    "for name in list(sample_log.columns.values):\n",
    "    if 'Discrete' in name:\n",
    "        column_list.append(name)\n",
    "column_list.append('Station-Cast #')\n",
    "column_list.append('Start Latitude')\n",
    "column_list.append('Start Longitude')\n",
    "column_list.append('Start Date')\n",
    "column_list.append('Start Time')\n",
    "column_list.append('Niskin #')\n",
    "column_list.append('Target Asset')\n",
    "column_list.append('Bottom Depth [m]')\n",
    "column_list.append('Comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the column list to pull out the discrete data from the sample log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_data = sample_log[column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_data['Station-Cast #'] = discrete_data['Station-Cast #'].apply(lambda x: str(int(x)).zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD['Cast'] = CTD['Cast'].apply(lambda x: str(x).zfill(3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the discrete data into the CTD data based on the Cast and Niskin bottle number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD = CTD.merge(discrete_data, how='left', left_on=['Cast','Bottle Position'], right_on=['Station-Cast #','Niskin #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.drop(labels=['Unnamed: 0','Niskin #'],axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.rename({'Cast #':'Station'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.fillna(-9999999, inplace=True)\n",
    "CTD['Cruise ID'] = sample_log['Cruise ID'][0]\n",
    "CTD['Bottle Closure Time [UTC]'] = CTD['Date Time'].apply(lambda x: pd.to_datetime(x).strftime('%Y-%m-%dT%H:%M:%SZ'))\n",
    "CTD.drop(columns='Date Time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find where there were data casts only (so no bottle closures), and fill in missing data on Start Latitutde, Longitude, Time, and Bottome Depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD['Start Latitude [degrees]'] = CTD['Start Latitude'].where(CTD['Start Latitude [degrees]'] == -9999999, other=CTD['Start Latitude [degrees]'])\n",
    "CTD['Start Longitude [degrees]'] = CTD['Start Longitude'].where(CTD['Start Longitude [degrees]'] == -9999999, other=CTD['Start Longitude [degrees]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD['Station-Cast #'] = CTD['Cast'].where(CTD['Station-Cast #'] == -9999999, other=CTD['Station-Cast #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTD.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autogenerate the filename following the agreed-upon form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CTD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-afac9e3ead9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcruise_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Irminger-3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcruise_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCTD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cruise ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcurrent_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'US/Eastern'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1-01'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CTD' is not defined"
     ]
    }
   ],
   "source": [
    "cruise_name = 'Irminger-3'\n",
    "cruise_id = list(set(CTD['Cruise ID']))[0]\n",
    "current_date = pd.to_datetime(pd.datetime.now()).tz_localize(tz='US/Eastern').tz_convert(tz='UTC')\n",
    "version = '1-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '_'.join([cruise_name,cruise_id,'Discrete','Summary',current_date.strftime('%Y-%m-%d'),'ver',version,'.xlsx'])\n",
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**========================================================================================================================**\n",
    "Import the column order list and use fuzzy string matching to sort the data and save the data to an new Excel spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = pd.read_excel(basepath+'column_order.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = tuple([x.replace('CTD','').strip() for x in column_order.columns.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "CTDsorted = pd.DataFrame()\n",
    "for column in column_order:\n",
    "    match = process.extractBests(column.replace('Discrete ','').replace('Calculated ',''),\n",
    "                                 CTD.columns.values, limit=2, score_cutoff=56, scorer=fuzz.ratio)\n",
    "    if 'calculated' in column.lower():\n",
    "        CTDsorted[column] = -9999999\n",
    "    elif 'flag' in column.lower():\n",
    "        if column not in ['Discrete DIC Flag','Discrete Alkalinity Flag','Discrete pCO2 Flag','Discrete pH Flag']:\n",
    "            CTDsorted[column] = -9999999\n",
    "        else:\n",
    "            CTDsorted[column] = CTD[column]\n",
    "            results.update({column:match[0]})\n",
    "    elif len(match) == 0:\n",
    "        CTDsorted[column] = -9999999\n",
    "    elif (match[0][0] not in [x[0] for x in results.values()]):\n",
    "        CTDsorted[match[0][0]] = CTD[match[0][0]]\n",
    "        results.update({column:match[0]})\n",
    "    elif len(match) == 1:\n",
    "        CTDsorted[match[0][0]] = CTD[match[0][0]]\n",
    "        results.update({column:match[0]})\n",
    "    else:\n",
    "        CTDsorted[match[1][0]] = CTD[match[1][0]]\n",
    "        results.update({column:match[1]})\n",
    "CTDsorted['Comments'] = CTD['Comments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check each of the resulting columns for if the values have actually been put in. If they haven't, we want to substitute in the sample bottle number, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for the values that are just surface bottle closures\n",
    "A = CTDsorted['Target Asset'] == -9999999\n",
    "#B = CTDsorted['Station-Cast #'] == '008'\n",
    "#mask = np.logical_or(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDsorted[A].sort_values(by=['Station-Cast #','Bottle Position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDsorted.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(CTDsorted[A]['Station-Cast #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDsorted[A][CTDsorted[A]['Station-Cast #'] == '007']['Pressure, Digiquartz [db]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the results\n",
    "CTDsorted.to_excel(basepath+array+cruise+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDsorted[CTDsorted['Target Asset'] == -9999999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDsorted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDsorted[CTDsorted['Target Asset'] == -9999999][['Discrete Phaeo (ug/l)', 'Discrete Fo/Fa Ratio',\n",
    "       'Discrete Fluorescence Flag', 'Discrete Fluorescence Duplicate Flag']].iloc[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(CTDsorted[mask]['Station-Cast #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTDsorted[A]['Station-Cast #']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(CTDsorted[CTDsorted['Target Asset'] != -9999999]['Station-Cast #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(CTD['Station-Cast #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CTDsorted[CTDsorted['Station-Cast #'] == '008'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017_Key_File.docx',\n",
       " 'Pioneer',\n",
       " 'Cabled-8_RR1713-RR1717_Discrete_Summary_2017-07-27-README.docx',\n",
       " 'rosette_file_processing.ipynb',\n",
       " 'Untitled.ipynb',\n",
       " 'Irminger',\n",
       " 'column_order.xlsx',\n",
       " '.ipynb_checkpoints',\n",
       " 'btl_file_processing.ipynb']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.~lock.Irminger-3_AR07-01_Discrete_Summary_2019-06-12_ver_1-01_.xlsx#',\n",
       " 'ctd',\n",
       " 'Irminger-3_AR07-01_Discrete_Summary_2019-06-12_ver_1-01_.xlsx',\n",
       " 'Water Sampling']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/'.join((os.getcwd(),'Irminger','Irminger-3')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/'.join((os.getcwd(),'Irminger','Irminger-3','Irminger-3_AR07-01_Discrete_Summary_2019-06-12_ver_1-01_.xlsx')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 77 columns):\n",
      "Cruise ID                                        503 non-null object\n",
      "Station-Cast #                                   503 non-null int64\n",
      "Target Asset                                     503 non-null object\n",
      "Start Latitude [degrees]                         503 non-null object\n",
      "Start Longitude [degrees]                        503 non-null object\n",
      "Start Time [UTC]                                 503 non-null object\n",
      "Cast                                             503 non-null int64\n",
      "Cast Flag                                        503 non-null int64\n",
      "Bottom Depth [m]                                 503 non-null int64\n",
      "CTD Filename                                     503 non-null object\n",
      "CTD File Flag                                    503 non-null int64\n",
      "Bottle Position                                  503 non-null int64\n",
      "Niskin Flag                                      503 non-null int64\n",
      "CTD Bottle Closure Time [UTC]                    503 non-null object\n",
      "CTD Pressure, Digiquartz [db]                    503 non-null float64\n",
      "CTD Pressure Flag                                503 non-null int64\n",
      "CTD Depth [salt water, m]                        503 non-null float64\n",
      "CTD Latitude [deg]                               503 non-null float64\n",
      "CTD Longitude [deg]                              503 non-null float64\n",
      "CTD Temperature [ITS-90, deg C]                  503 non-null float64\n",
      "CTD Temperature 1 Flag                           503 non-null int64\n",
      "CTD Temperature, 2 [ITS-90, deg C]               503 non-null float64\n",
      "CTD Temperature 2 Flag                           503 non-null int64\n",
      "CTD Conductivity [S/m]                           503 non-null float64\n",
      "CTD Conductivity 1 Flag                          503 non-null int64\n",
      "CTD Conductivity, 2 [S/m]                        503 non-null float64\n",
      "CTD Conductivity 2 Flag                          503 non-null int64\n",
      "CTD Salinity, Practical [PSU]                    503 non-null float64\n",
      "CTD Salinity, Practical, 2 [PSU]                 503 non-null float64\n",
      "CTD Oxygen, SBE 43 [ml/l]                        503 non-null float64\n",
      "CTD Oxygen Flag                                  503 non-null int64\n",
      "CTD Oxygen Saturation, Garcia & Gordon [ml/l]    503 non-null float64\n",
      "CTD Fluorescence [mg/m^3]                        503 non-null int64\n",
      "CTD Fluorescence Flag                            503 non-null int64\n",
      "CTD Beam Attenuation, WET Labs C-Star [1/m]      503 non-null float64\n",
      "CTD Beam Transmission, WET Labs C-Star [%]       503 non-null object\n",
      "CTD Transmissometer Flag                         503 non-null int64\n",
      "CTD pH                                           503 non-null int64\n",
      "CTD pH Flag                                      503 non-null int64\n",
      "Discrete Oxygen [mL/L]                           503 non-null float64\n",
      "Discrete Oxygen Flag                             503 non-null int64\n",
      "Discrete Oxygen Duplicate Flag                   503 non-null int64\n",
      "Discrete Chl (ug/l)                              503 non-null object\n",
      "Discrete Phaeo (ug/l)                            503 non-null object\n",
      "Discrete Fo/Fa Ratio                             503 non-null int64\n",
      "Discrete Fluorescence Flag                       503 non-null int64\n",
      "Discrete Fluorescence Duplicate Flag             503 non-null int64\n",
      "Discrete Phosphate [µmol/L]                      503 non-null int64\n",
      "Discrete Silicate [µmol/L]                       503 non-null int64\n",
      "Discrete Nitrate [µmol/L]                        503 non-null int64\n",
      "Discrete Nitrite [µmol/L]                        503 non-null int64\n",
      "Discrete Ammonium [µmol/L]                       503 non-null int64\n",
      "Discrete Nutrients Flag                          503 non-null int64\n",
      "Discrete Nutrients Duplicate Flag                503 non-null int64\n",
      "Discrete Salinity [psu]                          503 non-null float64\n",
      "Discrete Salinity Flag                           503 non-null int64\n",
      "Discrete Salinity Duplicate Flag                 503 non-null int64\n",
      "Discrete Alkalinity [µmol/kg]                    503 non-null float64\n",
      "Discrete Alkalinity Flag                         503 non-null int64\n",
      "Discrete DIC [µmol/kg]                           503 non-null float64\n",
      "Discrete DIC Flag                                503 non-null int64\n",
      "Discrete pCO2 [µatm]                             503 non-null int64\n",
      "Discrete pCO2 Analysis Temp [C]                  503 non-null int64\n",
      "Discrete pCO2 Flag                               503 non-null int64\n",
      "Discrete pH [Total Scale]                        503 non-null float64\n",
      "Discrete pH Analysis Temp [C]                    503 non-null int64\n",
      "Discrete pH Flag                                 503 non-null int64\n",
      "Calculated Alkalinity [µmol/kg]                  503 non-null int64\n",
      "Calculated DIC [µmol/kg]                         503 non-null int64\n",
      "Calculated pCO2 [µatm]                           503 non-null int64\n",
      "Calculated pH                                    503 non-null int64\n",
      "Calculated CO2aq [µmol/kg]                       503 non-null int64\n",
      "Calculated bicarb [µmol/kg]                      503 non-null int64\n",
      "Calculated CO3 [µmol/kg]                         503 non-null int64\n",
      "Calculated Omega-C                               503 non-null int64\n",
      "Calculated Omega-A                               503 non-null int64\n",
      "Comments                                         503 non-null object\n",
      "dtypes: float64(18), int64(48), object(11)\n",
      "memory usage: 302.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/'.join((os.getcwd(),'Irminger','Irminger-3','Irminger-3_AR07-01_Discrete_Summary_2019-06-15_ver_1-01_.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
